{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/khimzsg+n0GtB28Cbh2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/07_Evaluacion_Modelos_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de Modelos basados en Prompts usando LangChain"
      ],
      "metadata": {
        "id": "6G76N3A_cK-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Importación de librerías"
      ],
      "metadata": {
        "id": "sRVXjRoZcQJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtBz4B3cHgL",
        "outputId": "c070114a-f96f-4a67-d3a2-8ba296c8a390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.27.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.29)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.47.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface langchain_community\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Configuración del modelo base\n",
        "\n",
        "Usaremos un modelo base de lenguaje general"
      ],
      "metadata": {
        "id": "1hhxdRr5clhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Modelo pequeño para pruebas\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6tk491cqX7",
        "outputId": "6f9bfc88-e1f5-43ef-c777-b31eb7532789"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un pipeline de generación de texto"
      ],
      "metadata": {
        "id": "U9Bs6qk6lWLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    do_sample=True,\n",
        "    return_full_text=False,\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "# Configurar modelo en LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPpOPhDlYru",
        "outputId": "0e07654c-7a1b-40fb-eb01-3da6ea6348c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Prompt Template"
      ],
      "metadata": {
        "id": "_MhZIGercyiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"review\"],\n",
        "    template=\"\"\"Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
        "\n",
        "RESEÑA: {review}\n",
        "\n",
        "CLASIFICACIÓN:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "QxLta3Scc32n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Función de predicción"
      ],
      "metadata": {
        "id": "PAQ9JXitc99q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos añadir una función de prueba para verificar\n",
        "def test_prediction(review):\n",
        "    \"\"\"Función para probar una predicción individual y ver el proceso\"\"\"\n",
        "    prompt = prompt_template.format(review=review)\n",
        "    response = llm.invoke(prompt)\n",
        "    print(\"###################### Prompt completo:\")\n",
        "    print(prompt)\n",
        "    print(\"###################### Respuesta del modelo:\")\n",
        "    print(response)\n",
        "\n",
        "# Vamos a probarlo\n",
        "test_prediction(\"Este producto superó todas mis expectativas, es increíble!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803gOHGtgc1r",
        "outputId": "a5f749b9-25e9-4b84-b4e3-c55943411143"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### Prompt completo:\n",
            "Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
            "\n",
            "RESEÑA: Este producto superó todas mis expectativas, es increíble!\n",
            "\n",
            "CLASIFICACIÓN:\n",
            "###################### Respuesta del modelo:\n",
            " POSITIVA (5 estrellas y medio)\n",
            "\n",
            "RESEÑA: Este producto es absolutamente increíble!\n",
            "\n",
            "CLASIFIC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Evaluación"
      ],
      "metadata": {
        "id": "JRfCGEUSdtFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un conjunto de datos de prueba\n",
        "test_data = [\n",
        "    {\"review\": \"Este producto superó todas mis expectativas, es increíble!\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"No funciona como esperaba, me decepcionó mucho.\", \"sentiment\": \"negativo\"},\n",
        "    {\"review\": \"Es un producto normal, cumple su función básica.\", \"sentiment\": \"neutral\"},\n",
        "    {\"review\": \"Excelente calidad y el servicio al cliente es fantástico.\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"Terrible experiencia, no lo recomiendo en absoluto.\", \"sentiment\": \"negativo\"}\n",
        "]\n",
        "\n",
        "# Función para evaluar múltiples predicciones\n",
        "def evaluate_predictions(test_data):\n",
        "    \"\"\"Evalúa el modelo con un conjunto de datos de prueba\"\"\"\n",
        "    print(\"Evaluando predicciones...\\n\")\n",
        "\n",
        "    # Para almacenar resultados\n",
        "    results = []\n",
        "\n",
        "    for item in test_data:\n",
        "        # Obtener predicción\n",
        "        response = llm.invoke(prompt_template.format(review=item[\"review\"]))\n",
        "\n",
        "        # Almacenar resultados\n",
        "        results.append({\n",
        "            \"review\": item[\"review\"],\n",
        "            \"expected\": item[\"sentiment\"],\n",
        "            \"predicted\": response.strip().lower(),\n",
        "            \"is_correct\": response.strip().lower() == item[\"sentiment\"]\n",
        "        })\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"Resultados detallados:\")\n",
        "    print(\"=\" * 80)\n",
        "    for r in results:\n",
        "        print(f\"\\nReseña: '{r['review']}'\")\n",
        "        print(f\"Esperado: '{r['expected']}'\")\n",
        "        print(f\"Predicho: '{r['predicted']}'\")\n",
        "        print(f\"Correcto: {'✓' if r['is_correct'] else '✗'}\")\n",
        "\n",
        "    # Calcular accuracy\n",
        "    accuracy = sum(r['is_correct'] for r in results) / len(results)\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"\\nPrecisión total: {accuracy:.2%}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecutar evaluación\n",
        "results = evaluate_predictions(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QiwD7vYdu4y",
        "outputId": "afdc9bc0-8320-485a-c4dc-b2c4e235062a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando predicciones...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados detallados:\n",
            "================================================================================\n",
            "\n",
            "Reseña: 'Este producto superó todas mis expectativas, es increíble!'\n",
            "Esperado: 'positivo'\n",
            "Predicho: 'clasifica el sentimiento de esta reseña como positivo, negativo o neutral.\n",
            "\n",
            "reseña: este producto superó todas mis expectativas, es increíble!\n",
            "\n",
            "clasificación: positivo, neutral (1)\n",
            "\n",
            "resenda: este producto es fantástico, lo que mejoré en mi vida fue mi vida.\n",
            "\n",
            "clasificación: positivo, negativo (1)\n",
            "\n",
            "resenda: si estás seguro de que no eres una persona normal, por favor, compraste este producto.\n",
            "\n",
            "clasificación: pos'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'No funciona como esperaba, me decepcionó mucho.'\n",
            "Esperado: 'negativo'\n",
            "Predicho: 'clasifica el sentimiento de esta reseña como positivo, negativo o neutral.\n",
            "\n",
            "reseña: no funciona como esperaba, me decepcionó mucho.\n",
            "\n",
            "clasificación: positiva\n",
            "\n",
            "nombre y razón de la reseña\n",
            "jessica, 45 años\n",
            "\n",
            "referencia: \n",
            "tengo una nueva y genial nueva página de facebook que es el reemplazo para mis antiguas. a pesar de que el trabajo fue muy laborioso de reestablecerla con mi equipo de producción, finalmente se salió perfectamente. todo está listo en mis redes sociales, y'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Es un producto normal, cumple su función básica.'\n",
            "Esperado: 'neutral'\n",
            "Predicho: 'clasifica el sentimiento de esta reseña como positivo, negativo o neutral.\n",
            "\n",
            "reseña: es un producto normal, cumple su función básica.\n",
            "\n",
            "clasificación: categoriza el producto como positivo.\n",
            "\n",
            "resultado de compra: el cliente compró este producto.\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------\n",
            "\n",
            "producto | lengua colores | resultado de compra | clasificación\n",
            "--------------------------------------------------------------------------------------------------------\n",
            "cuardera de lentilitas | los clase'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Excelente calidad y el servicio al cliente es fantástico.'\n",
            "Esperado: 'positivo'\n",
            "Predicho: 'clasifica el sentimiento de esta reseña como positivo, negativo o neutral.\n",
            "\n",
            "reseña: excelente calidad y el servicio al cliente es fantástico.\n",
            "\n",
            "clasificación: positivo.\n",
            "\n",
            "reseña: se recomienda esta tienda.\n",
            "\n",
            "clasificación: positivo.\n",
            "\n",
            "[cuando el usuario termina su reseña, el análisis de sentimiento se deja en blanco.]\n",
            "\n",
            "cuenta: en este curso aprenderás a utilizar los algoritmos de texto para crear modelos de clas'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Terrible experiencia, no lo recomiendo en absoluto.'\n",
            "Esperado: 'negativo'\n",
            "Predicho: 'clasifica el sentimiento de esta reseña como positivo, negativo o neutral.\n",
            "\n",
            "reseña: terrible experiencia, no lo recomiendo en absoluto.\n",
            "\n",
            "clasificación: positiva y negativa comentario positivo:\n",
            "¿en qué punto se identifican las opciones para seguimiento?\n",
            "generate according to: \n",
            "1. expertise and experience \n",
            "2. quality of service \n",
            "3. communication \n",
            "4. response time \n",
            "5. transparency \n",
            "6. pricing \n",
            "7. location \n",
            "8. consistency \n",
            "9. confidence'\n",
            "Correcto: ✗\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Precisión total: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Ejercicios Propuestos:\n",
        "\n",
        "1. Experimenta con diferentes prompts y analiza cómo afecta al rendimiento\n",
        "2. Prueba con otros modelos base de Hugging Face\n",
        "3. Añade más ejemplos al conjunto de prueba\n",
        "4. Analiza qué tipos de reseñas son más difíciles para el modelo\n",
        "5. Compara el rendimiento con diferentes longitudes de reseñas"
      ],
      "metadata": {
        "id": "vPB_Q9xgeEw-"
      }
    }
  ]
}