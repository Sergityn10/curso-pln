{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDaoFWa5HiVGzi8qeBt2dN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/07_Evaluacion_Modelos_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de Modelos basados en Prompts usando LangChain"
      ],
      "metadata": {
        "id": "6G76N3A_cK-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Importación de librerías"
      ],
      "metadata": {
        "id": "sRVXjRoZcQJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtBz4B3cHgL",
        "outputId": "abedab2b-7d43-4f29-926f-274abb402b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.27.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.28)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Configuración del modelo base\n",
        "\n",
        "Usaremos un modelo base de lenguaje general"
      ],
      "metadata": {
        "id": "1hhxdRr5clhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Modelo pequeño para pruebas\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Ua6tk491cqX7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un pipeline de generación de texto"
      ],
      "metadata": {
        "id": "U9Bs6qk6lWLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    do_sample=True,\n",
        "    return_full_text=False,  # Esto hace que solo devuelva el texto nuevo generado\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Configurar modelo en LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPpOPhDlYru",
        "outputId": "5c2a7d9d-7db9-4dcb-ad98-f2b4d5c69027"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Prompt Template"
      ],
      "metadata": {
        "id": "_MhZIGercyiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"review\"],\n",
        "    template=\"\"\"Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
        "Responde ÚNICAMENTE con una de estas tres palabras.\n",
        "\n",
        "RESEÑA: {review}\n",
        "\n",
        "CLASIFICACIÓN:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "QxLta3Scc32n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Función de predicción"
      ],
      "metadata": {
        "id": "PAQ9JXitc99q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos añadir una función de prueba para verificar\n",
        "def test_prediction(review):\n",
        "    \"\"\"Función para probar una predicción individual y ver el proceso\"\"\"\n",
        "    prompt = prompt_template.format(review=review)\n",
        "    response = llm.invoke(prompt)\n",
        "    print(\"###################### Prompt completo:\")\n",
        "    print(prompt)\n",
        "    print(\"###################### Respuesta del modelo:\")\n",
        "    print(response)\n",
        "\n",
        "test_prediction(\"Este producto superó todas mis expectativas, es increíble!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803gOHGtgc1r",
        "outputId": "bbd4459b-294f-45a3-ec6d-d6b9ed8b9a3b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### Prompt completo:\n",
            "Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
            "Responde ÚNICAMENTE con una de las tres palabras y no digas nadas más.\n",
            "\n",
            "RESEÑA: Este producto superó todas mis expectativas, es increíble!\n",
            "\n",
            "CLASIFICACIÓN:\n",
            "###################### Respuesta del modelo:\n",
            " POSITIVO | 100%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Evaluación"
      ],
      "metadata": {
        "id": "JRfCGEUSdtFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un conjunto de datos de prueba\n",
        "test_data = [\n",
        "    {\"review\": \"Este producto superó todas mis expectativas, es increíble!\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"No funciona como esperaba, me decepcionó mucho.\", \"sentiment\": \"negativo\"},\n",
        "    {\"review\": \"Es un producto normal, cumple su función básica.\", \"sentiment\": \"neutral\"},\n",
        "    {\"review\": \"Excelente calidad y el servicio al cliente es fantástico.\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"Terrible experiencia, no lo recomiendo en absoluto.\", \"sentiment\": \"negativo\"}\n",
        "]\n",
        "\n",
        "# Función para evaluar múltiples predicciones\n",
        "def evaluate_predictions(test_data):\n",
        "    \"\"\"Evalúa el modelo con un conjunto de datos de prueba\"\"\"\n",
        "    print(\"Evaluando predicciones...\\n\")\n",
        "\n",
        "    # Para almacenar resultados\n",
        "    results = []\n",
        "\n",
        "    for item in test_data:\n",
        "        # Obtener predicción\n",
        "        response = llm.invoke(prompt_template.format(review=item[\"review\"]))\n",
        "\n",
        "        # Almacenar resultados\n",
        "        results.append({\n",
        "            \"review\": item[\"review\"],\n",
        "            \"expected\": item[\"sentiment\"],\n",
        "            \"predicted\": response.strip().lower(),\n",
        "            \"is_correct\": response.strip().lower() == item[\"sentiment\"]\n",
        "        })\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"Resultados detallados:\")\n",
        "    print(\"=\" * 80)\n",
        "    for r in results:\n",
        "        print(f\"\\nReseña: '{r['review']}'\")\n",
        "        print(f\"Esperado: '{r['expected']}'\")\n",
        "        print(f\"Predicho: '{r['predicted']}'\")\n",
        "        print(f\"Correcto: {'✓' if r['is_correct'] else '✗'}\")\n",
        "\n",
        "    # Calcular accuracy\n",
        "    accuracy = sum(r['is_correct'] for r in results) / len(results)\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"\\nPrecisión total: {accuracy:.2%}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecutar evaluación\n",
        "results = evaluate_predictions(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QiwD7vYdu4y",
        "outputId": "620ab41b-7975-480d-a8f0-ce0364a4d4f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando predicciones...\n",
            "\n",
            "Resultados detallados:\n",
            "================================================================================\n",
            "\n",
            "Reseña: 'Este producto superó todas mis expectativas, es increíble!'\n",
            "Esperado: 'positivo'\n",
            "Predicho: 'positivo (3)\n",
            "\n",
            "rese'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'No funciona como esperaba, me decepcionó mucho.'\n",
            "Esperado: 'negativo'\n",
            "Predicho: 'positivo\n",
            "\n",
            "reseña: n'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Es un producto normal, cumple su función básica.'\n",
            "Esperado: 'neutral'\n",
            "Predicho: 'positiva\n",
            "\n",
            "<|user|>\n",
            "can'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Excelente calidad y el servicio al cliente es fantástico.'\n",
            "Esperado: 'positivo'\n",
            "Predicho: 'positiva, positiva'\n",
            "Correcto: ✗\n",
            "\n",
            "Reseña: 'Terrible experiencia, no lo recomiendo en absoluto.'\n",
            "Esperado: 'negativo'\n",
            "Predicho: 'positiva\n",
            "la sensibilidad'\n",
            "Correcto: ✗\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Precisión total: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Ejercicios Propuestos:\n",
        "\n",
        "1. Experimenta con diferentes prompts y analiza cómo afecta al rendimiento\n",
        "2. Prueba con otros modelos base de Hugging Face\n",
        "3. Añade más ejemplos al conjunto de prueba\n",
        "4. Analiza qué tipos de reseñas son más difíciles para el modelo\n",
        "5. Compara el rendimiento con diferentes longitudes de reseñas"
      ],
      "metadata": {
        "id": "vPB_Q9xgeEw-"
      }
    }
  ]
}