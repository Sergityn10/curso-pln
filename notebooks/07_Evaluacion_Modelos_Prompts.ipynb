{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq/CwAm2hOr315XBE5NLbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/07_Evaluacion_Modelos_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de Modelos basados en Prompts usando LangChain"
      ],
      "metadata": {
        "id": "6G76N3A_cK-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Importación de librerías"
      ],
      "metadata": {
        "id": "sRVXjRoZcQJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtBz4B3cHgL",
        "outputId": "8c642739-6c2d-4a8a-d17b-5386fc686c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.27.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.28)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Configuración del modelo base\n",
        "\n",
        "Usaremos un modelo base de lenguaje general"
      ],
      "metadata": {
        "id": "1hhxdRr5clhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Modelo pequeño para pruebas\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6tk491cqX7",
        "outputId": "080225f1-b350-45d2-d745-d198979f02ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un pipeline de generación de texto"
      ],
      "metadata": {
        "id": "U9Bs6qk6lWLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    truncation=True,\n",
        "    do_sample=True,\n",
        "    return_full_text=True,\n",
        "    temperature=0.9,\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "# Configurar modelo en LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPpOPhDlYru",
        "outputId": "e63756f3-b76f-4b88-cb35-bede4e242ddc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "<ipython-input-3-eeb527a515d4>:14: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=text_pipeline)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Prompt Template"
      ],
      "metadata": {
        "id": "_MhZIGercyiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"review\"],\n",
        "    template=\"\"\"Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
        "\n",
        "RESEÑA: {review}\n",
        "\n",
        "CLASIFICACIÓN:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "QxLta3Scc32n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Función de predicción"
      ],
      "metadata": {
        "id": "PAQ9JXitc99q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos añadir una función de prueba para verificar\n",
        "def test_prediction(review):\n",
        "    \"\"\"Función para probar una predicción individual y ver el proceso\"\"\"\n",
        "    prompt = prompt_template.format(review=review)\n",
        "    response = llm.invoke(prompt)\n",
        "    print(\"###################### Prompt completo:\")\n",
        "    print(prompt)\n",
        "    print(\"###################### Respuesta del modelo:\")\n",
        "    print(response)\n",
        "\n",
        "# Vamos a probarlo\n",
        "test_prediction(\"Este producto superó todas mis expectativas, es increíble!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803gOHGtgc1r",
        "outputId": "4b79ff60-1b6b-4918-c5b1-a41541d34495"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################### Prompt completo:\n",
            "Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
            "\n",
            "RESEÑA: Este producto superó todas mis expectativas, es increíble!\n",
            "\n",
            "CLASIFICACIÓN:\n",
            "###################### Respuesta del modelo:\n",
            "Clasifica el sentimiento de esta reseña como POSITIVO, NEGATIVO o NEUTRAL.\n",
            "\n",
            "RESEÑA: Este producto superó todas mis expectativas, es increíble!\n",
            "\n",
            "CLASIFICACIÓN: POSITIVO\n",
            "\n",
            "Escucha: El nuevo modelo de teléfono está totalmente diseñado, con un diseño delicado (especialmente en el diseño de los lados laterales), muy resistente y que se adapta con facilidad a todos los gustos de quien lleve este producto.\n",
            "\n",
            "CLASIFICACIÓN: POSITIVO\n",
            "\n",
            "Escucha: Esperaba ver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Evaluación"
      ],
      "metadata": {
        "id": "JRfCGEUSdtFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un conjunto de datos de prueba\n",
        "test_data = [\n",
        "    {\"review\": \"Este producto superó todas mis expectativas, es increíble!\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"No funciona como esperaba, me decepcionó mucho.\", \"sentiment\": \"negativo\"},\n",
        "    {\"review\": \"Es un producto normal, cumple su función básica.\", \"sentiment\": \"neutral\"},\n",
        "    {\"review\": \"Excelente calidad y el servicio al cliente es fantástico.\", \"sentiment\": \"positivo\"},\n",
        "    {\"review\": \"Terrible experiencia, no lo recomiendo en absoluto.\", \"sentiment\": \"negativo\"}\n",
        "]\n",
        "\n",
        "# Función para evaluar múltiples predicciones\n",
        "def evaluate_predictions(test_data):\n",
        "    \"\"\"Evalúa el modelo con un conjunto de datos de prueba\"\"\"\n",
        "    print(\"Evaluando predicciones...\\n\")\n",
        "\n",
        "    # Para almacenar resultados\n",
        "    results = []\n",
        "\n",
        "    for item in test_data:\n",
        "        # Obtener predicción\n",
        "        response = llm.invoke(prompt_template.format(review=item[\"review\"]))\n",
        "\n",
        "        # Almacenar resultados\n",
        "        results.append({\n",
        "            \"review\": item[\"review\"],\n",
        "            \"expected\": item[\"sentiment\"],\n",
        "            \"predicted\": response.strip().lower(),\n",
        "            \"is_correct\": response.strip().lower() == item[\"sentiment\"]\n",
        "        })\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(\"Resultados detallados:\")\n",
        "    print(\"=\" * 80)\n",
        "    for r in results:\n",
        "        print(f\"\\nReseña: '{r['review']}'\")\n",
        "        print(f\"Esperado: '{r['expected']}'\")\n",
        "        print(f\"Predicho: '{r['predicted']}'\")\n",
        "        print(f\"Correcto: {'✓' if r['is_correct'] else '✗'}\")\n",
        "\n",
        "    # Calcular accuracy\n",
        "    accuracy = sum(r['is_correct'] for r in results) / len(results)\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"\\nPrecisión total: {accuracy:.2%}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecutar evaluación\n",
        "results = evaluate_predictions(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QiwD7vYdu4y",
        "outputId": "bda820e8-7820-4bac-bc14-5f7fb9312201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando predicciones...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Ejercicios Propuestos:\n",
        "\n",
        "1. Experimenta con diferentes prompts y analiza cómo afecta al rendimiento\n",
        "2. Prueba con otros modelos base de Hugging Face\n",
        "3. Añade más ejemplos al conjunto de prueba\n",
        "4. Analiza qué tipos de reseñas son más difíciles para el modelo\n",
        "5. Compara el rendimiento con diferentes longitudes de reseñas"
      ],
      "metadata": {
        "id": "vPB_Q9xgeEw-"
      }
    }
  ]
}