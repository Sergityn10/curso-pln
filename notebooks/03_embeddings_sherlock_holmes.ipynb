{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMX5EoATrqy2HqIiaUTLRIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/03_embeddings_sherlock_holmes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings de Palabras a partir de libros de Sherlock Holmes\n",
        "\n",
        "\n",
        "# 1) Carga de Datos\n",
        "\n",
        "Carga libros publicados en Project Gutenberg y elimina el header/footer:"
      ],
      "metadata": {
        "id": "pgX4RcCCEzfb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr89zm_uEldQ",
        "outputId": "4e0e5ba9-eb64-4b68-942f-be7bcceb5ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando texto desde: https://www.gutenberg.org/files/1661/1661-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/108/108-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/2097/2097-0.txt ..\n",
            "Cargando texto desde: https://www.gutenberg.org/files/244/244-0.txt ..\n",
            "Texto cargado: 1742150 caracteres\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def load_gutenberg_text(url):\n",
        "    print(\"Cargando texto desde:\", url, \"..\")\n",
        "    response = urllib.request.urlopen(url)\n",
        "    raw = response.read().decode('utf-8')\n",
        "\n",
        "    # Encontrar el inicio y fin del contenido real (eliminar header/footer de Gutenberg)\n",
        "    start = raw.find(\"*** START OF THE PROJECT GUTENBERG\")\n",
        "    start = raw.find(\"\\n\", start) + 1\n",
        "    end = raw.find(\"*** END OF THE PROJECT GUTENBERG\")\n",
        "\n",
        "    return raw[start:end]\n",
        "\n",
        "# URLs de los libros en Project Gutenberg\n",
        "urls = [\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\",    # The Adventures of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/108/108-0.txt\",      # The Return of Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/2097/2097-0.txt\",    # The Hound of the Baskervilles\n",
        "    \"https://www.gutenberg.org/files/244/244-0.txt\"       # A Study in Scarlet\n",
        "]\n",
        "\n",
        "# Carga y guarda el texto\n",
        "text = \" \"\n",
        "for url in urls:\n",
        "  book_text = load_gutenberg_text(url)\n",
        "  text += book_text\n",
        "\n",
        "\n",
        "print(\"Texto cargado:\", len(text), \"caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Preprocesamiento\n",
        "\n",
        "Tokeniza y limpia el texto:\n",
        "* Convierte a minúsculas\n",
        "* Elimina tokens que no son palabras"
      ],
      "metadata": {
        "id": "aEFtcjHpFBD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Inicializar spaCy (solo tokenizador para velocidad)\n",
        "nlp = English(disable=['tagger','parser','ner'])\n",
        "\n",
        "def tokenize(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text.lower() for token in doc\n",
        "            if token.text.strip() and not token.is_punct]\n",
        "\n",
        "# Dividir en oraciones y tokenizar\n",
        "corpus_sentences = []\n",
        "for line in text.split('\\n'):\n",
        "    if line.strip():  # ignorar líneas vacías\n",
        "        tokens = tokenize(line)\n",
        "        if tokens:  # ignorar líneas sin tokens válidos\n",
        "            corpus_sentences.append(tokens)\n",
        "\n",
        "print(\"Total de oraciones procesadas:\", len(corpus_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOY6GToqFB8G",
        "outputId": "841a1b52-e662-4075-d373-9f5ca7d775ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de oraciones procesadas: 27683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Modelo Word2Vec\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAXkjJtYFF0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "WLssPaVaFIOH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1) Entrenamiento"
      ],
      "metadata": {
        "id": "qz6fz_DXFX0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(sentences=corpus_sentences,\n",
        "                    vector_size=300,      # Dimensión del vector (300)\n",
        "                    window=8,             # Ventana más amplia para capturar más contexto (8)\n",
        "                    min_count=2,          # Filtrar palabras poco frecuentes (5)\n",
        "                    workers=4,\n",
        "                    sg=1,                 # Usar Skip-gram\n",
        "                    epochs= 30,           # Más ciclos de entrenamiento\n",
        "                    negative= 15,         # Tamaño de Muestra Negativa (Negative sampling)\n",
        "                    alpha= 0.025,         # Learning rate inicial\n",
        "                    min_alpha= 0.0001     # Learning rate final\n",
        "                  )"
      ],
      "metadata": {
        "id": "-E69AoT3FLt9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar modelos"
      ],
      "metadata": {
        "id": "lUuvM3a_FdVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"sherlock_w2v.model\")"
      ],
      "metadata": {
        "id": "CcwtMCPHFSmx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "Alaz2yIXFV2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar vectores"
      ],
      "metadata": {
        "id": "-Af8SyvvFg24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vectors = w2v_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", w2v_vectors.vector_size)\n",
        "print(\"Número de palabras (Word2Vec):\", len(w2v_vectors.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yLfuYjtFWWr",
        "outputId": "6605c4f5-d7ae-4fd7-da27-c1ba6e2b7233"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas del modelo:\n",
            "Dimensión de los vectores: 300\n",
            "Número de palabras (Word2Vec): 8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyZz7D9DFk5l",
        "outputId": "e2f53f88-b6b3-42a0-8b0b-cc60196b9237"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'holmes' (Word2Vec):\n",
            "[('sherlock', 0.5309870839118958), ('demurely', 0.4677028954029083), ('cheerily', 0.43281084299087524), ('gleefully', 0.4195120930671692), ('approvingly', 0.417387992143631), ('involuntarily', 0.41265785694122314), ('motioning', 0.4117877185344696), ('bungler', 0.40859004855155945), ('yawn', 0.40683627128601074), ('triumphantly', 0.40631672739982605)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(w2v_vectors.most_similar('crime'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLq7S5YvFqXC",
        "outputId": "5d8c25b1-7596-46a6-b5a2-c36b8a9f41af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'crime' (Word2Vec):\n",
            "[('committed', 0.5050350427627563), ('records', 0.4515470266342163), ('literature', 0.44971901178359985), ('talent', 0.4442700147628784), ('featureless', 0.44302573800086975), ('detect', 0.4392315149307251), ('deliberate', 0.4383099377155304), ('perpetrator', 0.42234182357788086), ('insane', 0.42127665877342224), ('sots', 0.42112964391708374)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"Word2Vec:\", w2v_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vPFl2EFsUo",
        "outputId": "f050d1c6-e8db-4059-adb6-697809e0543b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similitud entre 'crime' y 'art':\n",
            "Word2Vec: 0.20315917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3) Palabras fuera de vocabulario"
      ],
      "metadata": {
        "id": "SEwj5kfhFu3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "try:\n",
        "    print(\"Word2Vec - Similares a 'investigador':\")\n",
        "    print(w2v_vectors.most_similar('investigador'))\n",
        "except KeyError:\n",
        "    print(\"Word2Vec no puede manejar palabras fuera de vocabulario\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMxXTQUQFwvo",
        "outputId": "2551849b-2389-43b4-ce99-3fc877d1a0ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prueba con palabra fuera de vocabulario:\n",
            "Word2Vec - Similares a 'investigador':\n",
            "Word2Vec no puede manejar palabras fuera de vocabulario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4) Analogías"
      ],
      "metadata": {
        "id": "G-wbbEIyF5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAnalogías (Word2Vec):\")\n",
        "result = w2v_vectors.most_similar(positive=['watson', 'crime'],\n",
        "                                negative=['holmes'])\n",
        "print(\"watson:holmes como crime:?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmtgbjYoF3La",
        "outputId": "803ad445-b7a7-4465-9b01-aa242bb2fc3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analogías (Word2Vec):\n",
            "holmes:police como crime:?\n",
            "[('comparison', 0.3013310730457306), ('contemplation', 0.2806171774864197), ('composition', 0.27662739157676697), ('reliable', 0.2758445143699646), ('unique', 0.2752229869365692), ('annals', 0.27064117789268494), ('inference', 0.27038633823394775), ('capable', 0.26961779594421387), ('exploit', 0.2694958746433258), ('presuming', 0.2685224115848541)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) Modelo FastText\n"
      ],
      "metadata": {
        "id": "bBvI1CQgQGLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText"
      ],
      "metadata": {
        "id": "hDk90MunQU2U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1) Entrenamiento"
      ],
      "metadata": {
        "id": "xGyf8y68QhID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = FastText(sentences=corpus_sentences,\n",
        "                   vector_size=300,    # Aumentar dimensionalidad (300)\n",
        "                   window=8,           # Ventana más amplia para capturar más contexto (8)\n",
        "                   min_count=2,        # Mantener min_count bajo para capturar más variantes\n",
        "                   workers=4,\n",
        "                   sg=1,               # Skip-gram para mejor calidad\n",
        "                   min_n=2,            # Tamaño mínimo de n-gramas\n",
        "                   max_n=6,            # Tamaño máximo de n-gramas (aumentado para capturar más patrones)\n",
        "                   epochs=30,          # Más ciclos de entrenamiento (30)\n",
        "                   word_ngrams=1,      # Habilitar n-gramas de palabras\n",
        "                   negative=15,        # Más muestras negativas\n",
        "                   alpha=0.025,        # Learning rate inicial\n",
        "                   min_alpha=0.0001    # Learning rate final\n",
        "              )"
      ],
      "metadata": {
        "id": "qHLPLzC6FNtk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almacenamiento del modelo:"
      ],
      "metadata": {
        "id": "WrD-xvupRPYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save(\"sherlock_ft.model\")"
      ],
      "metadata": {
        "id": "3xwAe7HORRGD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2) Análisis de Similitudes"
      ],
      "metadata": {
        "id": "PjIe1rgrRfB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_vectors = ft_model.wv\n",
        "\n",
        "print(\"\\nEstadísticas del modelo:\")\n",
        "print(\"Dimensión de los vectores:\", ft_vectors.vector_size)\n",
        "print(\"Número de palabras (FastText):\", len(ft_vectors.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWm-jwakRhXM",
        "outputId": "12582cfa-3697-408b-fe42-ae5e2904815f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estadísticas del modelo:\n",
            "Dimensión de los vectores: 300\n",
            "Número de palabras (FastText): 8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'holmes' (FastText):\")\n",
        "print(ft_vectors.most_similar('holmes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqOEszGBSJfF",
        "outputId": "32a676af-5e05-43dd-cf5a-711d2d47a9ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'holmes' (FastText):\n",
            "[('holes', 0.48983535170555115), ('sherlock', 0.4753073453903198), ('soames', 0.4750997722148895), ('holborn', 0.431216299533844), ('holds', 0.4205917418003082), ('hold', 0.41582241654396057), ('holiday', 0.4053857922554016), ('holy', 0.4050311744213104), ('volumes', 0.3983922302722931), ('wolf', 0.3976997137069702)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPalabras más similares a 'crime' (Word2Vec):\")\n",
        "print(ft_vectors.most_similar('crime'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi21tk9tSP4m",
        "outputId": "9b454055-b4ac-4156-f8d0-de09b09d1637"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabras más similares a 'crime' (Word2Vec):\n",
            "[('crimes', 0.7936595678329468), ('crib', 0.632940411567688), ('criticism', 0.6317828297615051), ('criminal', 0.6295538544654846), ('criminals', 0.6158126592636108), ('grime', 0.6145389676094055), ('crimson', 0.5981522798538208), ('prime', 0.5892316699028015), ('cripple', 0.5829601287841797), ('crisis', 0.5707933902740479)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSimilitud entre 'crime' y 'art':\")\n",
        "print(\"FastText:\", ft_vectors.similarity('crime', 'art'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83OuWC6SVS_",
        "outputId": "2bd208a9-dc02-4752-b407-a363f1ddcd39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similitud entre 'crime' y 'art':\n",
            "FastText: 0.041709002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.3) Palabras fuera del vocabulario"
      ],
      "metadata": {
        "id": "kH2SCcT3SiAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrueba con palabra fuera de vocabulario:\")\n",
        "\n",
        "print(\"\\nFastText - Similares a 'investigador':\")\n",
        "print(ft_vectors.most_similar('investigador'))  # FastText puede generar vectores para palabras nuevas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNaWVvPMSkfd",
        "outputId": "7c7599e4-aed6-4b39-e223-497e3188acc7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prueba con palabra fuera de vocabulario:\n",
            "\n",
            "FastText - Similares a 'investigador':\n",
            "[('investigate', 0.9281193614006042), ('investigated', 0.9096882343292236), ('investigating', 0.9091376066207886), ('investigations', 0.8724058866500854), ('investigation', 0.868501603603363), ('invest', 0.8680830001831055), ('investments', 0.76113361120224), ('testimonial', 0.6011866927146912), ('domestic', 0.5770685076713562), ('zest', 0.5431040525436401)]\n"
          ]
        }
      ]
    }
  ]
}