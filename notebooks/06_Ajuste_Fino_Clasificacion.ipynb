{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNzp9UqNxsAmowD9zLkalzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "064c7774d93546d8921c9aaad73fecb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20c0d490e08342dcaf02c9164c5860fd",
              "IPY_MODEL_223f0ff788a14140bcd5faf8198c9c28",
              "IPY_MODEL_7aef343138fc480a959a14ee10e88691"
            ],
            "layout": "IPY_MODEL_4d4ac579d1434f98b0987e6a93b2fb1a"
          }
        },
        "20c0d490e08342dcaf02c9164c5860fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_268c194107a94797b31da806d588fc33",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff81761142a480e9a3fa1a2cd7e16f6",
            "value": "Map: 100%"
          }
        },
        "223f0ff788a14140bcd5faf8198c9c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784cce305db24bf6bbcae70c348059a1",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0dedd2d2ceb48909105858990387510",
            "value": 1000
          }
        },
        "7aef343138fc480a959a14ee10e88691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9ae5a61c634bf3bd3142110d20ec4e",
            "placeholder": "​",
            "style": "IPY_MODEL_f26434819bd745fab6f5e2eaaac07dad",
            "value": " 1000/1000 [00:00&lt;00:00, 1098.24 examples/s]"
          }
        },
        "4d4ac579d1434f98b0987e6a93b2fb1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268c194107a94797b31da806d588fc33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff81761142a480e9a3fa1a2cd7e16f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "784cce305db24bf6bbcae70c348059a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dedd2d2ceb48909105858990387510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca9ae5a61c634bf3bd3142110d20ec4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26434819bd745fab6f5e2eaaac07dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/06_Ajuste_Fino_Clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste Fino (Fine-Tuning) para Clasificación de Texto\n",
        "Este notebook complementa las diapositivas del curso mostrando un ejemplo práctico de cómo realizar ajuste fino de un modelo preentrenado para una tarea de clasificación de texto.\n"
      ],
      "metadata": {
        "id": "-Qd_tvBYChbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Configuración del Entorno\n",
        "\n",
        "Primero instalamos las bibliotecas necesarias:"
      ],
      "metadata": {
        "id": "3HmcNg56ClWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yHxd3GYCejM",
        "outputId": "bb48c419-9904-4cff-9eba-9019ce6e856b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las bibliotecas que vamos a utilizar:"
      ],
      "metadata": {
        "id": "ZG0-qNpyCq7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1Yro1YVrCuIV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Carga de Datos\n",
        "\n",
        "Para este ejemplo, usaremos el dataset IMDB para análisis de sentimientos, que es público y fácilmente accesible:\n"
      ],
      "metadata": {
        "id": "IINqlt9mCwb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar ejemplos negativos y positivos por separado\n",
        "negative_examples = load_dataset(\"imdb\", split=\"train[:500]\")  # 500 negativos\n",
        "positive_examples = load_dataset(\"imdb\", split=\"train[12500:13000]\")  # 500 positivos\n",
        "\n",
        "# Combinar los datasets\n",
        "balanced_dataset = concatenate_datasets([negative_examples, positive_examples])\n",
        "\n",
        "# Verificar la distribución de clases\n",
        "print(\"\\nDistribución de clases en los datos balanceados:\")\n",
        "labels = balanced_dataset['label']\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos ({count/len(labels)*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZFO8vAmC0ce",
        "outputId": "8d703085-f806-40bd-d054-941fb5b8aba7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribución de clases en los datos balanceados:\n",
            "Clase 0 (Negativo): 500 ejemplos (50.00%)\n",
            "Clase 1 (Positivo): 500 ejemplos (50.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Preparación del Modelo Base\n",
        "\n",
        "Utilizaremos un modelo BERT básico como punto de partida:"
      ],
      "metadata": {
        "id": "xEEJjLfBDMlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo base y el tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SCMWlzADTdW",
        "outputId": "7923b75e-f44d-47c5-b0d4-a0b17023896c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Preparación de los Datos\n",
        "\n",
        "Tokenizamos los textos y los preparamos para el entrenamiento:"
      ],
      "metadata": {
        "id": "XN29sub_DWXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                    padding=\"max_length\",\n",
        "                    truncation=True,\n",
        "                    max_length=512)\n",
        "\n",
        "print(\"\\nTokenizando datos...\")\n",
        "tokenized_dataset = balanced_dataset.map(tokenize_function, batched=True)\n",
        "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "064c7774d93546d8921c9aaad73fecb0",
            "20c0d490e08342dcaf02c9164c5860fd",
            "223f0ff788a14140bcd5faf8198c9c28",
            "7aef343138fc480a959a14ee10e88691",
            "4d4ac579d1434f98b0987e6a93b2fb1a",
            "268c194107a94797b31da806d588fc33",
            "9ff81761142a480e9a3fa1a2cd7e16f6",
            "784cce305db24bf6bbcae70c348059a1",
            "d0dedd2d2ceb48909105858990387510",
            "ca9ae5a61c634bf3bd3142110d20ec4e",
            "f26434819bd745fab6f5e2eaaac07dad"
          ]
        },
        "id": "rDADvpzxDarx",
        "outputId": "44d108aa-664b-4d16-a2bf-d9ec6c2d665a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizando datos...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "064c7774d93546d8921c9aaad73fecb0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar la distribución en los conjuntos de train y test"
      ],
      "metadata": {
        "id": "QVs5ivWRNbSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribución en conjunto de entrenamiento:\")\n",
        "train_labels = train_test[\"train\"]['label']\n",
        "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos\")\n",
        "\n",
        "print(\"\\nDistribución en conjunto de test:\")\n",
        "test_labels = train_test[\"test\"]['label']\n",
        "unique_labels, counts = np.unique(test_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Clase {label} ({'Negativo' if label == 0 else 'Positivo'}): {count} ejemplos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGsqm1ANcur",
        "outputId": "c2437379-6959-4481-e9f8-479b98201cbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribución en conjunto de entrenamiento:\n",
            "Clase 0 (Negativo): 404 ejemplos\n",
            "Clase 1 (Positivo): 396 ejemplos\n",
            "\n",
            "Distribución en conjunto de test:\n",
            "Clase 0 (Negativo): 96 ejemplos\n",
            "Clase 1 (Positivo): 104 ejemplos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Configuración del Entrenamiento\n",
        "\n",
        "Definimos los parámetros para el ajuste fino:"
      ],
      "metadata": {
        "id": "R92p7LXqDdZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=5,                  # Aumentado número de épocas\n",
        "    per_device_train_batch_size=8,       # Reducido para mejor generalización\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.005,                  # Reducido weight decay\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",         # Evaluar más frecuentemente\n",
        "    eval_steps=50,                       # Evaluar cada 50 pasos\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    learning_rate=5e-5,                  # Aumentado learning rate\n",
        "    warmup_ratio=0.1,                    # Añadido warmup\n",
        "    gradient_accumulation_steps=4,       # Añadido gradient accumulation\n",
        "    metric_for_best_model=\"f1\",          # Usar F1 para seleccionar mejor modelo\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ETR9f6Dgvc",
        "outputId": "84f7e706-7e66-42ed-a37c-f498e9ff403c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir métricas"
      ],
      "metadata": {
        "id": "ze3fdIzhNnNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5tDdj3aCNo1T"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Entrenamiento del Modelo\n",
        "\n",
        "Realizamos el ajuste fino:"
      ],
      "metadata": {
        "id": "20I8PPdIDjTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIniciando entrenamiento...\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test[\"train\"],\n",
        "    eval_dataset=train_test[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando el modelo...\")\n",
        "train_result = trainer.train()\n",
        "print(\"\\nResultados del entrenamiento:\")\n",
        "print(train_result.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "EUqiqdc0Dmej",
        "outputId": "1cbc6b78-feef-40fd-c28a-009c0dfc5f87"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando entrenamiento...\n",
            "\n",
            "Entrenando el modelo...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 07:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.594800</td>\n",
              "      <td>0.545886</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.767773</td>\n",
              "      <td>0.757009</td>\n",
              "      <td>0.778846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.341300</td>\n",
              "      <td>0.512044</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.740385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados del entrenamiento:\n",
            "{'train_runtime': 481.535, 'train_samples_per_second': 8.307, 'train_steps_per_second': 0.26, 'total_flos': 1052444221440000.0, 'train_loss': 2.774471736907959, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Evaluación y Uso del Modelo\n",
        "\n",
        "Función de predicción"
      ],
      "metadata": {
        "id": "N2RppKjKD8Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, threshold=0.6):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocesar el texto similar al entrenamiento\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Realizar múltiples forward passes con dropout activo\n",
        "    model.train()  # Activar dropout\n",
        "    n_forwards = 5\n",
        "    all_probs = []\n",
        "\n",
        "    for _ in range(n_forwards):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            all_probs.append(probs)\n",
        "\n",
        "    # Promediar las probabilidades\n",
        "    avg_probs = torch.mean(torch.stack(all_probs), dim=0)\n",
        "    neg_prob = avg_probs[0][0].item()\n",
        "    pos_prob = avg_probs[0][1].item()\n",
        "\n",
        "    print(f\"\\nProbabilidades (promediadas sobre {n_forwards} pases):\")\n",
        "    print(f\"  Negativo: {neg_prob:.4f}\")\n",
        "    print(f\"  Positivo: {pos_prob:.4f}\")\n",
        "\n",
        "    # Usar un umbral más conservador\n",
        "    if pos_prob > threshold:\n",
        "        return \"Positivo\", pos_prob\n",
        "    elif neg_prob > threshold:\n",
        "        return \"Negativo\", neg_prob\n",
        "    else:\n",
        "        # Si no estamos seguros, basarnos en la mayor probabilidad\n",
        "        return \"Positivo\" if pos_prob > neg_prob else \"Negativo\", max(neg_prob, pos_prob)"
      ],
      "metadata": {
        "id": "viEtKW2sNw_5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos el modelo con algunos ejemplos:"
      ],
      "metadata": {
        "id": "MIwqK8F4NyuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nProbando el modelo con ejemplos:\")\n",
        "ejemplos = [\n",
        "    \"This movie was absolutely fantastic! Great acting and amazing plot.\",\n",
        "    \"Terrible waste of time. The story made no sense and the acting was awful.\",\n",
        "    \"It was okay, not great but not terrible either. Somewhat entertaining.\"\n",
        "]\n",
        "\n",
        "print(\"\\nPredicciones:\")\n",
        "print(\"-\" * 60)\n",
        "for texto in ejemplos:\n",
        "    print(f\"Texto: {texto}\")\n",
        "    sentiment, conf = predict_sentiment(texto)\n",
        "    print(f\"Predicción: {sentiment} (Confianza: {conf:.4f})\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Verificar algunos ejemplos del dataset\n",
        "print(\"\\nEjemplos del dataset:\")\n",
        "for i in range(5):\n",
        "    print(f\"\\nTexto {i+1}: {balanced_dataset[i]['text'][:200]}...\")\n",
        "    print(f\"Etiqueta: {'Positivo' if balanced_dataset[i]['label'] == 1 else 'Negativo'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI_VZnnJD9tG",
        "outputId": "10454db2-9b92-4dae-f56b-cc3dd1cbd876"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando el modelo con ejemplos:\n",
            "\n",
            "Predicciones:\n",
            "------------------------------------------------------------\n",
            "Texto: This movie was absolutely fantastic! Great acting and amazing plot.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.0519\n",
            "  Positivo: 0.9481\n",
            "Predicción: Positivo (Confianza: 0.9481)\n",
            "------------------------------------------------------------\n",
            "Texto: Terrible waste of time. The story made no sense and the acting was awful.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.8970\n",
            "  Positivo: 0.1030\n",
            "Predicción: Negativo (Confianza: 0.8970)\n",
            "------------------------------------------------------------\n",
            "Texto: It was okay, not great but not terrible either. Somewhat entertaining.\n",
            "\n",
            "Probabilidades (promediadas sobre 5 pases):\n",
            "  Negativo: 0.7457\n",
            "  Positivo: 0.2543\n",
            "Predicción: Negativo (Confianza: 0.7457)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Ejemplos del dataset:\n",
            "\n",
            "Texto 1: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 2: \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that ...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 3: If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches ...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 4: This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impre...\n",
            "Etiqueta: Negativo\n",
            "\n",
            "Texto 5: Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoke...\n",
            "Etiqueta: Negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Conclusiones y Notas Importantes\n",
        "\n",
        "En este notebook hemos visto:\n",
        "1. Cómo cargar un modelo preentrenado\n",
        "2. Cómo preparar datos para ajuste fino\n",
        "3. Cómo configurar y realizar el entrenamiento\n",
        "4. Cómo evaluar y usar el modelo ajustado\n",
        "\n",
        "Consideraciones importantes:\n",
        "- Este es un ejemplo simplificado para fines didácticos\n",
        "- En un caso real, se recomienda:\n",
        "  - Usar más datos de entrenamiento\n",
        "  - Realizar una validación cruzada\n",
        "  - Ajustar hiperparámetros\n",
        "  - Implementar técnicas de regularización más robustas\n",
        "  - Considerar el balance de clases\n",
        "\n",
        "Para adaptar este código a otros problemas de clasificación, puedes modificar:\n",
        "- El modelo base (según el idioma y dominio)\n",
        "- Los datos de entrenamiento\n",
        "- El número de clases (num_labels)\n",
        "- Los hiperparámetros de entrenamiento"
      ],
      "metadata": {
        "id": "DgrUSYKdEBZN"
      }
    }
  ]
}