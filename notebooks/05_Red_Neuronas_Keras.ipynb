{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uKIAnsfq1NI1",
        "9eF3klQ1_CJs",
        "FqFNGkltUqgI",
        "Svk5lnmsbGKa",
        "Bi1hcyBabgfS",
        "62bZMg-Xex-f",
        "7us5buCmfn6m",
        "yrnDqgOnfu8x"
      ],
      "authorship_tag": "ABX9TyOfhvoUNStAEacdMBWamFRz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/curso-pln/blob/main/notebooks/05_Red_Neuronas_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción a Redes Neuronales con Keras\n",
        "\n",
        "Este notebook está diseñado para demostrar cómo construir y entrenar un modelo simple de red neuronal utilizando la biblioteca Keras en TensorFlow. Usaremos un conjunto de datos muy básico de frases en español para clasificar su sentimiento como positivo o negativo."
      ],
      "metadata": {
        "id": "g2CjjYTFS51k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1) Cargamos y preparamos los datos\n",
        "\n",
        "El conjunto de datos consiste en frases etiquetadas manualmente para simplificar el uso y la comprensión. Las frases son las siguientes:\n",
        "\n",
        "- \"Me gusta mucho este curso.\" -> Positivo   \n",
        "- \"Estoy aburrido de la rutina diaria.\" -> Negativo   \n",
        "- \"El clima hoy es maravilloso.\" -> Positivo   \n",
        "- \"No estoy satisfecho con el servicio.\" -> Negativo  "
      ],
      "metadata": {
        "id": "vwxqVmFiTAxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1gQIfmP4S3Dv"
      },
      "outputs": [],
      "source": [
        "# Example sentences and their labels\n",
        "sentences = ['Me gusta mucho este curso',\n",
        "             'Estoy aburrido de la rutina diaria',\n",
        "             'El clima hoy es maravilloso',\n",
        "             'No estoy satisfecho con el servicio']\n",
        "labels = [1, 0, 1, 0]  # 1: Positivo, 0: Negativo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformamos el texto en números mediante la técnica ** one-hot encoding** que convierte un texto en una lista de índices enteros, donde cada entero representa una palabra en el texto, codificada mediante una técnica simple de hashing"
      ],
      "metadata": {
        "id": "mPN58_IvgOj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "text = \"hello world\"\n",
        "vocab_size = 10000\n",
        "\n",
        "# Codificar el texto\n",
        "result = one_hot(text, vocab_size)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_XG0wTXgTOd",
        "outputId": "4aca49d0-0579-4dd4-c85f-15b96c2059a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6310, 296]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos también que estandarizar la longitud de las secuencias de texto (en este caso, los índices enteros que representan palabras) para que todas tengan el mismo tamaño. Este paso es necesario para entrenar la mayoría de los modelos de aprendizaje profundo, especialmente aquellos que involucran capas que esperan un tamaño de entrada fijo:"
      ],
      "metadata": {
        "id": "uJ0Ypcwtg-hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences = [[1, 3, 5], [7, 9], [10, 20, 30, 40, 50]]"
      ],
      "metadata": {
        "id": "Sq8fL1FIhNhx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_sentences = pad_sequences(encoded_sentences, maxlen=10, padding='post')\n",
        "print(padded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZNZNM1rhWmz",
        "outputId": "1673f4ce-d3e6-4c57-aea8-78e0af1c5ac8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  3  5  0  0  0  0  0  0  0]\n",
            " [ 7  9  0  0  0  0  0  0  0  0]\n",
            " [10 20 30 40 50  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación preparamos los datos de entrenamiento para tener representaciones numéricas del mismo tamaño:"
      ],
      "metadata": {
        "id": "iqm2izdNeroA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"es_core_news_sm\")\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Cargar el modelo de español de Spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "def prepare(corpus, vocab_size=50, max_length=10):\n",
        "    encoded_sentences = []\n",
        "    # Crear un diccionario para mapear tokens a índices\n",
        "    token_to_index = {}\n",
        "    current_index = 0\n",
        "\n",
        "    # Primera pasada para construir vocabulario\n",
        "    for sentence in corpus:\n",
        "        doc = nlp(sentence)\n",
        "        for token in doc:\n",
        "            if token.text not in token_to_index and current_index < vocab_size:\n",
        "                token_to_index[token.text] = current_index\n",
        "                current_index += 1\n",
        "\n",
        "    # Segunda pasada para codificar oraciones\n",
        "    for sentence in corpus:\n",
        "        doc = nlp(sentence)\n",
        "        encoded_sentence = []\n",
        "        for token in doc:\n",
        "            # Si el token está en nuestro vocabulario, usar su índice\n",
        "            if token.text in token_to_index:\n",
        "                encoded_sentence.append(token_to_index[token.text])\n",
        "            # Si no está, usar el índice 0 (desconocido)\n",
        "            else:\n",
        "                encoded_sentence.append(0)\n",
        "        encoded_sentences.append(encoded_sentence)\n",
        "\n",
        "    # Hacer padding de las secuencias\n",
        "    prepared_sentences = pad_sequences(encoded_sentences, maxlen=max_length, padding='post')\n",
        "    print(\"Oraciones procesadas(\",len(prepared_sentences),\"):\")\n",
        "    print(prepared_sentences)\n",
        "    print(\"\\nVocabulario (\",len(token_to_index),\"):\")\n",
        "    print(token_to_index)\n",
        "    return prepared_sentences, token_to_index\n",
        "\n",
        "# Uso\n",
        "vocab_size = 50\n",
        "max_length = 10\n",
        "prepared_sentences, vocabulary = prepare(sentences, vocab_size, max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etSoZOyuevDA",
        "outputId": "2a89a112-de7d-487b-c851-bf06b350b806"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Oraciones procesadas( 4 ):\n",
            "[[ 0  1  2  3  4  0  0  0  0  0]\n",
            " [ 5  6  7  8  9 10  0  0  0  0]\n",
            " [11 12 13 14 15  0  0  0  0  0]\n",
            " [16 17 18 19 20 21  0  0  0  0]]\n",
            "\n",
            "Vocabulario ( 22 ):\n",
            "{'Me': 0, 'gusta': 1, 'mucho': 2, 'este': 3, 'curso': 4, 'Estoy': 5, 'aburrido': 6, 'de': 7, 'la': 8, 'rutina': 9, 'diaria': 10, 'El': 11, 'clima': 12, 'hoy': 13, 'es': 14, 'maravilloso': 15, 'No': 16, 'estoy': 17, 'satisfecho': 18, 'con': 19, 'el': 20, 'servicio': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) Creamos el modelo basado en una red de neuronas\n",
        "\n",
        "A continuación, configuraremos un modelo `Sequential`. Este modelo es una pila lineal de capas. Podemos añadir capas con el método `add` y experimentar con diferentes arquitecturas cambiando el número y tipo de capas o ajustando parámetros como el número de neuronas por capa o las funciones de activación."
      ],
      "metadata": {
        "id": "S87nUOkyTQfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "vector_size = 8\n",
        "model.add(Embedding(vocab_size, vector_size))\n",
        "\n",
        "# Añadir una capa de aplanado (Flatten) para aplanar la entrada, convirtiendo los datos multidimensionales en un vector unidimensional\n",
        "model.add(Flatten())\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(\"Red diseñada correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqhivR3_TcfV",
        "outputId": "5f1b5fb8-8904-44af-e124-73c8a62b32fe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red diseñada correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos el modelo seleccionando:\n",
        "- **optimizador (optimizer)**: encargado de cambiar los atributos de la red neuronal como los pesos y la tasa de aprendizaje para reducir las pérdidas (e.g. 'adam', o 'rmsprop')\n",
        "- **función de pérdida (loss)**: mide como de bien el modelo está haciendo sus predicciones comparadas con los valores reales. El objetivo del entrenamiento es minimizar esta función.\n",
        "- **evaluación (metrics)**:  métricas utilizadas para evaluar el rendimiento del modelo. No se utilizan para entrenar el modelo pero son importantes para analizar cómo está funcionando el modelo."
      ],
      "metadata": {
        "id": "TIsGAambm6Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "GY776Ekum_L-",
        "outputId": "9a840e2b-dd5f-43e2-c8a2-5769d6cd9dc7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Entrenamos el modelo"
      ],
      "metadata": {
        "id": "6OswqP2RTlxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Convertir a NumPy arrays para asegurar compatibilidad y rendimiento\n",
        "prepared_sentences = np.array(prepared_sentences)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(prepared_sentences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfgfTAkLTnbX",
        "outputId": "1c2ffa73-856e-4b88-948d-cbfeee1dac51"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 215ms/step - accuracy: 0.5427 - loss: 0.6872 - val_accuracy: 0.5366 - val_loss: 0.6853\n",
            "Epoch 2/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 412ms/step - accuracy: 0.6199 - loss: 0.6643 - val_accuracy: 0.5610 - val_loss: 0.6958\n",
            "Epoch 3/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 360ms/step - accuracy: 0.6198 - loss: 0.6613 - val_accuracy: 0.5610 - val_loss: 0.6820\n",
            "Epoch 4/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 196ms/step - accuracy: 0.6420 - loss: 0.6411 - val_accuracy: 0.5610 - val_loss: 0.6886\n",
            "Epoch 5/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 362ms/step - accuracy: 0.6287 - loss: 0.6345 - val_accuracy: 0.5610 - val_loss: 0.6923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4) Evaluamos el modelo"
      ],
      "metadata": {
        "id": "jhiV8kubUDJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Conjunto más amplio de frases de prueba\n",
        "test_sentences = [\n",
        "    \"no fui al último concierto pq nadie me quería acompañar\",\n",
        "    \"Envidio de buena manera a los que tienen la oportunidad de ir mañana al estadio\",\n",
        "    \"Se nos está volviendo costumbre del domingo por la noche, ver el episodio anterior de SNL y eso me hace recibir el lunes en un mejor mood\",\n",
        "    \"al final decidí no ir al cine porque estaba cansado\"\n",
        "]\n",
        "\n",
        "# Preparar los datos\n",
        "prepared_test, vocabulary_test = prepare(test_sentences, vocab_size=vocab_size, max_length=max_length)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = model.predict(prepared_test)\n",
        "\n",
        "# Interpretar las predicciones con más detalle\n",
        "print(\"Predicciones detalladas:\")\n",
        "for i, sentence in enumerate(test_sentences):\n",
        "    pred = predictions[i][0]\n",
        "    sentiment = \"Positivo\" if pred > 0.5 else \"Negativo\"\n",
        "    print(f\"\\nTexto: {sentence}\")\n",
        "    print(f\"Predicción numérica: {pred:.4f}\")\n",
        "    print(f\"Sentimiento predicho: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMwRR9XdUFeJ",
        "outputId": "bd668738-2097-400e-f22c-b243f8da6b33"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.6009 - loss: 0.6774\n",
            "Accuracy: 56.10%\n",
            "Oraciones procesadas( 4 ):\n",
            "[[ 0  1  2  3  4  5  6  7  8  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0]\n",
            " [10 11 12 13 14 15 16 17 18 19 11 20 21  2 22  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0]\n",
            " [23 24 25 26 27 28 29 30 18 31 32 33 34 35 36 11 37 38 39  7 40 41 34 42\n",
            "  43 44 45 46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0]\n",
            " [ 2 47 48  0 20  2 49 50 51 52  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0]]\n",
            "\n",
            "Vocabulario ( 53 ):\n",
            "{'no': 0, 'fui': 1, 'al': 2, 'último': 3, 'concierto': 4, 'pq': 5, 'nadie': 6, 'me': 7, 'quería': 8, 'acompañar': 9, 'Envidio': 10, 'de': 11, 'buena': 12, 'manera': 13, 'a': 14, 'los': 15, 'que': 16, 'tienen': 17, 'la': 18, 'oportunidad': 19, 'ir': 20, 'mañana': 21, 'estadio': 22, 'Se': 23, 'nos': 24, 'está': 25, 'volviendo': 26, 'costumbre': 27, 'del': 28, 'domingo': 29, 'por': 30, 'noche': 31, ',': 32, 'ver': 33, 'el': 34, 'episodio': 35, 'anterior': 36, 'SNL': 37, 'y': 38, 'eso': 39, 'hace': 40, 'recibir': 41, 'lunes': 42, 'en': 43, 'un': 44, 'mejor': 45, 'mood': 46, 'final': 47, 'decidí': 48, 'cine': 49, 'porque': 50, 'estaba': 51, 'cansado': 52}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Predicciones detalladas:\n",
            "\n",
            "Texto: no fui al último concierto pq nadie me quería acompañar\n",
            "Predicción numérica: 0.1562\n",
            "Sentimiento predicho: Negativo\n",
            "\n",
            "Texto: Envidio de buena manera a los que tienen la oportunidad de ir mañana al estadio\n",
            "Predicción numérica: 0.1994\n",
            "Sentimiento predicho: Negativo\n",
            "\n",
            "Texto: Se nos está volviendo costumbre del domingo por la noche, ver el episodio anterior de SNL y eso me hace recibir el lunes en un mejor mood\n",
            "Predicción numérica: 0.6420\n",
            "Sentimiento predicho: Positivo\n",
            "\n",
            "Texto: al final decidí no ir al cine porque estaba cansado\n",
            "Predicción numérica: 0.3254\n",
            "Sentimiento predicho: Negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Mejoras"
      ],
      "metadata": {
        "id": "uKIAnsfq1NI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1) Aumentar el conjunto de entrenamiento\n",
        "\n",
        "Probemos con el dataset \"[cardiffnlp/tweet_sentiment_multilingual](https://huggingface.co/datasets/cardiffnlp/tweet_sentiment_multilingual)\" que contiene tweets en varios idiomas, incluido español"
      ],
      "metadata": {
        "id": "9eF3klQ1_CJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fxYUeexnAeGP",
        "outputId": "b0c020cb-48ad-4a35-a892-4411349af023"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Cargar el dataset desde Hugging Face\n",
        "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"spanish\", split='train')\n",
        "\n",
        "# Inspeccionar columnas\n",
        "print(dataset.column_names)\n",
        "\n",
        "# Filtrar datos para solo etiquetas positivas y negativas\n",
        "filtered_data = dataset.filter(lambda x: x['label'] in [0, 2])\n",
        "\n",
        "# Extraer texto y convertir etiquetas a binario\n",
        "labels = [1 if label == 2 else 0 for label in filtered_data['label']]\n",
        "texts = filtered_data['text']\n",
        "vocab_size = 5000\n",
        "max_length = 100\n",
        "prepared_sentences, vocabulary = prepare(texts, vocab_size, max_length)\n",
        "print(f\"Tamaño total del dataset: {len(texts)}\")\n",
        "print(f\"Distribución de etiquetas: Positivos={labels.count(1)}, Negativos={labels.count(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL55fXfjbYLl",
        "outputId": "185f9a6b-fb00-4c57-ac4d-f5ac8147069d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'label']\n",
            "Oraciones procesadas( 1226 ):\n",
            "[[   0    1    2 ...    0    0    0]\n",
            " [  12    4   13 ...    0    0    0]\n",
            " [  16   17   18 ...    0    0    0]\n",
            " ...\n",
            " [  33  315   28 ...    0    0    0]\n",
            " [ 125  431 1534 ...    0    0    0]\n",
            " [  21    0   54 ...    0    0    0]]\n",
            "\n",
            "Vocabulario ( 5000 ):\n",
            "{'estoy': 0, 'hasta': 1, 'el': 2, 'ojete': 3, 'de': 4, 'que': 5, 'me': 6, 'digáis': 7, 'tengo': 8, 'cara': 9, 'mala': 10, 'leche': 11, 'Esto': 12, 'estar': 13, 'feliz': 14, 'mola': 15, 'Ya': 16, 'no': 17, 'es': 18, 'tan': 19, 'divertido': 20, '@user': 21, 'con': 22, 'una': 23, 'pequeña': 24, 'donación': 25, 'hará': 26, 'felices': 27, 'a': 28, 'miles': 29, 'chicas': 30, 'tienen': 31, ' ': 32, '#': 33, 'asociacionmariloli': 34, 'He': 35, 'probado': 36, 'nueva': 37, 'espuma': 38, 'para': 39, 'pelo': 40, 'y': 41, 'sí': 42, 'lo': 43, 'deja': 44, 'más': 45, 'rizado': 46, 'pero': 47, 'se': 48, 'queda': 49, 'como': 50, 'efecto': 51, 'gomina': 52, 'gusta': 53, '.': 54, 'aquí': 55, 'tienes': 56, 'mi': 57, 'bae': 58, 'aka': 59, 'egipcia': 60, 'preciosa': 61, 'esta': 62, 'aprendiendo': 63, 'español': 64, 'Os': 65, 'llevareis': 66, 'bien': 67, 'ya': 68, 'somos': 69, 'dos': 70, ',': 71, 'triste': 72, '2AñosDeLegiónHolk': 73, 'Llevo': 74, 'unos': 75, '8': 76, 'meses': 77, 'Talvez': 78, 'menos': 79, 'o': 80, 'mas': 81, 'sé': 82, 'Me': 83, 'enseñaron': 84, 'demostraron': 85, 'LH': 86, 'algo': 87, 'magico': 88, '🌼': 89, 'severus': 90, 'snape': 91, '-pobresito': 92, '-nunca': 93, 'le': 94, 'odié': 95, 'parecía': 96, 'muy': 97, 'estricto': 98, 'e': 99, 'injusto': 100, 'sabía': 101, 'pasaba': 102, '...': 103, 'Se': 104, 'echa': 105, 'digital': 106, 'art': 107, 'life': 108, '@': 109, 'Escuela': 110, 'Superior': 111, 'Arte': 112, 'Tecnología': 113, '(': 114, 'ESAT': 115, ')': 116, 'http': 117, 'Esta': 118, 'ceniza': 119, 'tiene': 120, 'harta': 121, 'arden': 122, 'los': 123, 'ojos': 124, 'No': 125, 'tampoco': 126, 'soy': 127, 'cursi': 128, 'En': 129, 'fin': 130, 'huevos': 131, 'del': 132, '90%': 133, 'las': 134, 'personas': 135, 'así': 136, '    ': 137, 'está': 138, 'preparando': 139, 'cosillas': 140, 'nuevas': 141, 'jeje': 142, 'Jo': 143, 'yo': 144, 'había': 145, 'ilusionado': 146, 'Hoy': 147, 'toca': 148, 'escuchar': 149, 'MiguelRios': 150, 'otros': 151, 'grandes': 152, 'artistas': 153, 'Insurrección': 154, 'qué': 155, 'tendrá': 156, 'brozas': 157, '..': 158, 'jaajajaja': 159, 'descontrola': 160, 'será': 161, 'la': 162, 'influencia': 163, 'Voy': 164, 'jugar': 165, 'primera': 166, 'ranked': 167, '10': 168, 'Hmm': 169, 'si': 170, 'liaré': 171, 'bronce': 172, 'V': 173, 'espera': 174, 'mañana': 175, 'jugaré': 176, 'poco': 177, 'nada': 178, 'so': 179, 'jugársela': 180, 'Cuando': 181, 'he': 182, 'dicho': 183, 'bollo': 184, 'morena': 185, 'ha': 186, 'reído': 187, 'en': 188, 'Sin': 189, 'duda': 190, 'fue': 191, 'experiencia': 192, 'Y': 193, 'habrá': 194, '!': 195, 'Como': 196, 'les': 197, 're': 198, 'interesa': 199, 'actualizo': 200, ':': 201, 'dijo': 202, 'ver': 203, 'peli': 204, 'habló': 205, 'un': 206, 'pibe': 207, 'dándome': 208, 'entender': 209, 'están': 210, 'saliendo': 211, 'Go-Pro': 212, 'calidad': 213, 'proteccion': 214, 'bajo': 215, 'agua': 216, 'soporte': 217, 'cabeza': 218, '   ': 219, 'porq': 220, 'ago': 221, 'tantas': 222, 'caras': 223, 'OK': 224, 'EN': 225, 'FIN': 226, 'pena': 227, 'muerte': 228, 'bueno': 229, 'Pero': 230, 'diablos': 231, 'podemos': 232, 'hacer': 233, 'violadores': 234, 'Yo': 235, 'veo': 236, 'otra': 237, 'salida': 238, 'Que': 239, 'dicha': 240, 'hay': 241, 'trabajo': 242, 'salud': 243, 'vacaciones': 244, 'también': 245, 'Impresionante': 246, 'Una': 247, 'hoy': 248, 'pueda': 249, 'foto': 250, 'atardecer': 251, 'P.d': 252, 'Gracias': 253, 'guapiño': 254, 'La': 255, 'pulsera': 256, 'tio': 257, 'lamentable': 258, 'tema': 259, 'sensible': 260, 'jamás': 261, 'ese': 262, 'enfoque': 263, 'vaya': 264, 'felicidades': 265, 'atrasadas': 266, 'muchas': 267, 'gracias': 268, 'Otra': 269, 'cosa': 270, 'tuviera': 271, 'seguridad': 272, 'social': 273, 'porqe': 274, 'era': 275, 'obligatorio': 276, 'su': 277, 'situacion': 278, 'Lee': 279, 'libros': 280, 'muerden': 281, 'bonita': 282, 'gente': 283, 'educada': 284, 'gran': 285, 'abrazo': 286, 'vos': 287, '🤗': 288, 'Espanya': 289, 'prensa': 290, 'ni': 291, 'libre': 292, 'independiente': 293, 'muchísimo': 294, 'plural': 295, 'Síntoma': 296, 'nuestra': 297, 'pobre': 298, 'democracia': 299, 'Feliz': 300, 'Navidad': 301, 'Felino': 302, 'Jaja': 303, 'Saludos': 304, 'abrazos': 305, 'familia': 306, 'rompió': 307, 'pantalón': 308, 'horizontalmrnnte': 309, 'por': 310, 'muslo': 311, 'debajo': 312, 'nalga': 313, 'moda': 314, 'FF': 315, 'geniales': 316, 'designar': 317, 'quienes': 318, 'aficionados': 319, 'todos': 320, 'este': 321, 'mundo': 322, 'nippon': 323, 'aunque': 324, 'elicación': 325, 'suene': 326, '\"': 327, 'final': 328, 'mmm': 329, '2': 330, 'Si': 331, 'Eres': 332, 'crush': 333, 'máximo': 334, 'te': 335, 'considere': 336, 'mis': 337, 'mejores': 338, 'amigos': 339, 'Nunca': 340, 'dejes': 341, 'fb': 342, 'abierto': 343, 'tu': 344, 'hermana': 345, 'lado': 346, 'PELIGRO': 347, 'Google': 348, 'luego': 349, 'encarga': 350, 'asociar': 351, 'contenido': 352, 'escrito': 353, 'búsqueda': 354, 'hizo': 355, 'mal': 356, 'escrita': 357, 'Ayay': 358, 'quiero': 359, 'grrabar': 360, 'trocito': 361, 'Drown': 362, 'ukelele': 363, 'porque': 364, 'quedar': 365, 'voz': 366, 'fatal': 367, 'ricoooo': 368, 'abriste': 369, 'apetito': 370, 'Solo': 371, 'Las': 372, 'aceitunas': 373, 'ser': 374, 'negras': 375, 'puta': 376, 'mierda': 377, 'común': 378, 'pues': 379, 'nadie': 380, 'mete': 381, 'ningún': 382, 'grupo': 383, 'claro': 384, 'Bueno': 385, 'algunos(casi': 386, 'gratis': 387, 'confiar': 388, 'mi(un': 389, 'año': 390, 'enfermen': 391, 'mucho': 392, 'jaja': 393, 'mentira': 394, 'saludos': 395, 'pasa': 396, 'puede': 397, 'Twitter': 398, 'WhatsApp': 399, 'vez': 400, '?': 401, 'fiestas': 402, 'igual': 403, 'buenas': 404, 'perdiendo': 405, 'Hace': 406, 'tres': 407, 'días': 408, 'entre': 409, 'pegado': 410, 'segundo': 411, 'clip': 412, '1080': 413, 'desde': 414, 'alto': 415, 'ala': 416, 'caza': 417, 'pasan': 418, 'p': 419, '*': 420, '😢': 421, 'Tengo': 422, 'perrina': 423, 'adorable': 424, 'Sabéis': 425, 'acompaña': 426, 'habitación': 427, 'cuando': 428, 'voy': 429, 'dormir': 430, 'puedo': 431, 'dormida': 432, 'ratito': 433, 'mamá': 434, 'anémica': 435, 'nuevo': 436, 'Con': 437, 'cual': 438, 'todas': 439, 'ventanas': 440, 'conectado': 441, 'móvil': 442, 'altavoces': 443, 'ahora': 444, 'suena': 445, 'mejor': 446, 'Tio': 447, 'entonces': 448, 'piensas': 449, 'mosca': 450, 'insulto': 451, 'creo': 452, 'eso': 453, 'irrespetuoso': 454, 'pobres': 455, 'despierta': 456, 'curiosidad': 457, 'saber': 458, 'cuáles': 459, 'eran': 460, 'esos': 461, 'antiguos': 462, 'nombres': 463, 'lástima': 464, 'bicho': 465, 'grandote': 466, 'sirva': 467, 'sembrar': 468, 'destrucción': 469, 'Sólo': 470, 'Karlita': 471, 'entiende': 472, 'da': 473, 'buenos': 474, 'consejos': 475, 'libro': 476, 'leer': 477, 'serie': 478, 'noches': 479, 'volviendo': 480, 'aburridas': 481, 'Tengamos': 482, 'día': 483, 'lleno': 484, 'magia': 485, 'lindos': 486, 'momentos': 487, 'Después': 488, 'cuatro': 489, 'ermitaña': 490, 'salir': 491, 'al': 492, 'sol': 493, 'fiebre': 494, 'largate': 495, 'Días': 496, 'agradezco': 497, 'tener': 498, 'carro': 499, 'Andar': 500, 'hígado': 501, 'hinchado': 502, 'marchamos': 503, 'ando': 504, 'Uber': 505, 'Difícilmente': 506, 'quiera': 507, 'serio': 508, 'ust': 509, 'todo': 510, 'empezó': 511, 'yaleo': 512, 'nudes': 513, 'respétese': 514, 'verá': 515, 'buscan': 516, 'bonito️': 517, 'Manuel': 518, 'arte': 519, 'recoger': 520, 'texto': 521, 'revista': 522, 'Un': 523, 'grande': 524, 'Quiero': 525, 'comer': 526, 'llena': 527, 'cómo': 528, 'mezclan': 529, 'realidad': 530, 'mundos': 531, 'paralelos': 532, 'diferente': 533, 'demás': 534, 'películas': 535, 'Marvel': 536, 'glowen': 537, 'sigue': 538, 'cuentas': 539, 'inactivas': 540, 'plan': 541, 'oh': 542, 'seguro': 543, 'esas': 544, 'dan': 545, 'apoyo': 546, 'diste': 547, 'unf': 548, 'JAJAJA': 549, 'Gran': 550, 'capacidad': 551, 'análisis': 552, 'esa': 553, 'entrevista': 554, 'visión': 555, 'gustaría': 556, 'arreglar': 557, 'cosas': 558, 'ninguna': 559, 'frustrante': 560, 'SinPelosEnLaLengua': 561, 'Además': 562, 'novia': 563, 'luz': 564, 'buena': 565, 'opináis': 566, 'maricon': 567, 'Atm': 568, '7': 569, 'primeros': 570, 'teams': 571, 'lejos': 572, '3': 573, 'últimos': 574, 'A': 575, 'mejoran': 576, '/': 577, 'cambian': 578, 'sus': 579, 'estrategias': 580, 'etc': 581, 'idk': 582, 'guapísimo': 583, 'dejaron': 584, 'mendizorroza': 585, 'San': 586, 'mames': 587, '+': 588, 'guapos': 589, 'MUNDO': 590, '¡': 591, 'sin': 592, 'duda.(opinión': 593, 'Por': 594, 'payasa': 595, 'debo': 596, 'grupal': 597, 'algunos': 598, 'grupos': 599, 'aún': 600, 'terminan': 601, 'hacerlo': 602, 'horas': 603, '1000/10': 604, 'verdad': 605, 'ti': 606, 'decir': 607, 'petarda': 608, 'mí': 609, 'mismo': 610, '✨': 611, 'ola': 612, 'wapa': 613, 'k': 614, 'tal': 615, 'stas': 616, 'spero': 617, 'seas': 618, 'sorra': 619, 'kmo': 620, 'otras': 621, 'xikas': 622, '  ': 623, '-': 624, 'machirulo': 625, 'QUÉ': 626, 'COJONES': 627, 'JAJSAKJKJSADJJSJASJAJAJA': 628, '¿': 629, 'Será': 630, 'solo': 631, 'Perfecto': 632, 'De': 633, 'muchísimas': 634, 'Costa': 635, 'Rica': 636, 'Pura': 637, 'vida': 638, 'joder': 639, 'entiendo': 640, 'nosotros': 641, 'literalmente': 642, 'nos': 643, 'tenemos': 644, 'saltar': 645, 'clases': 646, 'ir': 647, 'centro': 648, 'comercial': 649, 'queremos': 650, 'kkar': 651, 'Ese': 652, 'aplauso': 653, 'Diego': 654, 'Luna': 655, 'Felicity': 656, 'Jones': 657, 'estruendoso': 658, 'ganas': 659, 'Rogue': 660, 'One': 661, 'Lo': 662, 'quedarse': 663, 'sola': 664, 'casa': 665, 'sonaba': 666, 'planazo': 667, 'domingo': 668, 'doy': 669, 'cuenta': 670, 'dulces': 671, 'cierto': 672, 'encantado': 673, 'conocerte': 674, 'virtualmente': 675, 'Tenemos': 676, 'Saludetes': 677, 'necesito': 678, 'ración': 679, 'atención': 680, 'diaria': 681, 'mantengo': 682, 'autoestima': 683, 'rica': 684, 'incluya': 685, 'modo': 686, 'extra': 687, 'original': 688, 'consola': 689, 'regalaban': 690, 'preorder': 691, 'fuerte': 692, 'son': 693, 'sigo': 694, 'capaz': 695, 'ponerme': 696, 'estudiar': 697, '....': 698, 'sueño': 699, 'conmigo': 700, 'zona': 701, 'entreno': 702, 'escogieron': 703, 'Creo': 704, 'talking': 705, 'to': 706, 'the': 707, 'moon': 708, 'Bruno': 709, 'Mars': 710, 'plof': 711, 'cancion': 712, 'Envidio': 713, 'manera': 714, 'oportunidad': 715, 'estadio': 716, 'MePasóPorPavazo': 717, 'Amigo': 718, 'guapo': 719, 'eres': 720, 'amiga': 721, 'trio': 722, 'ganador': 723, 'pepearon': 724, 'querer': 725, 'han': 726, 'elevado': 727, 'barra': 728, 'seguir': 729, 'preparandome': 730, 'waoooo': 731, 'extraordinario': 732, 'cafe': 733, 'loveyou️️': 734, 'Todos': 735, 'queríamos': 736, 'ticas': 737, 'juntas': 738, 'esto': 739, 'lei': 740, 'q': 741, 'avanza': 742, 'VISSLAISAworldjuniors': 743, 'des': 744, 'Bueeeeno': 745, 'siento': 746, 'playlist': 747, 'cagarme': 748, 'peor': 749, 'orines': 750, 'vi': 751, 'niña': 752, 'patines': 753, 'casco': 754, 'divirtiéndose': 755, 'Plaza': 756, 'Cultura': 757, 'lindo': 758, 'Ahora': 759, 'Abel': 760, 'quien': 761, 'resfriado': 762, 'ke': 763, 'juntos': 764, 'tiempo': 765, 'jajaja': 766, 'curro': 767, 'trabajar': 768, 'mirar': 769, 'par': 770, 'canal': 771, 'irme': 772, 'cine': 773, 'mascotas': 774, 'sabado': 775, 'Hablaba': 776, 'normal': 777, 'alguien': 778, 'antes': 779, 'usted': 780, 'metiera': 781, 'insultando': 782, 'Debería': 783, 'educación': 784, 'has': 785, 'escuchal': 786, '😂': 787, 'enlacabezaNo': 788, 'loSiento': 789, 'volver': 790, 'disfruta': 791, 'pronto': 792, 'él': 793, 'lejano': 794, 'SiNoEstás4días': 795, 'viejita': 796, 'extrañé': 797, 'toda': 798, 'formas': 799, 'gritos': 800, 'desorden': 801, 'sazón': 802, 'comida': 803, 'Mae': 804, 'mayoría': 805, 'busca': 806, 'Claro': 807, 'quería': 808, 'manifiesto': 809, 'cables': 810, 'chinos': 811, 'cojonudos': 812, 'compres': 813, 'barato': 814, 'mío': 815, 'especialmente': 816, 'difícil': 817, 'bro': 818, 'exclusivamente': 819, 'sobre': 820, 'plata': 821, 'u': 822, 'know': 823, 'this': 824, 'l': 825, '2016': 826, 'crecer': 827, 'Ivettly': 828, 'pasar': 829, 'alegría': 830, 'tristeza': 831, 'llenos': 832, 'enseñanzas': 833, 'streamer': 834, 'conseguir': 835, 'seguidores': 836, '-Cam': 837, '-Micro': 838, '-Subir': 839, 'decente': 840, '-Tetas': 841, 'faltan': 842, 'tetas': 843, 'tengas': 844, 'fantástico': 845, 'Caeli': 846, 'Mañana': 847, 'vuelvo': 848, 'después': 849, '15': 850, 'Donde': 851, 'quedan': 852, 'verano': 853, 'pequeños': 854, 'QueDuroEsSerAdulto': 855, 'programa': 856, 'extraña': 857, 'Leto': 858, 'sabran': 859, 'jueces': 860, 'quê': 861, 'honestidad': 862, 'respeto': 863, 'postulaba': 864, 'mercado': 865, 'abastos': 866, '.si': 867, 'Los': 868, 'miércoles': 869, 'quedarme': 870, 'am': 871, 'parece': 872, 'lujo': 873, 'Habrá': 874, 'traer': 875, 'audífonos': 876, 'chamba': 877, 'Estoy': 878, 'muriendo': 879, 'lentamente': 880, 'acaba': 881, 'fiesta': 882, 'últimodíadenavidad': 883, 'bajadadereyes': 884, '…': 885, 'Pobre': 886, 'ilusa': 887, 'pensé': 888, 'haríais': 889, 'caso': 890, 'sensación': 891, 'din': 892, 'os': 893, 'Eu': 894, 'na': 895, 'ofi': 896, 'lendo': 897, 'tampouco': 898, 'teño': 899, 'Triste': 900, 'cambie': 901, 'mujeres': 902, 'política': 903, '30': 904, 'años': 905, 'Tambien': 906, 'buen': 907, 'Fercito': 908, 'linda': 909, 'semana': 910, 'amigo': 911, 'aventuras': 912, 'tías': 913, 'juego': 914, 'mierdas': 915, 'suerte': 916, 'pa': 917, 'jugarmela': 918, 'leído': 919, 'Caerán': 920, 'prontito': 921, 'Vengo': 922, 'Carabanchel': 923, 'biblioteca': 924, 'cerrada': 925, 'Enhorabuena': 926, 'ganadora': 927, 'sorteo': 928, 'escríbenos': 929, 'mensaje': 930, 'privado': 931, 'darte': 932, 'premio': 933, 'Era': 934, '6': 935, 'levantar': 936, '5:15': 937, 'ruido': 938, 'hijueputa': 939, 'licuadora': 940, 'descerebrado': 941, 'primo': 942, 'acabó': 943, 'El': 944, 'Oso': 945, 'Tigre': 946, 'mientras': 947, 'duró': 948, 'Es': 949, 'cuarto': 950, 'sobremesa': 951, 'angustio': 952, 'sabéis': 953, 'vengo': 954, 'sofá': 955, 'portátil': 956, 'ventilador': 957, 'encantaría': 958, 'cámara': 959, 'usarla': 960, 'perfección': 961, 'contrato': 962, '500mbs': 963, 'llevo': 964, 'consumido': 965, 'Gb': 966, 'vea': 967, 'factura': 968, 'tanta': 969, 'risa': 970, 'atenta': 971, 'puntual': 972, 'bienvenida': 973, 'curso': 974, 'online': 975, 'Va': 976, 'placer': 977, 'contigo': 978, 'Quieras': 979, 'vivir': 980, 'rodeada': 981, 'mar': 982, 'influye': 983, 'Paso': 984, 'semanas': 985, 'playa': 986, 'hace': 987, 'falta': 988, 'contenta': 989, 'acabo': 990, 'gustos': 991, 'algún': 992, 'momento': 993, 'transmití': 994, 'banda': 995, 'específica': 996, 'llegado': 997, 'persona': 998, 'echo': 999, 'chicaa': 1000, 'Ey': 1001, 'UnMinutoSinDolor': 1002, 'single': 1003, 'promocional': 1004, 'LaMejorVariedadMusical': 1005, 'Preferiría': 1006, 'discutir': 1007, 'umpalumpa': 1008, 'cristiano': 1009, 'conservador': 1010, 'derecha': 1011, 'pizza': 1012, 'conversación': 1013, 'amena': 1014, 'Amigos': 1015, 'Buena': 1016, 'noche': 1017, 'Massimo': 1018, 'Bottura': 1019, 'América': 1020, 'Está': 1021, 'México': 1022, 'acostada': 1023, 'cama': 1024, 'sufriendoooo': 1025, 'conocerlo': 1026, 'Buenos': 1027, 'Facebook': 1028, 'Volvemos': 1029, 'Granizados': 1030, 'Soy': 1031, 'basura': 1032, 'justo': 1033, 'Andrea': 1034, 'tenía': 1035, 'verme': 1036, 'mujer': 1037, 'sentí': 1038, 'exámenes': 1039, 'viene': 1040, 'jajaxd': 1041, 'Desesperada': 1042, 'trabajaré': 1043, 'cualquier': 1044, 'Blanca': 1045, 'plato': 1046, 'fácil': 1047, 'rico': 1048, 'vistoso': 1049, 'segura': 1050, 'última': 1051, 'Jaime': 1052, 'Saavedra': 1053, 'ministro': 1054, 'Educación': 1055, 'Vamos': 1056, 'perder': 1057, 'Pensé': 1058, 'hacías': 1059, 'compartias': 1060, 'espontáneo': 1061, 'tenías': 1062, 'Follow': 1063, 'you': 1064, 'now': 1065, 'again': 1066, 'digo': 1067, 'mamón': 1068, 'chino': 1069, 'dicen': 1070, 'vulgaridad': 1071, 'confiando': 1072, 'quite': 1073, 'gripe': 1074, 'horrible': 1075, 'Eso': 1076, 'antiguo': 1077, 'Madrid': 1078, 'Aires': 1079, 'Bogotá': 1080, 'sería': 1081, 'hihihihi': 1082, 'Llévales': 1083, 'bibliografía': 1084, 'evidencia': 1085, 'médica': 1086, 'existe': 1087, 'Murcia': 1088, 'persiana': 1089, 'ooops': 1090, 'mata': 1091, 'jajajaja': 1092, 'improvisto': 1093, 'eh': 1094, 'grasias': 1095, 'hermosa': 1096, 'pura': 1097, 'llamé': 1098, 'haber': 1099, 'llamado': 1100, 'actualizacion': 1101, 'F1': 1102, 'Muchos': 1103, 'cambios': 1104, 'mejoras': 1105, 'Movistar': 1106, 'deje': 1107, 'colgado': 1108, 'internet': 1109, 'haberme': 1110, 'ido': 1111, 'Orange': 1112, 'Segunda': 1113, 'sesión': 1114, 'notando': 1115, 'adaptación': 1116, 'Muy': 1117, 'cómodo': 1118, 'ocasiomes': 1119, 'hago': 1120, 'Estos': 1121, 'encuentro': 1122, 'débil': 1123, 'espero': 1124, 'pase': 1125, 'Jajaja': 1126, 'ahí': 1127, 'diferentes': 1128, 'tb': 1129, 'hablar': 1130, 'TonyYSorayaEnMalaga': 1131, 'pff': 1132, 'Cada': 1133, 'qje': 1134, 'mura': 1135, 'rara': 1136, 'estreno': 1137, 'RogueOne': 1138, 'compañía': 1139, 'único': 1140, 'rescatar': 1141, 'TØP': 1142, 'Coldplay': 1143, 'cinco': 1144, 'Qué': 1145, 'pinta': 1146, 'suquet': 1147, 'rape': 1148, 'Porque': 1149, 'primer': 1150, 'semestre': 1151, 'daba': 1152, 'miedo': 1153, 'faltar': 1154, 'abandonas': 1155, 'Pensar': 1156, 'irse': 1157, 'capítulos': 1158, 'minorityreport': 1159, 'alegrarse': 1160, 'dice': 1161, 'escapa': 1162, 'otro': 1163, 'furgón': 1164, 'blindado': 1165, '@salaBBK': 1166, 'Bilbao': 1167, 'QuiqueGonzález': 1168, 'montado': 1169, 'espacio': 1170, 'ella': 1171, 'sobran': 1172, 'huecos': 1173, 'estara': 1174, 'llenita': 1175, 'gastar': 1176, 'comprándome': 1177, 'halloween': 1178, 'compro': 1179, 'mudada': 1180, 'paso': 1181, 'entrada': 1182, '5': 1183, 'mil': 1184, 'interesante': 1185, 'primero': 1186, 'enamoro': 1187, 'macedonio': 1188, 'ibiza': 1189, 'timbales': 1190, 'panorama': 1191, 'taaaaaan': 1192, 'bonito': 1193, 'fe': 1194, 'TEC': 1195, 'sea': 1196, 'masoquista': 1197, 'siempre': 1198, 'haga': 1199, 'lugar': 1200, 'Recuerdo': 1201, 'escribía': 1202, 'motivara': 1203, 'hiciera': 1204, 'sentir': 1205, 'útil': 1206, 'Dios': 1207, 'dio': 1208, 'juegos': 1209, 'Ubisoft': 1210, 'malos': 1211, 'malo': 1212, 'Sony': 1213, 'verla': 1214, 'optimista': 1215, 'Hay': 1216, 'luchar': 1217, 'fuertes': 1218, 'ante': 1219, 'especie': 1220, 'Titanic': 1221, 'versión': 1222, 'cutre': 1223, '20': 1224, 'comí': 1225, 'Chifrijo': 1226, 'Sabía': 1227, 'chicharron': 1228, 'tuviese': 1229, 'pellejo': 1230, 'madre': 1231, 'suicido': 1232, 'encontró': 1233, 'Chelo': 1234, 'muerta': 1235, 'éxito': 1236, 'maratonica': 1237, 'sumé': 1238, 'van': 1239, 'llevar': 1240, 'mucha': 1241, 'sufriendo': 1242, 'enamoré': 1243, 'bruja': 1244, 'veces': 1245, 'tanto': 1246, 'gato': 1247, 'cansino': 1248, 'Recibir': 1249, 'corazón': 1250, 'agradecido': 1251, 'bendición': 1252, 'nuestro': 1253, 'amado': 1254, 'Feliz2017': 1255, 'Ha': 1256, 'muerto': 1257, 'profesora': 1258, 'volumen': 1259, 'escultura': 1260, 'bajonazo': 1261, 'fiel': 1262, 'tío': 1263, 'siquiera': 1264, 'llegué': 1265, 'competiciones': 1266, 'Río': 1267, 'directo': 1268, 'barras': 1269, 'asimétricas': 1270, 'Aliya': 1271, 'genial': 1272, 'vamos': 1273, 'jo': 1274, 'Algo': 1275, 'encontrar': 1276, 'incendio': 1277, 'Villava': 1278, 'cerca': 1279, 'Instituto': 1280, 'seria': 1281, 'quemase': 1282, 'problema': 1283, 'ofertas': 1284, 'ahorita': 1285, 'esque': 1286, 'llegó': 1287, 'mínimo': 1288, 'regalarle': 1289, 'secreto': 1290, 'voa': 1291, 'estafar': 1292, 'habia': 1293, 'puesto': 1294, 'octavo': 1295, 'vuelta': 1296, '4': 1297, 'Tan': 1298, 'desesperado': 1299, 'stalkea': 1300, 'forma': 1301, 'dar': 1302, 'cago': 1303, 'dios': 1304, 'teen': 1305, 'cumpleaños': 1306, 'todavía': 1307, 'librerías': 1308, 'cae': 1309, 'mes': 1310, 'oleada': 1311, 'homófobas': 1312, 'anteriores': 1313, 'chicos': 1314, 'vuestros': 1315, 'fans': 1316, 'estamos': 1317, 'super': 1318, 'orgullosos': 1319, 'sólo': 1320, 'ahh': 1321, 'descanse': 1322, 'pereza': 1323, 'enfado': 1324, 'cariñoso': 1325, 'amor': 1326, 'visto': 1327, 'saludado': 1328, 'dije': 1329, 'ibas': 1330, 'acompañada': 1331, 'lleva': 1332, 'caminos': 1333, 'inextricables': 1334, 'alegro': 1335, 'haya': 1336, 'molado': 1337, 'Mi': 1338, 'imposible': 1339, 'quiere': 1340, 'Europa': 1341, 'pequeñas': 1342, 'esperanzas': 1343, 'sabiendo': 1344, 'regales': 1345, 'capturas': 1346, 'imagen': 1347, 'tus': 1348, 'actividades': 1349, 'sorpresa': 1350, 'sorprendente': 1351, 'inivitado': 1352, 'sano': 1353, 'atras': 1354, 'meo': 1355, 'chula': 1356, 'calor': 1357, 'haciendo': 1358, 'morimos': 1359, 'claros': 1360, 'ticos': 1361, 'solidarios': 1362, 'necesita': 1363, 'Juan': 1364, 'sabes': 1365, 'hetero': 1366, 'hora': 1367, 'media': 1368, 'Heredia': 1369, 'concurso': 1370, 'SoyJustDancer': 1371, 'españa': 1372, 'Bien': 1373, 'contra': 1374, 'tercera': 1375, 'generación': 1376, 'fav': 1377, 'merece': 1378, 'hablando': 1379, 'jodes': 1380, 'K': 1381, 'amistad': 1382, 'dias': 1383, 'recados': 1384, 'empezar': 1385, 'dia': 1386, 'energia': 1387, 'soportas': 1388, 'sevillano': 1389, 'hija': 1390, 'mía': 1391, 'Buen': 1392, 'partido': 1393, 'losers': 1394, 'volvemos': 1395, 'Saludo': 1396, 'casters': 1397, 'casi': 1398, 'fotos': 1399, 'chachis': 1400, 'careto': 1401, 'Pablo': 1402, 'Paula': 1403, 'Aquí': 1404, 'tenéis': 1405, 'verdadero': 1406, 'chic@s': 1407, 'gracioso': 1408, 'diciendo': 1409, 'fomenta': 1410, 'aun': 1411, 'odio': 1412, 'hacia': 1413, 'feminismo': 1414, '👍': 1415, '🏻': 1416, 'caja': 1417, 'tonta': 1418, 'Desde': 1419, 'tele': 1420, 'cunde': 1421, 'Uno': 1422, 'Te': 1423, 'acompaño': 1424, 'feels': 1425, 'Toca': 1426, 'maravilloso': 1427, 'dejar': 1428, 'ficción': 1429, 'podría': 1430, 'darse': 1431, 'Hermano': 1432, 'vol.02': 1433, 'Terminarán': 1434, 'odiándome': 1435, 'padres': 1436, 'conocen': 1437, 'hecho': 1438, 'espléndido': 1439, 'sentidos': 1440, 'Pues': 1441, 'tuvo': 1442, 'pijama': 1443, 'pq': 1444, 'últimamente': 1445, 'uso': 1446, 'vestidos': 1447, 'largos': 1448, 'ronchón': 1449, 'considerable': 1450, 'amo': 1451, 'fanart': 1452, 'roe': 1453, 'deer': 1454, 'Menciono': 1455, 'Sofía': 1456, 'bonitas': 1457, 'paga': 1458, 'bloqueandome': 1459, 'wa': 1460, 'primito': 1461, 'haré': 1462, 'presente': 1463, 'Estás': 1464, 'invitado': 1465, 'puedes': 1466, 'vienes': 1467, 'Este': 1468, 'sera': 1469, 'largo': 1470, 'Mira': 1471, 'haces': 1472, 'ejercicio': 1473, 'Más': 1474, 'vale': 1475, 'venirse': 1476, 'hacerme': 1477, 'ilusiones': 1478, 'feísimo': 1479, 'veremos': 1480, 'Espero': 1481, 'coincidir': 1482, 'Abrazo': 1483, 'crack': 1484, 'sido': 1485, 'funcionado': 1486, 'sad': 1487, 'conozcan': 1488, 'Trap': 1489, 'genuino': 1490, 'Puto': 1491, 'PS4': 1492, 'pro': 1493, 'pillado': 1494, 'congelado': 1495, 'pensaba': 1496, 'varios': 1497, 'veré': 1498, 'protagonista': 1499, 'consejo': 1500, 'sacar': 1501, 'notas': 1502, 'molonas': 1503, 'ESTUDIAD': 1504, 'bajar': 1505, 'cangas': 1506, 'tranquila': 1507, 'acuerdo': 1508, 'hice': 1509, 'súper': 1510, 'chachi': 1511, 'saltando': 1512, 'Él': 1513, 'ganado': 1514, 'especial': 1515, 'tuya': 1516, 'd': 1517, 'melena': 1518, 'muero': 1519, 'Mis': 1520, 'Felicitaciones': 1521, 'Usted': 1522, 'Señor': 1523, 'Presidente': 1524, 'Su': 1525, 'firme': 1526, 'mandamos': 1527, 'ultimo': 1528, 'Nooooo': 1529, 'iba': 1530, 'miercoles': 1531, 'positivo': 1532, 'sonrisa': 1533, 'poner': 1534, 'pulseras': 1535, 'mano': 1536, 'izquierda': 1537, 'molesten': 1538, 'escribir': 1539, 'aah': 1540, 'Ok': 1541, 'encerrado': 1542, '16': 1543, 'chocolates': 1544, 'Ferrero': 1545, 'fueron': 1546, 'suficientes': 1547, 'próxima': 1548, 'ojalá': 1549, 'regalen': 1550, '54': 1551, 'GUSTAZO': 1552, 'España': 1553, 'gane': 1554, 'Bélgica': 1555, 'CASA': 1556, 'encima': 1557, 'goles': 1558, 'CANARIO': 1559, 'underground': 1560, 'segunda': 1561, 'Of': 1562, 'course': 1563, 'ritmo': 1564, 'imagino': 1565, 'estará': 1566, 'Cuándo': 1567, 'dará': 1568, 'Apple': 1569, 'navegador': 1570, 'safari': 1571, 'competitivo': 1572, 'extensiones': 1573, 'MOZ': 1574, 'tipo': 1575, 'abrir': 1576, '600': 1577, 'mensajes': 1578, 'regalo': 1579, 'yupiiiiiiiiiiiiiiiiiiiiiiiiiiiii': 1580, 'disfruto': 1581, 'ratos': 1582, 'libres': 1583, 'mami': 1584, 'tomar': 1585, 'pastilla': 1586, '12': 1587, 'valdré': 1588, 'verga': 1589, 'duerme': 1590, 'líder': 1591, 'sigas': 1592, 'profe': 1593, 'comunicación': 1594, 'Umbridge': 1595, 'fondo': 1596, 'malvada': 1597, 'quedarnos': 1598, 'Amnesia': 1599, 'Terminas': 1600, 'verlo': 1601, 'npi': 1602, 'protas': 1603, '🌚': 1604, '👌': 1605, 'lluvia': 1606, 'definitivo': 1607, 'tiee': 1608, 'piedad': 1609, 'bus': 1610, 'Denada': 1611, 'porcierto': 1612, 'hazme': 1613, 'hueco': 1614, 'agenda': 1615, 'combates': 1616, 'monotype': 1617, 'mio': 1618, 'daría': 1619, 'dinero': 1620, 'menor': 1621, 'tarjeta': 1622, 'PayPal': 1623, 'debe': 1624, 'pasando': 1625, 'aprovecharon': 1626, 'gilipollas': 1627, 'cruzado': 1628, 'entero': 1629, 'rotonda': 1630, 'estaba': 1631, 'viendo': 1632, 'pusieron': 1633, 'colega': 1634, 'empecé': 1635, 'llamaba': 1636, 'selecto': 1637, 'sepa': 1638, 'descojona': 1639, 'indigno': 1640, 'toman': 1641, 'maite': 1642, 'monada': 1643, 'chica': 1644, 'pan': 1645, 'Tuve': 1646, 'vuelva': 1647, 'invierno': 1648, 'pantalones': 1649, 'chaquetas': 1650, 'sudaderas': 1651, 'abrigos': 1652, 'puto': 1653, 'profesor': 1654, 'instituto': 1655, 'suavizado': 1656, 'lenguaje': 1657, 'poético': 1658, 'séptimo': 1659, 'descansó': 1660, 'mae': 1661, 'muchacha': 1662, 'guapa': 1663, 'comemos': 1664, 'tragamos': 1665, 'tod': 1666, 'trayectoria': 1667, 'millon': 1668, 'suscriptor': 1669, 'DE': 1670, 'PERU': 1671, 'dawn': 1672, 'dispara': 1673, 'beth': 1674, 'daryl': 1675, 'inmediatamente': 1676, 'pone': 1677, 'llorar': 1678, 'Efectos': 1679, 'prácticos': 1680, 'Aprovechar': 1681, 'rival': 1682, 'hacemos': 1683, 'salvadas': 1684, 'público': 1685, 'salvada': 1686, 'jurado': 1687, 'canta': 1688, 'dms': 1689, 'solista': 1690, 'Aimee': 1691, 'LaBanda': 1692, 'Cómo': 1693, 'desean': 1694, 'navidad': 1695, 'favor': 1696, 'va': 1697, 'atendiendo': 1698, 'llamadas': 1699, 'portería': 1700, 'colegio': 1701, 'recepcionista': 1702, 'telefónico': 1703, 'niegues': 1704, 'misericordia': 1705, ';': 1706, 'protejan': 1707, 'Salmos': 1708, '40:11': 1709, 'bachillerato': 1710, 'historia': 1711, 'geografía': 1712, 'jodidamente': 1713, 'gordos': 1714, 'lunes': 1715, 'maravillosos': 1716, 'ejemplo': 1717, '😜': 1718, 'Hasta': 1719, 'Atleti': 1720, '2014/15': 1721, 'Juve': 1722, 'Olympiacos': 1723, 'Malmo': 1724, '2015/16': 1725, 'Benfica': 1726, 'Galatasaray': 1727, 'Astana': 1728, 'tocaba': 1729, 'Temporada': 1730, 'prestigiosa': 1731, 'crónicas': 1732, 'revistas': 1733, 'españolas': 1734, 'Oye': 1735, 'abandonada': 1736, 'buenazos': 1737, 'medio': 1738, 'gruesitos': 1739, 'cortados': 1740, 'vertical': 1741, 'Según': 1742, 'Pasa': 1743, 'link': 1744, 'please': 1745, 'pasaremos': 1746, 'tarde': 1747, 'ellos': 1748, 'ShowNavidad': 1749, 'CasaHogarMamáVictoria': 1750, 'anteojos': 1751, 'demasiado': 1752, 'flojos': 1753, 'comprados': 1754, 'bebé': 1755, 'reniega': 1756, 'hambre': 1757, 'comió': 1758, 'montón': 1759, 'siguiéndote': 1760, 'leyendo': 1761, 'ponías': 1762, 'dejas': 1763, 'diga': 1764, 'repitiendo': 1765, 'debí': 1766, 'bebido': 1767, 'último': 1768, 'Monster': 1769, 'teniendo': 1770, 'madrugar': 1771, 'Hostia': 1772, 'minutos': 1773, 'OMG': 1774, 'Almacén': 1775, 'Juegos': 1776, 'Bienvenidos': 1777, 'jugadores': 1778, 'Mas': 1779, 'penoso': 1780, 'desconocimiento': 1781, 'diversas': 1782, 'realidades': 1783, 'Perú': 1784, 'anda': 1785, 'preocupada': 1786, 'x': 1787, 'clásico': 1788, 'acertar': 1789, 'pablo': 1790, 'Pellegrino': 1791, 'dotado': 1792, 'equipo': 1793, 'consistencia': 1794, 'defensiva': 1795, 'fichajes': 1796, 'hombre': 1797, 'OCUPADO': 1798, 'pendiente': 1799, 'estas': 1800, 'general': 1801, 'motivación': 1802, 'revés': 1803, 'sobra': 1804, 'ego': 1805, 'sentía': 1806, 'incapaz': 1807, 'gustó': 1808, 'concierto': 1809, 'alegra': 1810, 'hacía': 1811, 'tocar': 1812, 'piezas': 1813, 'mariconadas': 1814, 'eliges': 1815, 'ves': 1816, 'querido': 1817, 'porrito': 1818, 'liado': 1819, 'Imelda': 1820, 'Tronconavideño': 1821, 'Fresas': 1822, 'frambuesas': 1823, 'blueberries': 1824, 'ceviche': 1825, 'makis': 1826, 'frustrada': 1827, 'BUENAS': 1828, 'amigas': 1829, 'cosica': 1830, 'fritos': 1831, 'manjar': 1832, 'mojar': 1833, 'existir': 1834, 'decepcionar': 1835, 'quieres': 1836, 'ex': 1837, 'absolutamente': 1838, 'esperan': 1839, 'horitas': 1840, 'autobus': 1841, 'seguramnete': 1842, 'funciona': 1843, 'Felicidades': 1844, 'Nos': 1845, 'hablamos': 1846, 'participar': 1847, 'tomé': 1848, 'decisión': 1849, 'NUNCA': 1850, 'dejen': 1851, 'Snapchat': 1852, 'celular': 1853, 'duermo': 1854, 'calle': 1855, 'superas': 1856, 'pierden': 1857, 'importancia': 1858, 'desastroso': 1859, 'aparentó': 1860, 'durante': 1861, 'campaña': 1862, 'Hope': 1863, 'is': 1864, 'all': 1865, 'we': 1866, 'have': 1867, 'left': 1868, 'Amanecí': 1869, 'comilona': 1870, 'anoche': 1871, 'BNOpenHouse': 1872, 'campo': 1873, 'desayunar': 1874, 'Windows10': 1875, 'caes': 1876, 'Para': 1877, 'aplicación': 1878, 'lento': 1879, 'torpe': 1880, 'ineficiente': 1881, 'pavor': 1882, 'música': 1883, 'adivinar': 1884, 'ganar': 1885, 'estás': 1886, 'pones': 1887, 'Camila': 1888, 'Ash': 1889, 'agencia': 1890, 'deprimir': 1891, 'muchos': 1892, 'Ojalá': 1893, 'accederia': 1894, 'Dani': 1895, 'Primera': 1896, 'David': 1897, 'cena': 1898, 'quiebra': 1899, 'vaso': 1900, 'París': 1901, 'visitas': 1902, 'New': 1903, 'York': 1904, 'pea': 1905, 'maldita': 1906, 'chaqueta': 1907, 'puente': 1908, 'constitución': 1909, 'Alicante': 1910, '12,13': 1911, '14': 1912, 'allí': 1913, 'estaré': 1914, '11.46PM': 1915, 'acuesto': 1916, 'panadería': 1917, 'lapsus': 1918, 'advertido': 1919, 'subsanado': 1920, 'aportación': 1921, 'consigo': 1922, 'ayudame': 1923, 'porfi': 1924, 'importante': 1925, 'Correcto': 1926, 'Mejor': 1927, 'pudiste': 1928, 'describir': 1929, 'Bendiciones': 1930, 'desgracia': 1931, 'vende': 1932, 'riñas': 1933, 'trifulcas': 1934, 'peleas': 1935, 'cuello': 1936, 'mátalo': 1937, 'feria': 1938, 'tierra': 1939, 'anfitrión': 1940, 'declaro': 1941, 'soltera': 1942, 'partir': 1943, 'daño': 1944, 'Plan': 1945, 'perfecto': 1946, 'terminar': 1947, 'convenció': 1948, 'recibí': 1949, 'noticia': 1950, 'emoción': 1951, 'Mar': 1952, 'Negro': 1953, 'caído': 1954, 'avión': 1955, 'músicos': 1956, 'médicos': 1957, 'enviaron': 1958, 'alegrar': 1959, 'Siria': 1960, 'Venga': 1961, 'física': 1962, 'vista': 1963, 'tienda': 1964, 'magnífica': 1965, 'DinastíaDelDienteDeLeón': 1966, 'empeñáis': 1967, 'española': 1968, 'dando': 1969, 'gordo': 1970, 'navideño': 1971, 'santa': 1972, 'despistada': 1973, 'marchamo': 1974, 'regalos': 1975, 'pagados': 1976, 'videos': 1977, 'envían': 1978, 'ay': 1979, 'jueguen': 1980, 'rencor': 1981, 'hacen': 1982, 'imparables': 1983, 'resentidos': 1984, 'hablan': 1985, 'decirme': 1986, 'animales': 1987, 'siiiiii': 1988, 'viernes': 1989, 'invito': 1990, 'litro': 1991, 'jurao': 1992, 'teneis': 1993, 'encontra': 1994, 'mia': 1995, 'proxima': 1996, 'vuestro': 1997, 'DiaDelVideojuegoHC': 1998, 'tardes': 1999, 'pasaran': 2000, 'feo': 2001, 'sino': 2002, 'animal': 2003, 'sentimientos': 2004, 'tía': 2005, 'vidilla': 2006, 'universitaria': 2007, 'come': 2008, 'cerquita': 2009, 'canales': 2010, 'SaltaconHolanda': 2011, 'trillado': 2012, 'Acabo': 2013, 'comprobar': 2014, 'Linkedin': 2015, 'eras': 2016, 'alumno': 2017, 'recuerdo': 2018, 'deseo': 2019, 'nervioso': 2020, 'función': 2021, 'laguna': 2022, 'mental': 2023, 'Mierda': 2024, 'pensar': 2025, 'cuantas': 2026, 'abre': 2027, 'escuchado': 2028, 'canso': 2029, 'gastado': 2030, '90': 2031, 'euros': 2032, 'LEGOs': 2033, 'maletines': 2034, 'regular': 2035, 'retiro': 2036, 'calificativo': 2037, 'ofensivo': 2038, 'gesto': 2039, 'parecido': 2040, 'valiente': 2041, 'contamos': 2042, 'shojos': 2043, 'comedia': 2044, 'romántica': 2045, 'centraran': 2046, 'romántico': 2047, 'pueblo': 2048, 'crema': 2049, 'Vento': 2050, 'perro': 2051, 'anden': 2052, 'izdo': 2053, 'autopista': 2054, 'huelva-sevilla': 2055, 'entrarme': 2056, 'impotencia': 2057, 'artículo': 2058, 'Carlos': 2059, 'Lucas': 2060, 'dramatizar': 2061, 'Vanessa': 2062, 'donde': 2063, 'extraño': 2064, 'verte': 2065, 'Ustedes': 2066, 'Anita': 2067, 'Amaya': 2068, 'preso': 2069, 'tuyo': 2070, 'plagiando': 2071, 'textos': 2072, 'Bonito': 2073, 'rincón': 2074, 'web': 2075, 'agusto': 2076, 'Circuito': 2077, 'termolúdico': 2078, 'Tenía': 2079, 'usar': 2080, 'Premiere': 2081, 'Pro': 2082, 'editando': 2083, 'olvidé': 2084, 'oficial': 2085, 'orzuelos': 2086, 'enquistados': 2087, 'ojo': 2088, 'izquierdo': 2089, 'asimétrica': 2090, 'raro': 2091, 'Nada': 2092, 'incitar': 2093, 'lectura': 2094, 'contarás': 2095, 'mágico': 2096, 'niños': 2097, 'amiguitos': 2098, 'defendiéndole': 2099, 'diciéndome': 2100, 'página': 2101, 'paz': 2102, 'necesitáis': 2103, 'hater': 2104, 'profesional': 2105, 'podéis': 2106, 'llamar': 2107, 'G8': 2108, 'calienta': 2109, 'bateria': 2110, 'baja': 2111, 'rápido': 2112, 'peluqueros': 2113, 'estén': 2114, 'locos': 2115, 'fuera': 2116, 'don': 2117, 'gentes': 2118, 'coñe': 2119, 'hablaba': 2120, 'fresh': 2121, 'naaada': 2122, 'tú': 2123, 'hiciste': 2124, 'Kheeeeeeeeeé': 2125, 'SacandoConclusiones': 2126, 'FelizMiercoles': 2127, 'ignorar': 2128, 'trolls': 2129, 'usé': 2130, 'block': 2131, 'pesado': 2132, 'bobo': 2133, 'conocí': 2134, 'clado': 2135, 'enseñado': 2136, 'entrando': 2137, 'depresión': 2138, 'máquina': 2139, 'lleve': 2140, '29': 2141, 'junio': 2142, 'Ay': 2143, 'temporada': 2144, 'sugerencia': 2145, 'Junto': 2146, 'montas': 2147, 'unico': 2148, 'llaman': 2149, 'Global': 2150, 'Talents': 2151, 'suele': 2152, 'subir': 2153, 'actuaciones': 2154, 'valoraciones': 2155, 'previos': 2156, 'resultados': 2157, 'perseguir': 2158, 'corruptos': 2159, 'defraudadores': 2160, 'pretenden': 2161, 'encarcelar': 2162, 'cuestionan': 2163, 'poder': 2164, 'cuentos': 2165, 'tuits': 2166, 'vuelve': 2167, 'grabación': 2168, 'preparado': 2169, 'burguesía': 2170, 'venezolana': 2171, 'ricos': 2172, 'animando': 2173, 'población': 2174, 'colapsar': 2175, 'Venezuela': 2176, 'Toma': 2177, 'Caracas': 2178, 'creer': 2179, 'Nini': 2180, 'maltrataban': 2181, 'penita': 2182, 'gusto': 2183, 'objetos': 2184, 'traten': 2185, 'indigna': 2186, 'recibas': 2187, 'tuit': 2188, 'alternativa': 2189, 'sigues': 2190, 'viva': 2191, 'camino': 2192, 'Suerte': 2193, 'nivel': 2194, 'llame': 2195, 'pizzeria': 2196, 'llueve': 2197, 'sombrilla': 2198, 'perdidas': 2199, 'RT': 2200, 'buscar': 2201, 'clan': 2202, 'conseguido': 2203, 'suplente': 2204, 'adc': 2205, 'DragonsZGaminG': 2206, 'duro': 2207, 'niño': 2208, 'verse': 2209, 'forzado': 2210, 'parte': 2211, 'procesos': 2212, 'septiembre': 2213, 'retarse': 2214, 'increible': 2215, 'aprender': 2216, 'medirse': 2217, 'obstáculo': 2218, 'joyita': 2219, 'corona': 2220, 's': 2221, 'terceras': 2222, 'elecciones': 2223, 'predicción': 2224, 'bailarte': 2225, 'medusa': 2226, 'loca': 2227, 'porqué': 2228, 'asquito': 2229, 'éramos': 2230, 'consideraba': 2231, 'vivo': 2232, 'alternativas': 2233, 'válidas': 2234, 'creas': 2235, 'miré': 2236, 'objetivo': 2237, 'uno': 2238, 'nunca': 2239, 'asombrándome': 2240, 'puse': 2241, 'acto': 2242, 'seguido': 2243, 'desbloquear': 2244, 'ajjajajja': 2245, 'Muchas': 2246, 'miraba': 2247, 'abrazoteee': 2248, 'novio': 2249, 'soltero': 2250, '96': 2251, 'injusta': 2252, 'Muchísimas': 2253, 'difundir': 2254, 'Allen': 2255, 'Walker': 2256, 'Expo': 2257, 'uff': 2258, 'menudo': 2259, 'cosplay': 2260, 'Lena': 2261, 'peluca': 2262, 'guay': 2263, 'concursante': 2264, 'encanta': 2265, 'impresionante': 2266, 'Alejandra': 2267, 'hagan': 2268, 'rogar': 2269, 'competir': 2270, 'humildad': 2271, 'rojo': 2272, '.....': 2273, 'increíble': 2274, 'entro': 2275, 'wpp': 2276, 'ambiente': 2277, 'chungo': 2278, 'río': 2279, 'caray': 2280, 'ayer': 2281, 'Creí': 2282, 'Almost': 2283, 'Blue': 2284, 'Chet': 2285, 'Baker': 2286, 'luzfloridecepción': 2287, 'hermoso': 2288, 'conociste': 2289, 'emocionante': 2290, 'puzzle': 2291, 'sunggyu': 2292, 'Ensalada': 2293, 'Salmón': 2294, 'ricas': 2295, 'propuestas': 2296, 'menú': 2297, 'MenuDiario': 2298, 'RestauranteCasinoLasPalmas': 2299, 'justin': 2300, 'subiendo': 2301, 'comiéndose': 2302, 'boca': 2303, 'sofía': 2304, 'den': 2305, 'culo': 2306, 'Aii': 2307, 'felicitar': 2308, 'Muchaass': 2309, 'Mara': 2310, 'hayas': 2311, 'pasado': 2312, 'Ayer': 2313, 'dieron': 2314, 'botella': 2315, 'pegue': 2316, 'trago': 2317, 'pensando': 2318, 'yin': 2319, 'Fresca': 2320, 'marifer': 2321, 'Humanidades': 2322, 'latín': 2323, 'griego': 2324, 'dado': 2325, 'latin': 2326, 'iria': 2327, 'ellas': 2328, 'Fue': 2329, 'cumpleañero': 2330, 'torta': 2331, 'mesa': 2332, 'risas': 2333, 'bendecido': 2334, 'ehhhhhhh': 2335, 'cojones': 2336, 'roben': 2337, 'identidad': 2338, 'Técnicas': 2339, 'Reunidas': 2340, 'mayores': 2341, 'ingenierías': 2342, 'internacionales': 2343, 'carné': 2344, 'fotografía': 2345, 'emoticono': 2346, 'carita': 2347, 'tambien': 2348, 'viajado': 2349, 'conocido': 2350, 'excelentes': 2351, 'iré': 2352, 'única': 2353, 'app': 2354, 'manga': 2355, 'leo': 2356, 'actualizado': 2357, 'ons': 2358, 'Octubre': 2359, 'cositas': 2360, 'pequeño': 2361, 'zurda': 2362, 'obligó': 2363, 'diestra': 2364, 'incondicional': 2365, 'clase': 2366, 'sentimiento': 2367, 'felicidad': 2368, 'incluso': 2369, 'costa': 2370, 'suyo': 2371, 'Familia': 2372, 'ama': 2373, 'chico': 2374, 'perverso': 2375, 'Hola': 2376, 'Luis': 2377, 'Vendrás': 2378, 'Barcelona': 2379, 'promocionar': 2380, 'TardeParaLaIra': 2381, 'racista': 2382, 'mirarlo': 2383, 'arreglarlo': 2384, 'negarlo': 2385, 'aww': 2386, 'Muaaaaaaaaaak': 2387, 'plena': 2388, 'auditoría': 2389, 'Muak': 2390, 'podemita': 2391, 'discusión': 2392, 'F': 2393, 'robar': 2394, 'sean': 2395, 'MarcaEspaña': 2396, 'Roxi': 2397, 'comiendo': 2398, 'precio': 2399, 'ridículo': 2400, 'haría': 2401, 'Feria': 2402, 'Gasto-nómica': 2403, 'lluviaencasa': 2404, 'apuntas': 2405, 'liga': 2406, 'Llorente': 2407, 'elegido': 2408, 'cool': 2409, 'gris': 2410, 'Ni': 2411, 'sueños': 2412, 'hubieras': 2413, 'imaginado': 2414, 'encuesta': 2415, 'tantos': 2416, 'votos': 2417, 'jajajj': 2418, 'moviliza': 2419, 'mando': 2420, 'poniendo': 2421, 'nerviosita': 2422, 'Puede': 2423, 'acostumbrarse': 2424, 'acostumbré': 2425, 'Despues': 2426, 'merezco': 2427, 'caprichos': 2428, 'Esperemos': 2429, 'empiece': 2430, 'tirar': 2431, 'arriba': 2432, 'despegar': 2433, 'proyecto': 2434, 'asi': 2435, 'gemelos': 2436, 'entran': 2437, 'meter': 2438, 'brazos': 2439, 'darles': 2440, 'abracito': 2441, 'típico': 2442, 'estreso': 2443, 'felizcumplemichi': 2444, 'pasala': 2445, 'seres': 2446, 'queridos': 2447, 'exitos': 2448, 'propongas': 2449, 'Bioquimica': 2450, 'fresquita': 2451, 'quitaron': 2452, 'banco': 2453, 'hola': 2454, 'intagram': 2455, 'seguia': 2456, 'igualmente': 2457, '🙄': 2458, '❤': 2459, '️': 2460, '300': 2461, 'aforo': 2462, 'orgullosa': 2463, 'fan': 2464, 'speach': 2465, 'admirando': 2466, 'red': 2467, 'encuentre': 2468, 'pagar': 2469, 'pagaba': 2470, 'tranquilo': 2471, 'pringa': 2472, 'trabajando': 2473, 'jajajajajaja': 2474, 'contentos': 2475, 'fiscales': 2476, 'afinen': 2477, 'ciclistas': 2478, 'Excelente': 2479, 'persigno': 2480, 'Aah': 2481, 'rastrero': 2482, 'egoísta': 2483, 'infantil': 2484, 'GILIPOLLAS': 2485, 'sra': 2486, 'presidenta': 2487, 'predica': 2488, 'ejm': 2489, 'volvamos': 2490, 'venezolano': 2491, 'exageró': 2492, 'huracán': 2493, 'escogido': 2494, 'quién': 2495, 'molaría': 2496, 'hcerme': 2497, 'cambio': 2498, 'drástico': 2499, 'pedir': 2500, 'ayuda': 2501, 'salirme': 2502, 'aguas': 2503, 'termales': 2504, 'Monteverde': 2505, 'negro': 2506, 'azulado': 2507, 'conseguirlo': 2508, 'tintes': 2509, 'color': 2510, 'echado': 2511, 'Ella': 2512, 'bbs': 2513, 'Chema': 2514, 'oficina': 2515, 'deseando': 2516, 'dirigir': 2517, 'empresa': 2518, 'quedamos': 2519, 'señor': 2520, 'Rajoy': 2521, 'Martes': 2522, 'Pásenla': 2523, 'sonreír': 2524, '.@user': 2525, 'atrocidodes': 2526, 'surgen': 2527, 'idealismo': 2528, 'bienintencionado': 2529, 'cabe': 2530, 'capaces': 2531, 'Viendo': 2532, 'JoselitoYSuOrquesta': 2533, 'WantanNight': 2534, 'jueves': 2535, 'despollando': 2536, 'disco': 2537, 'digerir': 2538, 'discografía': 2539, 'morir': 2540, 'sielto': 2541, 'anterior': 2542, 'bio': 2543, 'volar': 2544, '-y': 2545, 'Twitter-': 2546, 'recuerdan': 2547, 'SoisGrandes': 2548, '😘': 2549, 'arruinada': 2550, 'Berni': 2551, 'Son': 2552, 'frases': 2553, 'complementa': 2554, 'Así': 2555, 'pongo': 2556, 'Re': 2557, 'zero': 2558, 'dejan': 2559, 'intrigado': 2560, 'capitulo': 2561, 'importa': 2562, 'niu': 2563, 'old': 2564, 'amas': 2565, 'bienvenido': 2566, 'meto': 2567, 'contexto': 2568, 'llevarlas': 2569, 'terreno': 2570, 'enserio': 2571, 'aprecio': 2572, 'bloqueado': 2573, 'empezaba': 2574, 'tenerle': 2575, 'cariño': 2576, 'dile': 2577, 'Alex': 2578, 'aceites': 2579, 'duchas': 2580, 'arreglan': 2581, 'piel': 2582, 'codos': 2583, 'finísimos': 2584, 'Han': 2585, 'talado': 2586, 'abedul': 2587, 'gigante': 2588, 'esquina': 2589, 'Ríos': 2590, 'Rosas': 2591, 'Castellana': 2592, 'Alguien': 2593, 'sabe': 2594, 'Palmas': 2595, 'modesto': 2596, '1ª': 2597, 'división': 2598, 'empieza': 2599, 'L': 2600, 'Leicester': 2601, 'ahílodejo': 2602, 'ah': 2603, 'llamarme': 2604, 'oscurito': 2605, 'barrios': 2606, 'la.bendición': 2607, 'seré': 2608, 'despreciable': 2609, 'Ambientado': 2610, 'Italia': 2611, 'parejas': 2612, 'entuertos': 2613, 'honor': 2614, 'humor': 2615, 'rollo': 2616, 'gafas': 2617, 'mirando': 2618, 'Skins': 2619, 'claroooo': 2620, 'PSOE': 2621, 'roto': 2622, 'alba': 2623, 'esroy': 2624, 'poquito': 2625, 'digas': 2626, 'voto': 2627, 'memeo': 2628, 'cada': 2629, 'tendra': 2630, 'opinion': 2631, 'llego': 2632, 'huge': 2633, '2000': 2634, 'crecí': 2635, 'sube': 2636, 'temporadas': 2637, 'favoritas': 2638, 'numerosos': 2639, 'incendios': 2640, 'llueva': 2641, 'majo': 2642, 'Uníos': 2643, 'venir': 2644, 'feministas': 2645, 'OS': 2646, 'JODE': 2647, 'movimiento': 2648, 'nana': 2649, 'queres': 2650, 'comprar': 2651, 'chulada': 2652, 'Mola': 2653, 'post': 2654, 'lloro': 2655, 'Tú': 2656, 'sexy': 2657, 'Nerea': 2658, 'Besitos': 2659, 'gb': 2660, 'Enamorada': 2661, 'Second': 2662, 'Last': 2663, 'Love': 2664, 'Veré': 2665, 'probablemente': 2666, 'japonesa': 2667, 'NOOOO': 2668, 'omg': 2669, 'pierdo': 2670, 'fanarts': 2671, 'D.O': 2672, 'E': 2673, 'EL': 2674, 'KPOp': 2675, 'perdí': 2676, 'activo': 2677, 'Pasad': 2678, 'rato': 2679, 'encantará': 2680, 'impresiones': 2681, 'Seguro': 2682, 'Nora': 2683, 'encantada': 2684, 'Entre': 2685, 'podía': 2686, 'ME': 2687, 'PASA': 2688, 'MI': 2689, '-.-': 2690, \"'\": 2691, 'Próximo': 2692, 'destino': 2693, '......': 2694, 'Londres': 2695, 'currar': 2696, 'extranjero': 2697, 'yupiiiii': 2698, 'JAJAJAJAJJA': 2699, 'cague': 2700, 'listo': 2701, '🤘': 2702, 'buscando': 2703, 'mirada': 2704, 'perfecta': 2705, 'Roci': 2706, 'cuidado': 2707, 'quedas': 2708, '-Liena': 2709, 'quedó': 2710, 'Clásico': 2711, 'donostiarra': 2712, 'casita': 2713, 'fútbol': 2714, 'Donostia': 2715, 'Fútbol': 2716, 'aguantar': 2717, 'galería': 2718, 'captaste': 2719, 'misteriosa': 2720, 'además': 2721, 'moral': 2722, 'Amancio': 2723, 'nuestras': 2724, 'críticas': 2725, 'Otro': 2726, 'Javier': 2727, 'ilusión': 2728, 'respuesta': 2729, 'sigan': 2730, 'criticandome': 2731, 'paja': 2732, 'seguiré': 2733, 'viajando': 2734, 'examino': 2735, 'cumple': 2736, 'comes': 2737, 'paellas-de-verdad': 2738, 'japo': 2739, 'pijo': 2740, 'yr': 2741, 'desas': 2742, 'Instagram': 2743, 'homrepordios': 2744, 'graciosa': 2745, 'pretemporada': 2746, 'desagradable': 2747, 'cris': 2748, 'chiquito': 2749, 'juguete': 2750, 'pleno': 2751, '2017': 2752, 'servicios': 2753, 'pueden': 2754, 'utilizar': 2755, 'Windows': 2756, 'saludo': 2757, 'vino': 2758, 'café': 2759, 'Erito': 2760, 'tuve': 2761, 'chinearon': 2762, 'Utopí': 2763, 'audiencia': 2764, 'estable': 2765, \"8'5\": 2766, 'Imdb': 2767, 'cancelada': 2768, 'manta': 2769, 'farmacéutica': 2770, 'cucada': 2771, '😍': 2772, 'Le': 2773, 'lacito': 2774, 'llevaba': 2775, 'ash': 2776, 'explotado': 2777, 'Al': 2778, 'sucumbido': 2779, 'maldito': 2780, 'dura': 2781, 'problemas': 2782, 'espalda': 2783, 'rodillas': 2784, 'tobillos': 2785, 'compiten': 2786, '22': 2787, 'viejo': 2788, 'mandaras': 2789, 'md': 2790, 'dirás': 2791, '😳': 2792, '💞': 2793, 'arbitro': 2794, 'alguno': 2795, 'Valencia': 2796, 'Omega': 2797, 'Constellation': 2798, 'numéricos': 2799, 'romanos': 2800, 'postular': 2801, 'CEUP': 2802, 'cortísimo': 2803, 'enseñó': 2804, 'organizarme': 2805, 'tendremos': 2806, 'Ser': 2807, 'villano': 2808, 'película': 2809, 'mall': 2810, 'directos': 2811, 'deberían': 2812, 'totalmente': 2813, 'estables': 2814, 'solían': 2815, 'darme': 2816, 'vienen': 2817, 'chulas': 2818, 'SPOILERS': 2819, 'TWD': 2820, 'perdón': 2821, 'retuitea': 2822, 'conozco': 2823, 'abiertos': 2824, 'haser': 2825, 'vente': 2826, 'caceres': 2827, 'sitio': 2828, 'verás': 2829, 'luna': 2830, 'calladito': 2831, 'bajarse': 2832, 'mú': 2833, 'Cuánta': 2834, 'ignorancia': 2835, 'opinión': 2836, 'viaje': 2837, 'aventura': 2838, 'ugh': 2839, 'siii': 2840, 'Permiso': 2841, 'ninguno': 2842, 'Miquel': 2843, 'timeline': 2844, 'cabrooon': 2845, 'acabas': 2846, 'follando': 2847, 'novias': 2848, 'esposas': 2849, 'datos': 2850, 'catálogo': 2851, 'sísmico': 2852, 'históricos': 2853, 'ataque': 2854, 'ansiedad': 2855, 'soporto': 2856, 'dramas': 2857, 'emisión': 2858, 'sufrir': 2859, 'horrores': 2860, 'BLME': 2861, 'adaptado': 2862, 'Sparks': 2863, 'mención': 2864, 'askalvarogango': 2865, 'francia': 2866, 'probé': 2867, 'ramen': 2868, 'bolsa': 2869, 'Tokyo': 2870, 'Ramen': 2871, 'llévenme': 2872, 'Todavía': 2873, 'nueveeee': 2874, 'eeee': 2875, 'Uf': 2876, 'alta': 2877, 'asegurar': 2878, 'contagia': 2879, 'obviamente': 2880, 'seriedad': 2881, 'papá': 2882, 'cabello': 2883, 'TINTE': 2884, 'MEJOR': 2885, 'PREFIERO': 2886, 'NATURAL': 2887, 'identifico': 2888, 'hablabamos': 2889, 'skype': 2890, 'mona': 2891, 'ciego': 2892, 'vuelco': 2893, 'csa': 2894, 'Slides': 2895, 'preparadas': 2896, 'pillare': 2897, 'quedo': 2898, 'Super': 2899, 'Junior': 2900, 'escape': 2901, 'malas': 2902, 'apoyarlos': 2903, 'obligación': 2904, 'agresiones': 2905, 'sexistas': 2906, 'Fiestas': 2907, 'Sangüesa': 2908, 'elección': 2909, 'empujarme': 2910, 'saquen': 2911, 'egoísmo': 2912, 'insolidaridad': 2913, 'Aunque': 2914, 'mayor': 2915, 'Podemos': 2916, 'participando': 2917, 'preguntas': 2918, 'propias': 2919, 'pareja': 2920, 'labios': 2921, 'secos': 2922, 'anli': 2923, 'video': 2924, 'Cate': 2925, 'bello': 2926, 'Lograste': 2927, 'transmitir': 2928, 'Vibras': 2929, 'ambos': 2930, 'Debió': 2931, 'decirlo': 2932, 'chirriante': 2933, 'Caníbales': 2934, 'balance': 2935, 'bastante': 2936, 'sales': 2937, 'cantando': 2938, 'hermanos': 2939, 'decida': 2940, 'subnormal': 2941, 'perdido': 2942, 'merecen': 2943, 'encontrado': 2944, 'externo': 2945, 'gigas': 2946, 'Robbie': 2947, 'Williams': 2948, 'Sería': 2949, 'ideal': 2950, 'caer': 2951, 'O': 2952, 'Take': 2953, 'That': 2954, 'evan': 2955, 'peters': 2956, '-casi': 2957, 'equivoco': 2958, 'evans': 2959, 'peter': 2960, '-dejadme': 2961, '-es': 2962, 'sdasldjalsk': 2963, 'tras': 2964, 'vistazo': 2965, 'tw': 2966, 'pareces': 2967, 'Ánimo': 2968, 'puedas': 2969, 'recuperarte': 2970, 'cansado': 2971, 'tenes': 2972, 'albacete': 2973, 'rosario': 2974, '...........': 2975, 'orgullo': 2976, 'dañada': 2977, '-Yo': 2978, 'fichado': 2979, 'darle': 2980, 'NecesitoElViajeAAndalucia': 2981, 'mongol': 2982, 'soñé': 2983, 'actuación': 2984, 'fui': 2985, 'extremadamente': 2986, 'logre': 2987, 'investiduraRajoy': 2988, 'NO': 2989, 'ES': 2990, 'NOTICIA': 2991, 'contrario': 2992, 'serán': 2993, 'becarios': 2994, 'prácticas': 2995, 'experto': 2996, 'reencuentros': 2997, 'inolvidables': 2998, 'since': 2999, '1994': 3000, 'Piper': 3001, 'robe': 3002, 'casas': 3003, 'junto': 3004, 'albóndiga': 3005, 'YT': 3006, 'arrepiento': 3007, 'pido': 3008, 'perdon': 3009, 'duele': 3010, 'dedo': 3011, 'pie': 3012, 'heee': 3013, 'calma': 3014, 'laura': 3015, 'arregla': 3016, 'Balance': 3017, 'patrocinador': 3018, 'Sele': 3019, 'camisetas': 3020, 'feas': 3021, 'acabamos': 3022, 'simpática': 3023, 'grace': 3024, 'atropellaron': 3025, 'cuento': 3026, 'Amo': 3027, 'canción': 3028, 'Reyes': 3029, 'capital': 3030, 'caliente': 3031, 'quejan': 3032, 'clima': 3033, 'caluroso': 3034, 'sacan': 3035, 'sangre': 3036, 'ayunas': 3037, 'Dadme': 3038, 'ánimos': 3039, 'situación': 3040, 'heavy': 3041, 'tocando': 3042, 'Fin': 3043, 'Misión': 3044, 'Lima-limon': 3045, 'tod@s': 3046, 'onda': 3047, 'corto': 3048, 'repetirá': 3049, 'visita': 3050, 'Silvia': 3051, 'pesada': 3052, 'rt': 3053, 'sale': 3054, 'doble': 3055, 'notificación': 3056, 'laboral': 3057, 'Éxitos': 3058, 'vidas': 3059, 'Casi': 3060, 'cuquis': 3061, 'llevamos': 3062, 'ruta': 3063, 'cuantos': 3064, 'padre': 3065, 'pasó': 3066, 'ralladas': 3067, 'oye': 3068, 'burguesito': 3069, 'sbs': 3070, 'Perdon': 3071, 'dudas': 3072, 'traves': 3073, 'askLFI': 3074, 'ayudas': 3075, 'ayudasLFI': 3076, 'convocatoria': 3077, 'interesnate': 3078, 'cabrones': 3079, 'invitación': 3080, 'formal': 3081, 'Mundo': 3082, 'Chiquito': 3083, 'mándale': 3084, 'Capitán': 3085, 'américa': 3086, 'hipervitaminado': 3087, 'motiva': 3088, 'Assange': 3089, 'Destrucción': 3090, 'total': 3091, 'niñas': 3092, 'ocupada': 3093, 'evershhh': 3094, 'yyy': 3095, 'estudie': 3096, 'conta': 3097, 'yyyy': 3098, 'examen': 3099, 'Stranger': 3100, 'Mr': 3101, 'Robot': 3102, 'recomienda': 3103, 'The': 3104, 'get': 3105, 'down': 3106, 'marché': 3107, 'relacionar': 3108, 'tomarme': 3109, 'copita': 3110, 'lasaña': 3111, 'Cocinan': 3112, 'adoptaron': 3113, 'contento': 3114, 'mimitos': 3115, 'sabia': 3116, 'pasaria': 3117, 'pos': 3118, 'sobretodo': 3119, 'tenerla': 3120, '♥': 3121, 'identificada': 3122, 'tweet': 3123, 'aveces': 3124, 'lastimosamente': 3125, 'entradas': 3126, 'ganaron': 3127, 'REVENDEDORES': 3128, 'Estaba': 3129, 'desperté': 3130, 'famoso': 3131, 'Lugar': 3132, 'recomendable': 3133, 'Colon': 3134, 'importantes': 3135, 'acá': 3136, 'tarea': 3137, 'cálculo': 3138, 'dolor': 3139, 'unas': 3140, 'enormes': 3141, 'ganotas': 3142, 'Bla': 3143, 'bla': 3144, 'antibióticos': 3145, 'milagrosos': 3146, 'ilegal': 3147, 'palabras': 3148, 'emociones': 3149, 'generan': 3150, 'útiles': 3151, 'generar': 3152, 'podido': 3153, 'lovers': 3154, 'signal': 3155, 'ídolo': 3156, 'corriente': 3157, 'escribe': 3158, 'cucha': 3159, 'independentista': 3160, 'escribiendo': 3161, 'Barça': 3162, 'vas': 3163, 'grassias': 3164, 'gggg': 3165, 'conmemorativo': 3166, 'bar': 3167, 'despedidas': 3168, 'siiiii': 3169, 'lista': 3170, 'OT': 3171, 'Entiendo': 3172, 'gráfica': 3173, 'muera': 3174, 'vídeos': 3175, 'bien!!!viva': 3176, 'pueblos': 3177, 'indígenas': 3178, 'respuesta!Sí': 3179, 'correcto': 3180, 'consulté': 3181, 'habitual': 3182, 'llamativo': 3183, 'friki': 3184, 'hastag': 3185, 'motivo': 3186, 'dadle': 3187, 'tope': 3188, 'venga': 3189, 'demoslelavuelta': 3190, 'cojo': 3191, 'aburrimiento': 3192, 'diferenciarlos': 3193, 'muchísima': 3194, 'llegar': 3195, 'reina': 3196, 'descuentos': 3197, 'estudiante': 3198, 'menores': 3199, '27': 3200, 'dices': 3201, 'planeando': 3202, 'salidas': 3203, 'viajes': 3204, 'futuro': 3205, 'apiado': 3206, 'existen': 3207, 'encuentras': 3208, 'lee': 3209, 'conseguí': 3210, 'inventario': 3211, 'despues': 3212, 'huelo': 3213, 'laas': 3214, 'vacacioness': 3215, 'recuerde': 3216, 'faltado': 3217, 'Salud': 3218, 'república': 3219, 'Acampar': 3220, 'mundial': 3221, 'Necesito': 3222, 'paguen': 3223, 'miseria': 3224, 'formado': 3225, 'edición': 3226, 'Master': 3227, 'molestar': 3228, 'duermen': 3229, 'andamos': 3230, 'Síndrome': 3231, 'post-Uncharted': 3232, 'S': 3233, 'golpe': 3234, 'Peeeero': 3235, 'Tu': 3236, 'parido': 3237, 'grandisimo': 3238, 'hijo': 3239, 'vengas': 3240, 'quedada': 3241, 'magicamente': 3242, 'bebe': 3243, 'mica': 3244, 'ne': 3245, 'g': 3246, 'ig': 3247, 'dudar': 3248, 'cbt': 3249, 'peru': 3250, 'alla': 3251, 'welcome': 3252, 'back': 3253, 'cálido': 3254, 'morirán': 3255, 'terremoto': 3256, 'Nadie': 3257, 'zonza': 3258, 'parada': 3259, 'toalla': 3260, 'chineada': 3261, 'traen': 3262, 'almuerzo': 3263, 'traducido': 3264, 'busqué': 3265, 'encontré': 3266, 'subtitulado': 3267, 'siemprw': 3268, 'mato': 3269, 'eeh': 3270, 'dejo': 3271, 'descanses': 3272, 'dormido': 3273, 'despertar': 3274, 'Yessica': 3275, 'TOP8': 3276, 'esperaba': 3277, 'aqui': 3278, 'Menuda': 3279, 'joyica': 3280, 'reclutado': 3281, 'tierras': 3282, 'Hubiera': 3283, 'tenido': 3284, 'hubiera': 3285, 'chill': 3286, 'Netflix': 3287, 'estos': 3288, 'recomiendo': 3289, 'monótona': 3290, 'vuelven': 3291, 'interés': 3292, 'mazo': 3293, 'utilizáis': 3294, 'dejéis': 3295, 'miel': 3296, 'vueltas': 3297, 'emocionado': 3298, 'GIGANTE': 3299, 'palmarés': 3300, 'jugaban': 3301, 'Siempre': 3302, 'cielo': 3303, 'azul': 3304, 'rascacielos': 3305, 'cabrito': 3306, 'quito': 3307, 'perdónale': 3308, 'Sigo': 3309, 'imbatible': 3310, 'ganando': 3311, 'Fifa': 3312, 'siendo': 3313, 'visitante': 3314, 'costado': 3315, '13': 3316, '360': 3317, 'cicatrices': 3318, 'sufrido': 3319, 'provocado': 3320, 'microaventura': 3321, 'kayak': 3322, 'expertos': 3323, 'kayakistas': 3324, 'Ría': 3325, 'Villaviciosa': 3326, 'Puntal': 3327, 'tirarse': 3328, 'toooooodo': 3329, 'durmiendo': 3330, 'tato': 3331, 'WORK': 3332, 'FROM': 3333, 'HOME': 3334, 'espectacular': 3335, 'verlas': 3336, 'ConMTVal727Tour': 3337, 'creen': 3338, 'erosky': 3339, 'compra': 3340, 'redacté': 3341, 'testamento': 3342, 'Ale': 3343, 'publique': 3344, 'Steven': 3345, 'dejaste': 3346, 'misio': 3347, 'publica': 3348, 'nuestros': 3349, 'festivales': 3350, 'favoritos': 3351, 'Hemos': 3352, 'troye': 3353, 'empiezan': 3354, 'ciudad': 3355, 'mojabraguear': 3356, '😡': 3357, 'estaría': 3358, 'paseo': 3359, 'tren': 3360, 'tendría': 3361, 'findes': 3362, 'ponedme': 3363, 'tbm': 3364, 'tiempos': 3365, 'twitter': 3366, 'agradable': 3367, 'recordar': 3368, 'menciono': 3369, 'Igual': 3370, 'ferrolana': 3371, 'lentita': 3372, 'Verónika': 3373, 'actriz': 3374, 'maravillosa': 3375, 'Deseando': 3376, 'Besos': 3377, 'brindis': 3378, 'hipócritas': 3379, 'bufanda': 3380, 'Rivera': 3381, 'pactado': 3382, 'Nivea': 3383, 'lanzar': 3384, 'pelotas': 3385, 'avioneta': 3386, 'vemos': 3387, '25D': 3388, 'costumbre': 3389, 'episodio': 3390, 'SNL': 3391, 'recibir': 3392, 'mood': 3393, 'ducharme': 3394, 'estuve': 3395, 'esperando': 3396, 'posiblemente': 3397, 'suba': 3398, 'tarde-noche': 3399, 'Yoshi': 3400, 'aparece': 3401, 'escríbele': 3402, 'huerta': 3403, 'perros': 3404, 'condiciones': 3405, 'estupendas': 3406, 'tiraros': 3407, 'descuentiyo': 3408, '40%': 3409, 'aprox': 3410, 'bilbao': 3411, 'caro': 3412, 'cliente': 3413, 'Listo': 3414, 'metas': 3415, 'echán2te': 3416, 'verteeee': 3417, 'excusa': 3418, '-_-': 3419, 'enterizos': 3420, 'marcha': 3421, 'información': 3422, 'tomamos': 3423, 'nota': 3424, 'peten': 3425, 'Sí': 3426, 'imaginaba': 3427, 'aprende': 3428, 'cambiar': 3429, 'username': 3430, 'numero': 3431, 'aiuda': 3432, 'Demasiado': 3433, 'alturas': 3434, 'Seleeeeee': 3435, 'quieren': 3436, 'desnaturalizar': 3437, 'BienestarAnimal': 3438, 'dejando': 3439, 'iniciativa': 3440, 'popular': 3441, 'gatos': 3442, 'Buscaré': 3443, 'Pinterest': 3444, 'debería': 3445, 'siguiente': 3446, '-Hola': 3447, '-Bien': 3448, 'Esa': 3449, 'Nota': 3450, 'menta': 3451, 'felicitaciones': 3452, 'automatizadas': 3453, 'LinkedIn': 3454, 'cantan': 3455, 'llegan': 3456, 'dizque': 3457, 'debut': 3458, 'CM': 3459, 'Punk': 3460, 'UFC': 3461, 'entrar': 3462, 'vídeo': 3463, 'Selección': 3464, 'selecciones': 3465, 'Siento': 3466, 'romperé': 3467, 'silla': 3468, 'plástico': 3469, 'relaja': 3470, 'plajo': 3471, 'farda': 3472, 'saca': 3473, '11': 3474, 'siiii': 3475, 'teniamos': 3476, 'habernos': 3477, 'sacado': 3478, 'Morí': 3479, 'like': 3480, 'Bombon': 3481, 'Rumors': 3482, 'teníamos': 3483, 'tradición': 3484, 'Zapote': 3485, '25': 3486, 'YeimyTeMueve': 3487, 'Escribí': 3488, 'Contigo': 3489, 'matas': 3490, '-->Tal': 3491, 'mereces': 3492, 'conseguirás': 3493, 'ahors': 3494, 'conciertos': 3495, 'suyos': 3496, 'mueve': 3497, 'escenario': 3498, 'vd': 3499, 'renegara': 3500, 'lloraron': 3501, 'TAMBIÉN': 3502, 'FUERON': 3503, 'FELICES': 3504, 'seguirá': 3505, 'Teide': 3506, 'proeza': 3507, 'Todo': 3508, 'bella': 3509, 'Hablando': 3510, 'apruebe': 3511, 'matemáticas': 3512, 'tiro': 3513, 'ventana': 3514, 'décimo': 3515, 'sobrevivo': 3516, 'escribo': 3517, 'preocupa': 3518, 'libreta': 3519, 'regaló': 3520, 'somnífero': 3521, 'instantáneo': 3522, 'usuarios': 3523, 'SFV': 3524, 'quita': 3525, 'mortales': 3526, 'Ambas': 3527, 'mindblowing': 3528, 'White': 3529, 'Collar': 3530, 'terminara': 3531, 'repente': 3532, '5ta': 3533, 'Suits': 3534, '-felicidades': 3535, '🎉': 3536, '-sales': 3537, 'icon': 3538, '-no': 3539, 'esclavo': 3540, 'fines': 3541, 'darnos': 3542, 'valor': 3543, 'aportar': 3544, 'misión': 3545, 'preguntan': 3546, 'pita': 3547, 'SCORT': 3548, 'cobro': 3549, 'lochas': 3550, 'recomiende': 3551, 'non': 3552, 'falo': 3553, 'moito': 3554, 'galego': 3555, 'GRACIÑAS': 3556, 'tmbn': 3557, 'abandonadisimo': 3558, 'engañada': 3559, 'vara': 3560, 'quiz': 3561, 'eición': 3562, 'ensayo': 3563, 'acaban': 3564, 'efectivamente': 3565, 'píldora': 3566, 'viral': 3567, 'ilustrativa': 3568, 'libre;como': 3569, '>': 3570, 'temprano': 3571, 'FollowSpree': 3572, 'soñado': 3573, 'personajes': 3574, 'PLL': 3575, 'real': 3576, 'conocia': 3577, 'Shay': 3578, 'Lucy': 3579, 'yuriko': 3580, 'caca': 3581, 'grabarle': 3582, 'homosexual': 3583, 'odiosa': 3584, 'VALE': 3585, 'YA': 3586, 'FUNCIONA': 3587, 'ALELUYA': 3588, 'boton': 3589, 'palanza': 3590, 'poseída': 3591, 'Holly': 3592, 'calentura': 3593, 'llegas': 3594, 'cuernos': 3595, 'vivas': 3596, 'contarlo': 3597, 'arranco': 3598, 'preocupeis': 3599, 'P': 3600, 'juicio': 3601, 'carcel': 3602, 'Jajajaja': 3603, 'cuanto': 3604, 'salga': 3605, 'bucle': 3606, 'infinito': 3607, 'imprimo': 3608, 'mapas': 3609, 'filler': 3610, 'chicha': 3611, 'XDD': 3612, 'entra': 3613, 'Olimpo': 3614, 'Duel': 3615, 'bufeo': 3616, 'bombarderos': 3617, 'arreglen': 3618, 'putos': 3619, 'rammers': 3620, 'salen': 3621, 'ilesos': 3622, 'Podre': 3623, 'grabador': 3624, 'error': 3625, 'Volvere': 3626, 'evento': 3627, '1000': 3628, 'Cosa': 3629, 'Nostra': 3630, 'estado': 3631, 'puro': 3632, 'Don': 3633, 'Vito': 3634, 'comunicador': 3635, 'colmo': 3636, 'tardar': 3637, 'quedarte': 3638, 'perderte': 3639, 'guste': 3640, 'Escocia': 3641, 'precioso': 3642, 'norte': 3643, 'sur': 3644, 'levante': 3645, 'humedad': 3646, 'mosquitos': 3647, 'caló': 3648, 'azotado': 3649, 'parecer': 3650, 'ita\"': 3651, 'iSe': 3652, 've': 3653, 'divina': 3654, 'chinita': 3655, 'uds': 3656, 'Dormy': 3657, 'Ojala': 3658, 'presentándome': 3659, 'shawn': 3660, 'vergonzosa': 3661, 'nace': 3662, 'Nacho': 3663, 'cadena': 3664, 'pokemon': 3665, 'veian': 3666, 'rastreadores': 3667, 'campeón': 3668, 'pierda': 3669, 'CarlsenKarjakin': 3670, 'terminó': 3671, 'pasada': 3672, '.Mi': 3673, 'EVDLV': 3674, 'incalculables': 3675, 'arrochadas': 3676, 'oir': 3677, 'haran': 3678, 'wow': 3679, 'acuerdan': 3680, 'server': 3681, 'japonés': 3682, 'escucha': 3683, 'piro': 3684, 'piscina': 3685, 'estupendo': 3686, 'Confirmao': 3687, 'notado': 3688, 'hueso': 3689, 'movía': 3690, 'oeste': 3691, 'gana': 3692, 'probar': 3693, 'verdaderos': 3694, 'escucho': 3695, 'Instituciones': 3696, 'Sui': 3697, 'Generis': 3698, 'escarapela': 3699, 'apoyar': 3700, 'planta': 3701, 'enterito': 3702, 'Ves': 3703, 'quedándote': 3704, 'sitios': 3705, 'bonitos': 3706, 'SSS': 3707, 'és': 3708, 'lastima': 3709, 'ideas': 3710, 'diseño': 3711, 'Java': 3712, 'rinden': 3713, 'MicroSoft': 3714, 'eresiones': 3715, 'comunes': 3716, 'país': 3717, 'muestran': 3718, 'cultura': 3719, 'Vida': 3720, 'agregar': 3721, 'tocó': 3722, 'Festival': 3723, 'Navideño': 3724, 'PZ': 3725, 'lloviendo': 3726, 'Adivinen': 3727, 'quedé': 3728, 'PPK': 3729, 'jóvenes': 3730, 'marcharon': 3731, 'lucha': 3732, 'vano': 3733, 'MensajeALaNación': 3734, 'LaEducaciónSeRespeta': 3735, 'enojó': 3736, 'iva': 3737, 'pachanga': 3738, 'v': 3739, 'amiguito': 3740, 'resultó': 3741, 'querida': 3742, 'vimos': 3743, 'fluimos': 3744, 'oficia': 3745, 'Konoplyanka': 3746, 'barata': 3747, 'Reus': 3748, 'Bundes': 3749, 'Bienvenida': 3750, 'mentales': 3751, 'sufren': 3752, 'GetWellSoonSelenaFromSpain': 3753, 'promesita': 3754, '👉': 3755, '👈': 3756, 'ingrato': 3757, 'gustara': 3758, 'pingüino': 3759, 'esté': 3760, 'Díganme': 3761, 'ustedes': 3762, 'viejos': 3763, 'encantan': 3764, 'comprando': 3765, 'Kiko': 3766, 'revender': 3767, 'cupón': 3768, 'fds': 3769, 'Hotel': 3770, 'Chincha': 3771, 'pasaste': 3772, 'pendejo': 3773, 'vegetariano': 3774, 'logro': 3775, 'Luego': 3776, 'dulce': 3777, 'finde': 3778, 'cenar': 3779, 'cristal': 3780, 'inflado': 3781, 'barriga': 3782, 'Tienes': 3783, 'KI': 3784, 'Chicago': 3785, 'PD': 3786, 'autobús': 3787, 'Benidorm-Madrid': 3788, 'puertas': 3789, 'abiertas': 3790, 'tentado': 3791, 'subirme': 3792, 'Incendios': 3793, 'Forestales': 3794, 'basta': 3795, 'jodidos': 3796, 'Jejeje': 3797, 'explicado': 3798, 'tranqui': 3799, 'prefieres': 3800, 'Sue': 3801, 'reservaron': 3802, 'empiezas': 3803, 'palabra': 3804, 'preferida': 3805, 'gratitud': 3806, 'agradeciendo': 3807, 'cerrar': 3808, 'joderte': 3809, 'gol': 3810, 'perdimos': 3811, '8-1': 3812, 'LaPoderosaKeiko': 3813, '4to': 3814, 'ignorante': 3815, 'burbuja': 3816, 'sábado': 3817, 'tuiteros': 3818, 'disfrutar': 3819, 'coctel': 3820, 'evolucionar': 3821, 'tipos': 3822, 'idiota': 3823, 'tome': 3824, 'jarabe': 3825, 'tos': 3826, 'estuviera': 3827, 'borracha': 3828, 'encantando': 3829, 'animacion': 3830, 'encerio': 3831, 'background': 3832, 'Ptmr': 3833, 'presenta': 3834, 'trébol': 3835, 'gotica': 3836, 'presentó': 3837, 'cagada': 3838, 'niñuca': 3839, 'sensibilidad': 3840, 'valoro': 3841, 'refiero': 3842, 'Maria': 3843, 'Krisbell': 3844, 'Mandale': 3845, 'saluditos': 3846, 'ingratas': 3847, 'quiniela': 3848, 'mundiales': 3849, 'skins': 3850, 'definitivas': 3851, 'dejado': 3852, 'llorando': 3853, 'saltos': 3854, 'lágrimas': 3855, 'tenores': 3856, 'alma': 3857, 'lleguen': 3858, 'respetar': 3859, 'obligarte': 3860, 'fuerza': 3861, 'Agradecidos': 3862, 'miras': 3863, 'fun': 3864, 'Antu': 3865, 'deseos': 3866, 'Pos': 3867, 'limitada': 3868, 'aburrirse': 3869, 'larga': 3870, 'bellas': 3871, 'estarás': 3872, 'planes': 3873, 'Maldita': 3874, 'hombreee': 3875, 'montes': 3876, 'bici': 3877, 'sabrán': 3878, 'gloria': 3879, 'ánimo': 3880, 'llega': 3881, 'Aún': 3882, 'demasiados': 3883, 'pocos': 3884, 'Yolo': 3885, 'mondaymotivation': 3886, 'operación': 3887, 'Carmen': 3888, '♡': 3889, 'Conmigo': 3890, 'bloqueó': 3891, '7/8': 3892, 'eterno': 3893, 'necesitaba': 3894, 'compartirlo': 3895, 'NADA': 3896, 'sois': 3897, 'razón': 3898, 'pisco': 3899, 'buenazo': 3900, 'tmb': 3901, 'tristes': 3902, 'velorios': 3903, 'entierros': 3904, 'Papá': 3905, 'bebito': 3906, 'recien': 3907, 'nacido': 3908, 'Cosas': 3909, 'debemos': 3910, 'simplificar': 3911, 'cerebro': 3912, 'sentido': 3913, 'eliminar': 3914, 'Simple': 3915, 'sueles': 3916, 'reclamar': 3917, 'sobrentendidos': 3918, 'mira': 3919, 'seductora': 3920, 'debió': 3921, 'asumir': 3922, 'femenino': 3923, 'cierre': 3924, 'VillardeOlalla': 3925, 'Cuenca': 3926, 'Preparados': 3927, 'traído': 3928, 'perra': 3929, 'seis': 3930, 'nerviosa': 3931, 'delgada': 3932, 'llegue': 3933, 'gustaba': 3934, 'cuadrado': 3935, 'prometo': 3936, 'alegrado': 3937, 'detalle': 3938, 'Bello': 3939, 'enternecedor': 3940, 'Mil': 3941, 'besos': 3942, 'iniciar': 3943, 'noticias': 3944, 'sep': 3945, 'MUY': 3946, 'lectora': 3947, 'círculo': 3948, 'amistades': 3949, 'entera': 3950, 'saldrá': 3951, 'relacionado': 3952, 'paisajes': 3953, 'increíbles': 3954, 'rencorosa': 3955, 'vuelto': 3956, 'energías': 3957, 'renovadas': 3958, 'Doctor': 3959, 'Amor': 3960, 'consulta': 3961, 'periscope': 3962, 'Prohibirlo': 3963, 'campañas': 3964, 'pedagogía': 3965, 'aplaudir': 3966, 'pseudo-feministas': 3967, 'mente': 3968, 'soñadora': 3969, 'puñado': 3970, 'posible': 3971, 'cogerme': 3972, 'manos': 3973, 'suciaaaaas': 3974, 'jodido': 3975, 'suelo': 3976, 'harto': 3977, 'intento': 3978, 'supuesto': 3979, 'pases': 3980, 'atasca': 3981, 'garganta': 3982, 'Meduele': 3983, 'Esas': 3984, 'costillitas': 3985, 'ven': 3986, 'platónico': 3987, 'gay': 3988, 'dejé': 3989, 'pampa': 3990, 'lindísima': 3991, 'llegáis': 3992, 'Favstar': 3993, 'cretácico': 3994, 'duráis': 3995, 'suspiro': 3996, 'neuronas': 3997, 'jopé': 3998, 'linea': 3999, 'juegas': 4000, 'seguirás': 4001, 'buenisimo': 4002, 'LOL': 4003, 'miguez': 4004, 'hagas': 4005, 'VASCA': 4006, 'alli': 4007, 'SE': 4008, 'FOLLA': 4009, 'culpa': 4010, 'muuuchos': 4011, 'elementos': 4012, 'primeras': 4013, 'agregan': 4014, 'nuevos': 4015, 'periodistas': 4016, 'Nación': 4017, 'ud': 4018, 'dueños': 4019, 'vea.11': 4020, 'perfectas': 4021, 'DIOS': 4022, 'NECESITO': 4023, 'QUE': 4024, 'ALGUN': 4025, 'DIA': 4026, 'CONFIRME': 4027, 'jode': 4028, 'pantalon': 4029, 'pitillo': 4030, 'quede': 4031, 'PITILLO': 4032, 'vaqueros': 4033, 'Haces': 4034, 'melancolía': 4035, 'devuelves': 4036, 'ábacos': 4037, 'permitidos': 4038, 'Sobre': 4039, 'saben': 4040, 'usarlo': 4041, 'relativo': 4042, 'secesión': 4043, 'estimado': 4044, 'amante': 4045, 'marcianadas': 4046, 'debatir': 4047, 'entretenido': 4048, 'cabron': 4049, 'ultima': 4050, '😁': 4051, 'árbol': 4052, 'camisa': 4053, 'taller': 4054, 'arruinar': 4055, 'realice': 4056, 'llamada': 4057, 'internacional': 4058, 'Chile': 4059, 'tambor': 4060, 'rutina': 4061, 'recuperar': 4062, 'Empezare': 4063, 'descargarme': 4064, 'Manchester': 4065, 'City': 4066, 'West': 4067, 'Ham': 4068, 'eclipse': 4069, 'certero': 4070, 'mariaa': 4071, 'Tenlo': 4072, 'avisaré': 4073, 'beso': 4074, 'Shits': 4075, 'happens': 4076, 'concilio': 4077, 'Nicea': 4078, 'fumado': 4079, 'explico': 4080, 'm': 4081, 'barca': 4082, 'pierde': 4083, 'qe': 4084, 'influya': 4085, 'madrid': 4086, 'cmo': 4087, 'tuani': 4088, 'IA': 4089, 'dinamización': 4090, 'fecha': 4091, 'caducidad': 4092, 'abrumador': 4093, 'Entramos': 4094, 'pilas': 4095, 'cargadas': 4096, 'vuestra': 4097, 'clínica': 4098, 'dental': 4099, 'confianza': 4100, 'Lamentable': 4101, 'informan': 4102, 'murió': 4103, 'Gabriel': 4104, 'Badilla': 4105, 'RIPGladiador': 4106, 'guarda': 4107, 'perdurara': 4108, 'eternidad': 4109, 'Quien': 4110, 'encuentra': 4111, 'conforma': 4112, 'Broder': 4113, 'pinxe': 4114, 'tráfico': 4115, 'Salaverry': 4116, 'UPC': 4117, 'jodas': 4118, 'solucionao': 4119, 'casualidad': 4120, 'arruinado': 4121, 'coge': 4122, 'agradecerte': 4123, 'tantísimo': 4124, 'das': 4125, 'decirte': 4126, 'GRACIAS': 4127, 'Obviamente': 4128, 'e-mail': 4129, 'ENCIMA': 4130, 'podré': 4131, 'ahi': 4132, 'cambiando': 4133, 'hábitos': 4134, 'estilo': 4135, 'enseñes': 4136, 'aprenda': 4137, 'hicimos': 4138, 'queria': 4139, 'coaching': 4140, 'raptor': 4141, '700R': 4142, 'special': 4143, 'edition': 4144, '$': 4145, '000': 4146, 'BELLEZA': 4147, 'Lástima': 4148, 'sentado': 4149, 'hormiguero': 4150, 'miraré': 4151, 'Spidey': 4152, 'rallando': 4153, 'necesitamos': 4154, 'comunicado': 4155, 'ok': 4156, 'hacerle': 4157, 'drama': 4158, 'resto': 4159, 'VMA': 4160, 'flexible': 4161, 'horarios': 4162, 'tecnica': 4163, 'quieras': 4164, 'explorar': 4165, 'vet': 4166, 'Aslitan': 4167, 'enfermito': 4168, 'Sra.': 4169, 'perrito': 4170, 'operando': 4171, 'AI': 4172, '100': 4173, 'enciende': 4174, 'ruter': 4175, 'mg': 4176, 'wee': 4177, 'Veo': 4178, 'tropical': 4179, 'convierte': 4180, 'llamará': 4181, 'Otto': 4182, 'comience': 4183, 'MemeFest': 4184, 'recuerda': 4185, 'Iman': 4186, 'siente': 4187, 'vacío': 4188, 'bulla': 4189, 'razonablemente': 4190, 'jajajajaja': 4191, 'Bon': 4192, 'Egun': 4193, 'on': 4194, 'reyes': 4195, 'magos': 4196, 'llegaron': 4197, 'oro': 4198, 'incienso': 4199, 'mirra': 4200, 'Melchoro': 4201, 'Alan': 4202, 'Toledo': 4203, 'vastadehuasquear': 4204, 'Ollanta': 4205, 'nadinevagastar': 4206, 'odebrechlen': 4207, 'Gracioso': 4208, 'puedan': 4209, 'acercar': 4210, 'escapao': 4211, 'dragonite': 4212, 'arcanie': 4213, 'bayas': 4214, 'frambu': 4215, 'superball': 4216, 'zorros': 4217, 'impotencias': 4218, 'Entiende': 4219, 'significa': 4220, 'resignación': 4221, 'ignorada': 4222, 'lamentarme': 4223, 'aprovechar': 4224, 'vibra': 4225, 'transmite': 4226, '36,5': 4227, '°C': 4228, 'sombra': 4229, 'comenzar': 4230, 'GoT': 4231, 'Looking': 4232, 'Queers': 4233, 'as': 4234, 'Folk': 4235, 'gays': 4236, 'adopta': 4237, 'chiqui': 4238, 'colacao': 4239, 'grito': 4240, 'mayúscula': 4241, 'curiosa': 4242, 'fortuna': 4243, 'etapas': 4244, 'juro': 4245, 'inmitándole': 4246, 'Buenas': 4247, '😻': 4248, '💜': 4249, 'Yaco': 4250, 'decia': 4251, 'Patricio': 4252, 'personalmente': 4253, 'económicos': 4254, 'récord': 4255, 'trimestre': 4256, 'hacéis': 4257, 'Iba': 4258, 'peero': 4259, 'detienen': 4260, 'sere': 4261, 'egresada': 4262, '21': 4263, 'años,2': 4264, 'carreras': 4265, 'estudios': 4266, 'europa': 4267, 'excelente': 4268, 'dr': 4269, 'tratamiento': 4270, 'medicina': 4271, 'natural': 4272, 'alergias': 4273, 'aire': 4274, 'acondionado': 4275, 'agentes': 4276, 'pesadilla': 4277, 'Lunes': 4278, 'Llego': 4279, '9:20': 4280, 'caminando': 4281, 'dormidos': 4282, 'Oh': 4283, 'nice': 4284, 'viéndome': 4285, 'cuarta': 4286, 'Kill': 4287, 'Bill': 4288, 'oportunista': 4289, 'ocaciones': 4290, 'vender': 4291, 'seestrenasietevidas': 4292, 'Garfield': 4293, 'vago': 4294, 'Mg': 4295, 'adjetivo': 4296, 'repelente': 4297, 'nombre': 4298, 'solitos': 4299, 'felizmente': 4300, 'fijo': 4301, 'quitan': 4302, 'hemos': 4303, 'gracia': 4304, 'páde': 4305, 'RafaGuerrero': 4306, 'natación': 4307, 'modorra': 4308, 'repasar': 4309, 'ladilla': 4310, 'chevere': 4311, 'asesinos': 4312, 'codición': 4313, 'humanos': 4314, 'depende': 4315, 'acciones': 4316, 'Congratulations': 4317, 'Dr.': 4318, 'Alejandro': 4319, 'peruano': 4320, 'eligió': 4321, 'gobernar': 4322, 'congreso': 4323, 'manchado': 4324, 'aldea': 4325, 'quizá': 4326, 'tierno': 4327, 'haciéndolo': 4328, 'pensba': 4329, 'reflexion': 4330, 'profunda': 4331, 'algun': 4332, 'proximo': 4333, 'gustaria': 4334, 'saberlo': 4335, 'Ando': 4336, 'lentes': 4337, 'contacto': 4338, 'Vale': 4339, 'psicóloga': 4340, 'cristiana': 4341, 'acertado': 4342, 'Calvin': 4343, '1': 4344, 'aciertos': 4345, 'VMAs': 4346, 'gustazo': 4347, 'dibujarte': 4348, 'propios': 4349, 'posters': 4350, 'envio': 4351, 'Amanda': 4352, 'empiezo': 4353, 'ratings': 4354, 'insultarlos': 4355, 'comisaria': 4356, 'AMPLIANDO': 4357, 'LA': 4358, 'DENUNCIA': 4359, 'POR': 4360, 'ACOSO': 4361, 'descubrir': 4362, 'Filip': 4363, 'der': 4364, 'Cruyssen': 4365, 'increibles': 4366, 'fotografia': 4367, 'retratos': 4368, 'practico': 4369, 'dijiste': 4370, 'VAPES': 4371, 'alegrarnos': 4372, 'conejito': 4373, 'llámala': 4374, 'mándala': 4375, 'realmente': 4376, 'hallo': 4377, 'km': 4378, 'catarro': 4379, 'Descansa': 4380, 'sueñes': 4381, 'hayan': 4382, 'diseñado': 4383, 'propia': 4384, 'condicionados': 4385, 'lecturas': 4386, 'Vienen': 4387, 'gloriosos': 4388, 'volvieron': 4389, 'Abrazote': 4390, 'enorme': 4391, 'Sos': 4392, 'dejó': 4393, 'fueran': 4394, 'cámaras': 4395, 'cobalto': 4396, 'broncearme': 4397, 'manchas': 4398, '⚠': 4399, 'aparezca': 4400, 'escucharlo': 4401, 'Venir': 4402, 'pasarte': 4403, 'MUSU': 4404, 'bocadillo': 4405, 'lomo': 4406, 'delito': 4407, 'Musucomotequierojoderperoatusbocadillosmás': 4408, '2x1': 4409, 'puntos': 4410, 'Hut': 4411, 'pésimas': 4412, 'Peazo': 4413, 'abuelo': 4414, 'pletorico': 4415, 'pierna': 4416, 'puñetazo': 4417, 'aye': 4418, 'agresivo': 4419, 'sonido': 4420, 'Desearía': 4421, 'aurin': 4422, 'sucia': 4423, 'mojada': 4424, 'duerma': 4425, 'cnmigo': 4426, 'aprendizaje': 4427, 'obtenido': 4428, ';)': 4429, 'Comenzando': 4430, 'enfermandome': 4431, 'contribución': 4432, 'sientes': 4433, 'Echo': 4434, 'Irlanda': 4435, 'alternativo': 4436, 'Gante': 4437, 'fuese': 4438, 'actualizar': 4439, 'presupuesto': 4440, 'indicaciones': 4441, '296798': 4442, 'duoq': 4443, 'cuqui': 4444, 'odiabas': 4445, 'superficial': 4446, 'mencionas': 4447, 'compras': 4448, 'cuerpo': 4449, 'llevado': 4450, 'hermano': 4451, 'cambiaria': 4452, 'Porqué': 4453, 'costra': 4454, 'enfermerita': 4455, 'Decepcionado': 4456, 'acostumbrado': 4457, 'juegan': 4458, 'chutar': 4459, 'apañados': 4460, 'Ninguno': 4461, 'Pronto': 4462, 'malita': 4463, 'quejo': 4464, 'frio': 4465, 'solucion': 4466, 'frase': 4467, 'sabadete': 4468, 'Socialistas': 4469, 'honrados': 4470, 'oxímoron': 4471, 'levantarse': 4472, 'resaca': 4473, 'Parece': 4474, 'olor': 4475, 'cesado': 4476, 'misma': 4477, 'darán': 4478, 'canasta': 4479, 'navideña': 4480, 'aparte': 4481, 'panetón': 4482, 'proveedores': 4483, 'engríen': 4484, 'jefes': 4485, 'gallina': 4486, 'quedese': 4487, 'tomese': 4488, 'pastillitas': 4489, 'siga': 4490, 'echandole': 4491, 'youtubers': 4492, 'ayyy': 4493, 'soniditos': 4494, 'musicales': 4495, 'distintos': 4496, 'bb': 4497, 'ohhhhh': 4498, 'hombres': 4499, 'vetados': 4500, '😀': 4501, 'catear': 4502, 'inglés': 4503, 'cómic': 4504, 'bronca': 4505, 'barcos': 4506, 'putas': 4507, 'propongo': 4508, 'cambi': 4509, 'frío': 4510, 'Argentina': 4511, 'tengan': 4512, 'pisos': 4513, 'llevan': 4514, 'solos': 4515, 'viciarme': 4516, 'nooo': 4517, 'pordede': 4518, 'Dentro': 4519, '9': 4520, 'sabor': 4521, 'Querido': 4522, 'Arturo': 4523, 'viniendo': 4524, 'agradece': 4525, 'cumplido': 4526, 'titular': 4527, 'ostia': 4528, 'jugaba': 4529, 'SNES': 4530, 'acabé': 4531, 'encantaban': 4532, 'Quería': 4533, 'grabar': 4534, 'amanecer': 4535, 'tirado': 4536, 'queso': 4537, 'favorito': 4538, 'UberEmpanadas': 4539, 'provecho': 4540, 'n': 4541, 'escarmentams': 4542, 'mismas': 4543, 'encueshshtasshs': 4544, 'Lindo': 4545, 'productoras': 4546, 'estaban': 4547, 'centradas': 4548, 'compa': 4549, 'olvidado': 4550, 'humana': 4551, 'Weee': 4552, 'perno': 4553, 'U': 4554, 'salvar': 4555, 'pishe': 4556, 'palo': 4557, 'compartir': 4558, 'pregunta': 4559, 'Ask': 4560, '2.0': 4561, 'Maruchi': 4562, 'peña': 4563, 'íbamos': 4564, 'estudio': 4565, 'Peppa': 4566, 'Pig*esto': 4567, 'Queremos': 4568, 'Scream': 4569, 'Sabeis': 4570, 'abandonan': 4571, 'fea': 4572, 'gorda': 4573, 'pfff': 4574, 'pesadisimo': 4575, 'xd': 4576, 'Quién': 4577, 'anima': 4578, 'planchar': 4579, 'mitología': 4580, 'colección': 4581, '60': 4582, 'tomos': 4583, '😫': 4584, 'jugo': 4585, 'naranja': 4586, 'Léete': 4587, '80%': 4588, 'pobladores': 4589, 'ubicados': 4590, 'estiman': 4591, '50': 4592, 'muertos': 4593, 'Lima': 4594, 'tirarme': 4595, 'gordi': 4596, 'Amazon': 4597, 'siéntete': 4598, 'afortunada': 4599, 'vocero': 4600, 'Lewin': 4601, 'Mejía': 4602, 'amago': 4603, 'bodega': 4604, 'manual': 4605, 'PES': 4606, 'cambia': 4607, 'jugando': 4608, 'leyenda': 4609, '0': 4610, 'velocidad': 4611, 'IMPRESIONANTE': 4612, 'PES2017': 4613, 'Melanie': 4614, 'echaron': 4615, 'SINVERGUENZAS': 4616, 'recordamos': 4617, 'Bajón': 4618, 'Ed': 4619, 'Sheeran': 4620, 'llorera': 4621, 'asegurada': 4622, 'opción': 4623, 'coche': 4624, 'aburrida': 4625, '-Estás': 4626, '-Si': 4627, 'reconocelo': 4628, 'abu+': 4629, 'triana': 4630, 'deti': 4631, 'Contacta': 4632, 'estúpido': 4633, 'herida': 4634, 'cicatrizada': 4635, 'importando': 4636, 'Zarcero': 4637, 'haha': 4638, 'Mmmm': 4639, 'Supongo': 4640, 'lógico': 4641, 'tuvieran': 4642, 'Bienvenido': 4643, 'Septiembre': 4644, 'marca': 4645, 'comienzo': 4646, 'objetivos': 4647, 'cumplir': 4648, 'FelizJueves': 4649, 'autoengañarse': 4650, 'moreee': 4651, 'easyy': 4652, 'terminamos': 4653, 'vivos': 4654, 'engordo': 4655, 'Perdóneme': 4656, 'excitante': 4657, 'Cocina': 4658, 'rutinaria': 4659, 'oficinismo': 4660, 'poh': 4661, 'divertida': 4662, 'retransmisión': 4663, 'reviento': 4664, 'comido': 4665, 'box': 4666, 'kebab': 4667, 'ayudadme': 4668, 'Internet': 4669, 'ilimitado': 4670, 'G': 4671, 'contrate': 4672, 'aso': 4673, 'santander': 4674, 'productora': 4675, 'radiofónica': 4676, 'salí': 4677, 'salgo': 4678, 'chilena': 4679, '\\xa0': 4680, 'amable': 4681, 'cariñosa': 4682, 'achucharte': 4683, 'TuitUtil': 4684, 'ponéis': 4685, 'Entró': 4686, 'laboro': 4687, 'apena': 4688, 'crisis': 4689, 'allá': 4690, 'Gerudo': 4691, 'Podría': 4692, 'lcp': 4693, 'galleta': 4694, 'rellenita': 4695, 'céntimos': 4696, 'vasito': 4697, 'cifrut': 4698, 'Sigamos': 4699, 'Cuidado': 4700, 'deseas': 4701, 'acuerdas': 4702, 'pesados': 4703, 'fuimos': 4704, 'sacamos': 4705, 'Pocas': 4706, 'maneras': 4707, 'ocurren': 4708, 'pudieras': 4709, 'coges': 4710, 'ave': 4711, 'harias': 4712, 'postrecito': 4713, 'endulzarme': 4714, 'crei': 4715, 'expulsion': 4716, 'parecio': 4717, 'tongo': 4718, 'Ares': 4719, 'robados': 4720, 'aquella': 4721, 'animo': 4722, 'ofender': 4723, 'focas': 4724, 'estafada': 4725, 'hamburguesa': 4726, 'pollo': 4727, 'pavo': 4728, '🦃': 4729, 'nomegusta': 4730, 'comentarios': 4731, 'Graciaaas': 4732, 'vernos': 4733, 'FBC': 4734, 'Visto': 4735, 'LO': 4736, 'menuda': 4737, 'promoción': 4738, 'gentuza': 4739, 'envidiosa': 4740, 'denunciar': 4741, '¬¬': 4742, 'Jonasito': 4743, 'calentando': 4744, 'entonar': 4745, 'Wagner': 4746, 'desánimo': 4747, 'soberanismo': 4748, 'Arrimadas': 4749, '400.000': 4750, 'inscritos': 4751, 'cientos': 4752, 'Desánimo': 4753, 'Castalla': 4754, 'oportunamente': 4755, 'celebran': 4756, 'Moros': 4757, 'i': 4758, 'Cristians': 4759, 'pasta': 4760, 'Año': 4761, 'Nuevo': 4762, 'podrían': 4763, 'actores': 4764, 'puestos': 4765, 'paripe': 4766, 'profesionales': 4767, 'eliminada': 4768, 'Nooo': 4769, 'eliminado': 4770, 'Pasó': 4771, 'semifinal': 4772, 'cantoso': 4773, 'returns': 4774, 'carga': 4775, 'religiosa': 4776, 'trabajos': 4777, 'citado': 4778, 'varias': 4779, 'Heidegger': 4780, 'tuíter': 4781, 'esfuerzo': 4782, 'victoria': 4783, 'Albacete': 4784, 'acompañar': 4785, 'Alicia': 4786, 'Emilia': 4787, 'mandaba': 4788, 'porel': 4789, 'RELAJESE': 4790, 'VA': 4791, 'QUEDAR': 4792, 'crushes': 4793, 'llevéis': 4794, 'Guerrero': 4795, 'leeejos': 4796, 'lanzado': 4797, 'acostumbrarme': 4798, 'dientes': 4799, 'ciudadochicos': 4800, 'jajajaj': 4801, 'adelgazado': 4802, 'aumentado': 4803, 'músculo': 4804, 'Mario': 4805, 'Bros': 4806, 'cruzó': 4807, '200': 4808, 'mató': 4809, '4000': 4810, 'enemigos': 4811, 'princesa': 4812, 'mandarle': 4813, 'mensaje.-.-': 4814, 'grandioso': 4815, 'conocer': 4816, 'maravillosas': 4817, 'horribles': 4818, 'citizen': 4819, 'sonríe': 4820, 'Volverdevacaciones': 4821, 'figura': 4822, 'magearna': 4823, 'retrasando': 4824, 'vendedor': 4825, 'normalmente': 4826, 'pack': 4827, 'acabar': 4828, 'muuuuuuuuy': 4829, 'contentas': 4830, 'Entonces': 4831, 'sufres': 4832, 'Intenta': 4833, 'andaba': 4834, 'parranda': 4835, 'podio': 4836, 'cómico': 4837, 'diferencia': 4838, 'altura': 4839, 'prendieron': 4840, 'fuego': 4841, 'cantaron': 4842, 'fila': 4843, 'baño': 4844, 'explicas': 4845, 'parlamento': 4846, 'monos': 4847, 'sentados': 4848, 'ramas': 4849, 'árboles': 4850, 'gustado': 4851, 'habían': 4852, 'Pétalos': 4853, 'viento': 4854, 'tirón': 4855, 'tf': 4856, 'FelizLunes': 4857, 'defiendes': 4858, 'apoyas': 4859, 'activista': 4860, 'machista': 4861, 'opresor': 4862, 'caido': 4863, 'genialmente': 4864, 'pelota': 4865, 'compañera': 4866, 'estuvo': 4867, 'enamorada': 4868, 'grado': 4869, 'Momento': 4870, 'emprendedores': 4871, 'Congreso': 4872, 'Diputados': 4873, 'cita': 4874, 'startups': 4875, 'innovadores': 4876, 'sociales': 4877, 'necesario': 4878, 'sig': 4879, 'temporal': 4880, 'arregle': 4881, 'Vuelta': 4882, 'asignaturas': 4883, 'preferidas': 4884, 'Empezamos': 4885, 'Oposalud': 4886, 'salido': 4887, 'defensa': 4888, 'clásicos': 4889, 'gratamente': 4890, 'sorprendida': 4891, '🤖': 4892, 'mu': 4893, 'bn': 4894, 'borde': 4895, 'xq': 4896, 'sesion': 4897, 'clasicos': 4898, 'be': 4899, 'imaginar': 4900, 'reducido': 4901, 'carreteras': 4902, 'prevenir': 4903, 'accidentes': 4904, 'trenes': 4905, 'Encantado': 4906, 'visitaros': 4907, 'Málaga': 4908, 'Ah': 4909, 'suelta': 4910, 'llamando': 4911, 'wifi': 4912, 'apagado': 4913, 'CuriousCat': 4914, 'Antes': 4915, 'Tener': 4916, 'panza': 4917, 'embarazada': 4918, 'terminas': 4919, 'Apoyen': 4920, 'Network': 4921, 'network': 4922, 'hare': 4923, 'habran': 4924, 'absurdo': 4925, 'argumentamos': 4926, 'españoles': 4927, 'obligados': 4928, 'sonyer': 4929, 'entendiste': 4930, 'trama': 4931, 'véala': 4932, 'Búscame': 4933, 'Zapdos': 4934, 'legales': 4935, 'gustan': 4936, 'wapo': 4937, 'sobrina': 4938, 'pasaría': 4939, 'Angelita': 4940, 'inteligente': 4941, 'conviene': 4942, 'PONTE': 4943, 'BONITA': 4944, 'ENERO': 4945, 'ht': 4946, 'spam': 4947, 'surgió': 4948, 'Noooo': 4949, 'Lucena': 4950, 'tranquilos': 4951, 'seguía': 4952, 'Besets': 4953, 'boku': 4954, 'dake': 4955, 'ga': 4956, 'inai': 4957, 'machi': 4958, 'comenzamos': 4959, 'adiosagosto': 4960, 'cantar': 4961, 'estupida': 4962, 'curar': 4963, 'través': 4964, 'piernas': 4965, 'médico': 4966, 'yendo': 4967, 'ello': 4968, 'RoadToPixel': 4969, 'coraje': 4970, 'lxs': 4971, 'prepotentxs': 4972, 'Av': 4973, 'prado': 4974, 'salgantodos': 4975, 'ahhh': 4976, 'rubias': 4977, 'distraído': 4978, 'políticas': 4979, 'PP': 4980, 'discutibles': 4981, 'políticos': 4982, 'Quw': 4983, '36': 4984, 'finales': 4985, 'prendida': 4986, 'apago': 4987, 'optimistas': 4988, 'haberle': 4989, 'haberte': 4990, 'mencionado': 4991, 'aceptado': 4992, 'reembolsarme': 4993, 'cobertura': 4994, 'marítima': 4995, 'advirtió': 4996, 'típica': 4997, 'picha': 4998, 'Mami': 4999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3) Añadir más capas\n",
        "\n",
        "Agregar más capas a un modelo Sequential es sencillo. Basta con usar el método .add() para incluir nuevas capas. A continuación se añade una capa densa adicional y una capa de dropout para regularización. Hay que tener cuidado con no tener sobreajuste:"
      ],
      "metadata": {
        "id": "Svk5lnmsbGKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=100, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "#vector_size = 64\n",
        "#model.add(Embedding(vocab_size, vector_size))\n",
        "\n",
        "# Añadir una capa de aplanado (Flatten) para aplanar la entrada, convirtiendo los datos multidimensionales en un vector unidimensional\n",
        "model.add(Flatten())\n",
        "\n",
        "# Añadimos una nueva capa densa con activación ReLU\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "# Añadimos una capa de dropout para regularización\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "E2pkyeKcbR73",
        "outputId": "c0be109d-3e45-4592-fe94-f9edd2d8e1f9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.4) Cambiar las funciones de activación\n",
        "\n",
        "Cambiar la función de activación es tan simple como actualizar el argumento de activación en las capas que lo permitan. Por ejemplo, para cambiar la función de activación de la nueva capa densa a tanh, se puede hacer así:"
      ],
      "metadata": {
        "id": "Bi1hcyBabgfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=100, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# Añadir una capa de aplanado (Flatten) para aplanar la entrada, convirtiendo los datos multidimensionales en un vector unidimensional\n",
        "model.add(Flatten())\n",
        "\n",
        "# Cambiando a tanh\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "\n",
        "# Añadimos una capa de dropout para regularización\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t02_1F9ZbqBl",
        "outputId": "56116944-af0c-4539-c34f-8b40512ffcb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │          \u001b[38;5;34m15,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,000\u001b[0m (58.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> (58.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,000\u001b[0m (58.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> (58.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.5) Utilizar RNN\n",
        "\n",
        "Para implementar un modelo que utilice redes neuronales recurrentes en Keras, basta con incluir capas como SimpleRNN, LSTM (Long Short-Term Memory), o GRU (Gated Recurrent Units), que son diseñadas para manejar dependencias de secuencias a lo largo del tiempo:"
      ],
      "metadata": {
        "id": "62bZMg-Xex-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "embedding_dim = 128\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "#model.add(Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# # SimpleRNN con 64 unidades\n",
        "#model.add(SimpleRNN(units=64))\n",
        "model.add(Bidirectional(SimpleRNN(64, return_sequences=False)))\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "fRJyFKKae7n9",
        "outputId": "6eea76ce-430c-49ed-bf25-d8273afb6f8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1) LSTM"
      ],
      "metadata": {
        "id": "7us5buCmfn6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "embedding_dim = 128\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "#model.add(Embedding(vocab_size, embedding_dim, input_length=100, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "YDZYgaM7hIqm",
        "outputId": "7e4d4073-9954-48d5-d8f5-45465503948a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │       \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2)GRU"
      ],
      "metadata": {
        "id": "yrnDqgOnfu8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "embedding_dim = 128\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "#model.add(Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# # GRU con 50 unidades\n",
        "model.add(Bidirectional(GRU(64, return_sequences=False)))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Req28dYEfwzm",
        "outputId": "b03e0716-2a8e-47b4-afe7-f3f6ec7f7843"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.6) Utilizar Embeddings Preentrenados en vez de one-hot encoding\n",
        "\n",
        "Existen varios embeddings preentrenados disponibles que se podrían utilizar. Algunos de los más populares incluyen:\n",
        "\n",
        "- Word2Vec: Entrenado en Google News dataset, disponible en varios tamaños.\n",
        "   \n",
        "- GloVe (Global Vectors for Word Representation): Disponible en varios tamaños y entrenado en diferentes corpus como Wikipedia o Twitter.\n",
        "\n",
        "- FastText: Ofrecido por Facebook, similar a Word2Vec pero también considera subpalabras."
      ],
      "metadata": {
        "id": "FqFNGkltUqgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.6.1) Descarga de embeddings en español"
      ],
      "metadata": {
        "id": "UZCa3rqPVYsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Descargar la versión comprimida de FastText en español (300MB en lugar de varios GB)\n",
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.es.vec\"\n",
        "print(\"Descargando embeddings...\")\n",
        "response = requests.get(url)\n",
        "\n",
        "# Guardar el archivo\n",
        "with open(\"wiki.es.vec\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"Embeddings descargados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qufsxvBe6fhE",
        "outputId": "a3863fc9-92d8-4b0a-b265-5102fd6f0100"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando embeddings...\n",
            "Embeddings descargados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.2) Cargar los Embeddings\n",
        "Primero, hay que descargar los embeddings y cargarlos en nuestro entorno."
      ],
      "metadata": {
        "id": "chVyEKeiU4Qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "# Cargamos solo las 10,000 palabras más comunes para ahorrar memoria\n",
        "embeddings = KeyedVectors.load_word2vec_format('wiki.es.vec', limit=10000)"
      ],
      "metadata": {
        "id": "CyZYl7Oj69Z5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.3) Preparar la Matriz de Embeddings de los datos de entrenamiento\n",
        "Vamos a crear una matriz de embeddings para usar en la capa de Embedding de Keras. Esta matriz debe tener un vector para cada palabra del vocabulario:"
      ],
      "metadata": {
        "id": "zq7Kd3usWAjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Primero creamos un tokenizador\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Ahora obtenemos el word_index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Crear la matriz de embeddings\n",
        "embedding_dim = 300  # FastText usa 300 dimensiones\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= vocab_size:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = embeddings[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except KeyError:\n",
        "        continue\n",
        "\n",
        "print(\"Matriz de embeddings creada\")"
      ],
      "metadata": {
        "id": "E6rvl1YLWGO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e6cff4-e607-4861-9b6a-6d179b1d380d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de embeddings creada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.4) Diseñar el Modelo con la Capa de Embedding Preentrenada\n",
        "Ahora ya podemos crear el modelo utilizando la matriz de embeddings en la capa de Embedding. Es importante establecer trainable=False para no modificar los embeddings durante el entrenamiento:"
      ],
      "metadata": {
        "id": "r-V8JugLWXQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "# Crear una red secuencial para el modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Añadir una capa inicial de embedding que transforma los índices de palabras en vectores densos\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# Añadir una capa de aplanado (Flatten) para aplanar la entrada, convirtiendo los datos multidimensionales en un vector unidimensional\n",
        "model.add(Flatten())\n",
        "\n",
        "# Añadir una capa densa con 1 neurona para una salida binaria con una función de activación sigmoid para clasificación binaria\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "Dpiiw0wPWdXL",
        "outputId": "9e22b416-baf3-4d98-e727-7b46b198ae4e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │       \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación puedes volver al paso 3 para entrenar el modelo"
      ],
      "metadata": {
        "id": "yiIfV6UA3uVS"
      }
    }
  ]
}