{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traducción de Inglés a Sindarin",
   "id": "3bb8d98c335e60cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funciones listas para traducir una frase o una traducción en bloque:",
   "id": "8d86d73a3c635a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:23:43.261981Z",
     "start_time": "2024-12-26T16:23:43.046013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "token = \"\"\n",
    "print(\"Hugging Face logging\")\n",
    "login(token)\n",
    "\n",
    "def translate(text, model, tokenizer, do_sample=False, temperature=1.0):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs, do_sample=do_sample, temperature=temperature)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def translate_batch(texts, model, tokenizer, batch_size=32, do_sample=False, temperature=1.0):\n",
    "    translations = []\n",
    "    model.eval()  # Asegurarse de estar en modo inferencia\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Usar GPU si está disponible\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Deshabilitar gradientes para inferencia\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, max_length=90, padding=True).to(device)\n",
    "            translated_tokens = model.generate(**inputs, do_sample=do_sample, temperature=temperature)\n",
    "            translations.extend(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True))\n",
    "\n",
    "    return translations"
   ],
   "id": "6bf8a033aaf43756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face logging\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preparar un conjunto de entrenamiento y otro de evaluación para la tarea de traducir de Inglés a Sindarin, para maximizar las posibilidades de obtener buenos resultados vamos a realizar un entrenamiento y evaluación con overfit. Para ello, prepare un",
   "id": "815e27d9c73fb8ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:23:50.037982Z",
     "start_time": "2024-12-26T16:23:47.009696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libs.lotr_ds_builder import build_datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train, test = build_datasets()\n",
    "train_dataset = train['Sindarin']\n",
    "test_dataset = test['Sindarin']\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "eval_dataset = Dataset.from_dict(test_dataset)\n",
    "\n",
    "# TODO: Mostrar la primera frase, la utilizaremos para probar los modelos\n",
    "print(\">\", train_dataset['translation'][0])"
   ],
   "id": "f2edad9214d04b3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sindarin': 163, 'Adûnaic': 28, 'Black Speech': 26, 'Quenya': 45, 'Rohirric': 19}\n",
      "{'Sindarin': 65, 'Rohirric': 18}\n",
      "> {'en': 'Who brings to us this token of darkness?', 'fo': 'Man ammen toltha i dann hen morn?'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenar un modelo MarianMT",
   "id": "6e7d3541bb8ff43a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, MarianConfig\n",
    "\n",
    "# Crear configuración para un modelo Marian en blanco\n",
    "config = MarianConfig(\n",
    "    vocab_size=32000,  # Tamaño del vocabulario (ajústalo según tu caso)\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    encoder_attention_heads=8,\n",
    "    decoder_attention_heads=8,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1,\n",
    "    pad_token_id=0,\n",
    "    eos_token_id=1,\n",
    "    bos_token_id=2,\n",
    ")\n",
    "\n",
    "# Crear el modelo MarianMT desde cero\n",
    "marian_model_trained = MarianMTModel(config)\n",
    "\n",
    "# Crear un tokenizador vacío (puedes cargar o definir tu propio vocabulario)\n",
    "marian_tokenizer_trained = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "marian_model_trained.resize_token_embeddings(len(marian_tokenizer_trained))\n",
    "\n",
    "\n",
    "marian_model_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "# Ajustar el tamaño del vocabulario del modelo Marian para que coincida con el tokenizador\n",
    "marian_tokenizer_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "\n",
    "def load_trained_marian():\n",
    "    marian_model = MarianMTModel.from_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "    marian_tokenizer = MarianTokenizer.from_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "    return marian_model, marian_tokenizer\n",
    "\n"
   ],
   "id": "32164aad639c5b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T21:14:07.777703Z",
     "start_time": "2024-12-25T21:12:16.926805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/training/trained-marian-en-sindarin\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "marian_model_trained, marian_tokenizer_trained = load_trained_marian()\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global marian_tokenizer_trained\n",
    "    inputs_lang = [example['en'] for example in examples['translation']]\n",
    "    targets_lang =  [example['fo'] for example in examples['translation']]\n",
    "\n",
    "    model_inputs = marian_tokenizer_trained(inputs_lang, text_target=targets_lang, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "encoded_training_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=marian_tokenizer_trained, model=marian_model_trained)\n",
    "trainer = Trainer(\n",
    "    model=marian_model_trained,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_training_dataset,\n",
    "    eval_dataset=encoded_eval_dataset,\n",
    "    data_collator= collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "marian_model_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "marian_tokenizer_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "\n",
    "marian_trained_model, marian_trained_tokenizer = load_trained_marian()\n",
    "text = [\"Who brings to us this token of darkness?\"]\n",
    "translated_text = translate(text, marian_trained_model, marian_trained_tokenizer)\n",
    "print(\">Marian trained: \", translated_text)"
   ],
   "id": "6b50e19e80638d35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 163/163 [00:00<00:00, 3424.73 examples/s]\n",
      "Map: 100%|██████████| 65/65 [00:00<00:00, 6570.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 01:38, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.461216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.911453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.543131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.232056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreacimmino/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Marian trained:  ãùãÞnnnnnnnnnnnnnnnnnn\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entrenar un modelo T5\n",
    "Utilizar un modelo T5 en blanco y entrenarlo enteramente con el dataset inglés-sindarin."
   ],
   "id": "267a91a90aa51f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T21:15:28.184548Z",
     "start_time": "2024-12-25T21:15:26.000307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "\n",
    "# Crear configuración para un modelo T5 en blanco\n",
    "config = T5Config(\n",
    "    vocab_size=32000,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1,\n",
    "    pad_token_id=0,  # Token de padding\n",
    "    eos_token_id=1,  # Token de fin de secuencia\n",
    "    decoder_start_token_id=0,  # Token de inicio del decodificador\n",
    ")\n",
    "\n",
    "t5_model_trained = T5ForConditionalGeneration(config)\n",
    "\n",
    "t5_tokenizer_trained = T5Tokenizer.from_pretrained(\"vgaraujov/t5-base-translation-en-es\")\n",
    "\n",
    "t5_model_trained.save_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "t5_tokenizer_trained.save_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "\n",
    "def load_t5():\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "    return t5_model, t5_tokenizer\n"
   ],
   "id": "48fefd1f03c131fb",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilizando el primer modelo, generar una version refinada que esté entrenada con el dataset",
   "id": "eeb6b092f20d4300"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T21:19:10.274711Z",
     "start_time": "2024-12-25T21:18:05.290049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/training/trained-t5-en-sindarin\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "t5_model_trained, t5_tokenizer_trained = load_t5()\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global t5_tokenizer_trained\n",
    "    inputs_lang = [example['en'] for example in examples['translation']]\n",
    "    targets_lang =  [example['fo'] for example in examples['translation']]\n",
    "\n",
    "    model_inputs = t5_tokenizer_trained(inputs_lang, text_target=targets_lang, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "encoded_training_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=t5_tokenizer_trained, model=t5_model_trained)\n",
    "trainer = Trainer(\n",
    "    model=t5_model_trained,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_training_dataset,\n",
    "    eval_dataset=encoded_eval_dataset,\n",
    "    data_collator= collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "t5_model_trained.save_pretrained(\"./models/trained-t5-en-es\")\n",
    "t5_tokenizer_trained.save_pretrained(\"./models/trained-t5-en-es\")\n",
    "\n",
    "\n",
    "t5_trained_model, t5_trained_tokenizer = load_t5()\n",
    "text = [\"Who brings to us this token of darkness?\"]\n",
    "translated_text = translate(text, t5_trained_model, t5_trained_tokenizer)\n",
    "print(\">Marian trained: \", translated_text)"
   ],
   "id": "b47d9ab597deab9d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 163/163 [00:00<00:00, 6571.49 examples/s]\n",
      "Map: 100%|██████████| 65/65 [00:00<00:00, 6328.45 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:58, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.989416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.776430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.646415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreacimmino/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Marian trained:  \n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Usando el modelo LLama para la traducción",
   "id": "9d237054c7d2d9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:55:27.637281Z",
     "start_time": "2024-12-26T16:53:00.738401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def load_tinyllama_model():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", cache_dir=\"./models/tiny_llama\", local_files_only=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", cache_dir=\"./models/tiny_llama\", local_files_only=False)\n",
    "    return model, tokenizer\n",
    "\n",
    "def prompt_llama(text, model, tokenizer, do_sample=False, temperature=1.0,  max_length=50):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    translated_tokens = model.generate(**inputs, do_sample=do_sample, temperature=temperature)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "llama_model, llama_tokenizer = load_tinyllama_model()\n",
    "text = [\n",
    "    \"Translate to Sindarin: 'Who brings to us this token of darkness?'\"\n",
    "]\n",
    "translated_text = prompt_llama(text, llama_model, llama_tokenizer, do_sample=True, temperature=0.7)\n",
    "print(\">LLama trained: \", translated_text)"
   ],
   "id": "7a15d105fd401338",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 20\u001B[0m\n\u001B[1;32m     16\u001B[0m llama_model, llama_tokenizer \u001B[38;5;241m=\u001B[39m load_tinyllama_model()\n\u001B[1;32m     17\u001B[0m text \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTranslate to Sindarin: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWho brings to us this token of darkness?\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     19\u001B[0m ]\n\u001B[0;32m---> 20\u001B[0m translated_text \u001B[38;5;241m=\u001B[39m \u001B[43mprompt_llama\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllama_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllama_tokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>LLama trained: \u001B[39m\u001B[38;5;124m\"\u001B[39m, translated_text)\n",
      "Cell \u001B[0;32mIn[17], line 11\u001B[0m, in \u001B[0;36mprompt_llama\u001B[0;34m(text, model, tokenizer, do_sample, temperature, max_length)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprompt_llama\u001B[39m(text, model, tokenizer, do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m,  max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):\n\u001B[1;32m     10\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m tokenizer(text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39mmax_length)\n\u001B[0;32m---> 11\u001B[0m     translated_tokens \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     translated_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(translated_tokens[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m translated_text\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2215\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2207\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2208\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2209\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2210\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2211\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2212\u001B[0m     )\n\u001B[1;32m   2214\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2215\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2216\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2222\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2225\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2226\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   2227\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   2228\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   2229\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2234\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   2235\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:3206\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3203\u001B[0m model_inputs\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_hidden_states\u001B[39m\u001B[38;5;124m\"\u001B[39m: output_hidden_states} \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;28;01melse\u001B[39;00m {})\n\u001B[1;32m   3205\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 3206\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3208\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3209\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3210\u001B[0m     outputs,\n\u001B[1;32m   3211\u001B[0m     model_kwargs,\n\u001B[1;32m   3212\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3213\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1190\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001B[0m\n\u001B[1;32m   1187\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1190\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1197\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1198\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1203\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpretraining_tp \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:945\u001B[0m, in \u001B[0;36mLlamaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    933\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    934\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    935\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    942\u001B[0m         position_embeddings,\n\u001B[1;32m    943\u001B[0m     )\n\u001B[1;32m    944\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 945\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    950\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    956\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:676\u001B[0m, in \u001B[0;36mLlamaDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    673\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[1;32m    675\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 676\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    687\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    689\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/UEX/Sesion1_MT/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:612\u001B[0m, in \u001B[0;36mLlamaSdpaAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    602\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mscaled_dot_product_attention(\n\u001B[1;32m    603\u001B[0m     query_states,\n\u001B[1;32m    604\u001B[0m     key_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    608\u001B[0m     is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[1;32m    609\u001B[0m )\n\u001B[1;32m    611\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m--> 612\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[43mattn_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbsz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    614\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mo_proj(attn_output)\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m attn_output, \u001B[38;5;28;01mNone\u001B[39;00m, past_key_value\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparar todos los modelos usando las metricas BLEU, METEOR y ROUGE",
   "id": "d38362b7cede7913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T21:22:57.354119Z",
     "start_time": "2024-12-25T21:22:43.092618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "expected_results = [ [row['fo']] for row in eval_dataset['translation']]\n",
    "inputs = [row['en'] for row in eval_dataset['translation']]\n",
    "\n",
    "t5_trained_results = translate_batch(inputs, t5_trained_model, t5_trained_tokenizer, do_sample=True, temperature=1.2)\n",
    "marianmt_trained_results = translate_batch(inputs, marian_trained_model, marian_trained_tokenizer)\n",
    "\n",
    "print(\"Expected Results:\", expected_results)\n",
    "print(\"T5 Translations:\", t5_trained_results)\n",
    "print(\"Marian Translations:\", marianmt_trained_results)\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "bleu_t5_trained = bleu_metric.compute(predictions=t5_trained_results, references=expected_results)\n",
    "meteor_t5_trained = meteor_metric.compute(predictions=t5_trained_results, references=expected_results)\n",
    "rouge_t5_trained = rouge_metric.compute(predictions=t5_trained_results, references=expected_results)\n",
    "\n",
    "bleu_marian_trained = bleu_metric.compute(predictions=marianmt_trained_results, references=expected_results)\n",
    "meteor_marian_trained = meteor_metric.compute(predictions=marianmt_trained_results, references=expected_results)\n",
    "rouge_marian_trained = rouge_metric.compute(predictions=marianmt_trained_results, references=expected_results)\n"
   ],
   "id": "33323ab6d28dbca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Results: [['Hiro hyn hîdh ab ’wanath.'], ['Aragorn, nad no ennas!'], ['Man cenich?'], ['Man le trasta, Brego?'], ['Man cenich?'], ['Ú i vethed'], ['nâ i onnad.'], ['Minlû pedich nin'], ['i aur hen telitha.'], ['Ú i vethednâ i onnad.'], ['Boe bedich go Frodo.'], ['Dolen i vâd o nin.'], ['Si peliannen i vâd na dail lîn.'], ['Si boe ú-dhannathach.'], ['Ae ú-esteliach nad'], ['estelio han'], ['estelio ammen.'], ['Estelio han.'], ['Estelio han.'], ['Estelio veleth.'], ['Nach gwannatha sin?'], ['Ma nathach hi gwannathach or minuial archened?'], ['Ú-ethelithon.'], ['Estelio guru lîn ne dagor.'], ['Ethelithach.'], ['Ú-bedin o gurth ne dagor.'], ['O man pedich?'], ['Edra le men, men na guil edwen'], ['haer o auth a nîr a naeth.'], ['Tollen, i lû.'], ['I chair gwannar na Valannor. Si bado, no círar.'], ['Ah im, ú-’erin veleth lîn?'], ['Gerich veleth nîn, ada.'], ['I amar prestar aen.'], ['Han mathon ne nen.'], ['Han mathon ne chae.'], ['A han noston ned ’wilith.'], ['Mae carnen, Brego, mellon nîn.'], ['Le abdollen.'], ['Hannon le.'], ['Boe a hyn'], ['Neled heraindan caer menig.'], ['Si, beriathar hyn ammaeg na ned Edoras.'], ['Aragorn, nedin dagor hen ú-’erir ortheri.'], ['Natha daged dhaer'], ['Ú-moe edaved, Legolas'], ['Mae govannen, Haldir.'], ['A Eruchîn, ú-dano i faelas a hyn'], ['an uben tanatha le faelas!'], ['Dartho!'], ['Tangado a chadad!'], ['Faeg i-varv dîn na lanc'], ['a nu ranc!'], ['Hado i philinn!'], ['Pendraith!'], ['Na fennas!'], ['Hado ribed! Hado!'], ['Togo hon dad, Legolas!'], ['Dago hon!'], ['Dago hon!'], ['Hado i philinn!'], ['Herio!'], ['Nan barad!'], ['Nan barad!'], ['Nan barad!']]\n",
      "T5 Translations: ['aclaró aclaró aclaró aclaró aclarójust diseña diseña diseña caravana Superliga lechugaectoectoectoectoectoecto', 'podrían podrían podrían podrían podrían podrían podrían audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual', '(20 (20 Qui autonomía autonomía Classic Classic gustan gustan favorable favorable diferenciPuedoPuedoPuedo redujo redujo reyes reyes', 'ATAT psiquiátrico finalistas finalistas demostraba demostraba demostraba demostraba demostraba demostraba demostraba fluctuaciones fluctuaciones fluctuaciones precaria precaria precaria precaria', 'influenciado influenciado homenaje homenaje homenaje homenaje enamorados purificación purificación purificación purificación climático climático climático climático climático climáticoprofesionalprofesional', 'excarcela excarcela policíasPorquéPorquéPorquéPorquéPorqué dirigencia dirigencia Xalapa Xalapa Xalapa Xalapa Xalapa Xalapa Xalapa Xalapabilización', 'expedi aprendiz fijar habitantes habitantes habitantes habitantes habitantes Funcionarios Funcionarios Funcionarios Funcionarios Af Af Af Af Af cupón cupón', 'amerita pierdo pierdo[9][9][9][9] iniciarse iniciarse iniciarse iniciarse iniciarse iniciarse iniciarse iniciarse iniciarse iniciarse FC FC', 'reproducir reproducir imbécil imbécil imbécil imbécil imbécil imbécil Sentí Sentí Sentíollar hernia duerm Sinaloa Sinaloa Sinaloa Sinaloa Sinaloa', 'legalidad legalidad Müller Müller Müller Müller lustro onda onda onda egipcios egipcios egipcios egipcios egipcios egipcios Esteban Esteban sueldo', 'lavandería terminar terminar terminar homólogo homólogo homólogo cerr cerr cerr cerr cerr cerr Presta Presta Permíta Permíta Permíta esguince', 'Superior Superior Superior Superior minúscula minúscula minúscula minúscula minúscula Muhammad222222 reactivación reactivación reactivación pseudo pseudo pseudo', 'Otra Otra Otra Otra Otra Otra Otra dependencias dependencias dependencias dependencias dependencias dependencias sonido sonido sonido sonido sonido sonido', 'tóxico tóxico tóxico tóxico homólogo homólogo homólogo homólogo tecnológicas tecnológicas tecnológicas tecnológicas tecnológicas tecnológicaslidadfiliafiliafilia', 'Jackie Jackie Jackie contenida contenida contenida contenida contenida contenidablablablabla High High High High rebosa estableció', 'cajita cajita cajita cajitaSu Term multiplicidad multiplicidad participar participar participar participar participar participar participar gobernante gobernante gobernante gobernante', 'fluctuaciones fluctuaciones fluctuaciones fluctuaciones Square Square Square Square Square Square Square Square Square Square Xu Entertainment Entertainment Entertainment', 'internautas Competencia Competencia Competencia Competencia Competencia Competencia Competenciaservservservservserv corrigiendo corrigiendo corrigiendo corrigiendo Funcionarios hago', 'repleto repleto repleto repleto omisión omisión omisión omisión grave iglesia iglesia iglesia iglesia iglesia iglesia iglesia iglesia procesión intervenido', 'implementó implementó implementó monoplaza monoplaza Pontevedra Pontevedra Pontevedra Pontevedra hombres hombresinginginginginginginging', 'NONONONONONO Auditoría Auditoría ofertas ofertas ofertas ofertas ofertas ofertas ofertas ofertas ofertas Superliga Superliga', '46 46 fotógrafos Aguascalientes Aguascalientes Aguascalientes Simula Simula SimulaOlvid especialista especialista especialista especialista especialista especialistakovkovkov', 'tóxico audiovisual audiovisual audiovisualinginginginginginginginging homólogo homólogo homólogo homólogo', 'complot internas internas Ministro Ministro Ministro murales murales cebolla cebolla cebolla cebolla cebolla cebolla cebolla cebolla cebolla cebolla cebolla', 'importación importación Entertainment Superliga Superliga Funcionarios Funcionarios Funcionarios ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar ocasionar', 'Hermanos haciéndome haciéndomeculpculp achaca achaca achaca achaca achaca achaca achaca achaca desahogo Lleva Lleva metí metí metí', 'metíienLASLASLASLASLAS Cord Cord Cord Cord Cord Cord Cord Cord agred agred divertirse divertirse', 'Otra Otra molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó molestó', 'dupla echaba echaba echaba echaba Villanueva Villanueva Villanueva contagiargico Otra violencia violencia protagonizada protagonizada crímenes crímenes brujas ético', 'isla isla isla isla isla Bah Bah Bahtrabajotrabajo educado educado educado Quiroga recupera recupera reproducir reproducir reproducir', 'nutricionista audiovisual proyección proyecciónstitución Entertainment Entertainment Entertainment Entertainment Entertainment Entertainment Entertainment Entertainment Entertainment auténtico Mantenga Mantenga Mantenga Mantenga', 'ancho contrastar Consultado Consultado Consultado Consultado Consultado Consultado Bueno Bueno comprando comprando comprando comprando comprando comprando comprando violencia violencia', 'reproducir reproducir reproducir reproducir sobrepasa sobrepasa venezolana venezolana venezolana goles goles goles goles goles goles goles goles goles goles', 'animaciones animaciones animaciones animaciones animaciones numeración escoja Solidaria Solidaria Solidaria Solidaria Podía consiguiera diciéndome diciéndome auténtico auténtico caravana prestan', 'TúTúTúTúTúTú Bah Bah Bah BahSTR capacidad corredores corredores corredorestificacióntificacióntificación', 'Simula Simula Simula treintena Betty Betty Betty Betty Betty Betty Betty Betty Betty dependencias infertilidad infertilidad infertilidad propiedades ahorr', 'imbécil imbécil imbécil imbécil imbécil imbécil imbécil imbécil imbécil imbécil imbécil sentado reyes reyesVayaVayaVayaVayaVaya', 'bodegas entradas entradas entradas entradasPORTridge esclarecer esclarecer esclarecer esclarecer esclarecer esclarecer esclarecer esclarecer Antigua Antigua Antigua Antigua', 'echaba echaba reproducir reproducir reproduciringing internas Word contratos contratoscienda designar designar desayuno desayuno desayuno desayuno rollo', 'dependiente dependiente dependiente dependiente dependienteNuestroNuestroNuestro tips tips tips nominada nominada nominada nominada nominada nominada nominada', 'admiro admiro admiro estarían guardia guardia{{StarStarStarStarStarStarStar hacíamos hacíamos hacíamos hacíamos', 'señalado señalado señalado 2013. prestan internas internas internas internas internas internas internas internas Angélica Angélica integrantes estuviera estuviera estuviera', 'prioridad prioridad prioridad prioridad prioridad presunto presunto Option Option Option Option Option Option Option ataca cerebral cerebral cerebral cerebral', 'Jacinto Jacinto Jacinto Jacinto Jacinto Jacinto Jacinto Jacinto Atenas Atenas Atenas ingresos Comodoro reorganización reorganización reorganización reorganización reorganizaciónollar', 'semillas comienzan Rayo Rayo Rayo Infobae Infobae Infobae ocupación ocupación ocupación ocupación ocupación ocupación ocupación ocupación ocupación ocupación ocupación', 'plasmar plasmar plasmar plasmar plasmar plasmar roba roba roba roba roba roba roba roba roba robaciendaciendacienda', 'alejar alejar alejar alejar dicta dicta dicta dicta dicta dicta dicta acercar acercar acercar acercar acercar indica indica indica', 'RedRed dependencias WiFi WiFi plasmar poseía poseía inalámbrico inalámbrico inalámbrico velada nominada legalidad Mori Mori Mori incluyó incluyó', 'Gamb Gamb Gamb Select Select audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual audiovisual insurgenteutilizautilizautiliza', 'Esteban Esteban iniciado iniciado iniciado iniciado iniciado iniciado iniciado Distancia Distancia Distancia Distanciarece 1.5 1.5 1.5 1.5 1.5', 'expedi sindical sindical sindical sindical sindical sindical avisos Gaza montura montura montura rótulo rótulo rótulo rotativoecto acercá fusiones', 'angular angular angular angular angular angular angular angular angular angular angular prestanCTCTCTCTCTCTCT', 'Gastos Gastos Gastos Gastos Gastos Gastos Gastos Gastoslidadlidadlidadlidadlidadlidadlidadlidadbilización DT DT', 'Esteban Esteban Esteban Estebankovkovkovkovkovkovkovkovkov recibían Jefatura Xu caravana caravana caravana', 'auténtico auténticoOlvidOlvidOlvid Mori Mori Mori odiaba odiaba odiaba movimientos movimientos movimientos movimientos movimientos movimientos movimientos movimientos', 'querer querer amante iPad iPad extraordinario querer querer quererfiliafilia reconocer reconocer reconocer reconocer hombres hombres hombres hombres', 'bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexual bisexualcía calibre desesper desesper', 'caucaucaucau corrigiendo corrigiendo corrigiendo corrigiendo corrigiendo corrigiendo corrigiendo corrigiendo refleja refleja refleja refleja refleja refleja embutido', 'Marsellaieárseloárselolúlú calibre Bahamas fusionesococ Economía Economía Economía vicisitudes vicisitudes Chiqui Chiqui fusiones', 'L L L L L L L L L L L L L L L Consulting rotativo mosquet mosquet', 'reducirá reducirá reducirá reducirá reducirá reduciráchuQUQUQUQUQUtándolotándolotándolocaucaucaucau', 'anual Capricornio Villanueva Villanueva Villanueva Villanueva Villanueva Villanueva suaves suaves letras Cord Jamaica repleto posicionar posicionar posicionar posicionar posicionar', 'monoplaza monoplaza monoplaza monoplaza monoplaza animó brujas desactivar desactivar desactivar Intente Intente Intente Intente MÁS MÁS MÁS Superliga Superliga', 'AT Bah Bah Bah Bah Bah Bah Bah Bah Bah tirón Work brujas perteneció brujas creyentes despertar despertar despertar', 'monoplaza preguntaron preguntaron preguntaron preguntaron preguntaron preguntaron preguntaronrryrry InstitucionalMOSMOSMOSMOSMOS prácticas prácticas prácticas']\n",
      "Marian Translations: ['ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn', 'ãùãÞnnnnnnnnnnnnnnnnnn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreacimmino/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/andreacimmino/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/andreacimmino/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T21:23:10.853496Z",
     "start_time": "2024-12-25T21:23:10.303641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sustituye estos valores por los resultados reales\n",
    "scores_t5 = {\n",
    "    \"BLEU\": bleu_t5_trained['bleu'],\n",
    "    \"METEOR\": meteor_t5_trained[\"meteor\"],\n",
    "    \"ROUGE-1\": rouge_t5_trained[\"rouge1\"],\n",
    "    \"ROUGE-2\": rouge_t5_trained[\"rouge2\"],\n",
    "    \"ROUGE-L\": rouge_t5_trained[\"rougeL\"]\n",
    "}\n",
    "\n",
    "scores_marian = {\n",
    "    \"BLEU\": bleu_marian_trained[\"bleu\"],\n",
    "    \"METEOR\": meteor_marian_trained[\"meteor\"],\n",
    "    \"ROUGE-1\": rouge_marian_trained[\"rouge1\"],\n",
    "    \"ROUGE-2\": rouge_marian_trained[\"rouge2\"],\n",
    "    \"ROUGE-L\": rouge_marian_trained[\"rougeL\"],\n",
    "}\n",
    "\n",
    "# Crear gráfico\n",
    "labels = list(scores_t5.keys())\n",
    "t5_values = list(scores_t5.values())\n",
    "marian_values = list(scores_marian.values())\n",
    "\n",
    "x = range(len(labels))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, t5_values, width=0.4, label=\"T5\", align=\"center\")\n",
    "plt.bar([i + 0.4 for i in x], marian_values, width=0.4, label=\"MarianMT\", align=\"center\")\n",
    "\n",
    "# Configurar etiquetas y leyenda\n",
    "plt.xticks([i + 0.2 for i in x], labels)\n",
    "plt.xlabel(\"Métricas\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.title(\"Comparación de Métricas entre T5 y MarianMT\")\n",
    "plt.legend()"
   ],
   "id": "5fb81492ed6ea467",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2583fae50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
