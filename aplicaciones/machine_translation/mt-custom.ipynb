{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traducción de Inglés a Sindarin",
   "id": "3bb8d98c335e60cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funciones listas para traducir una frase o una traducción en bloque:",
   "id": "8d86d73a3c635a40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "token = \"\"\n",
    "print(\"Hugging Face logging\")\n",
    "login(token)\n",
    "\n",
    "def translate(text, model, tokenizer, do_sample=False, temperature=1.0):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs, do_sample=do_sample, temperature=temperature)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def translate_batch(texts, model, tokenizer, batch_size=32, do_sample=False, temperature=1.0):\n",
    "    translations = []\n",
    "    model.eval()  # Asegurarse de estar en modo inferencia\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Usar GPU si está disponible\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Deshabilitar gradientes para inferencia\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, max_length=90, padding=True).to(device)\n",
    "            translated_tokens = model.generate(**inputs, do_sample=do_sample, temperature=temperature)\n",
    "            translations.extend(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True))\n",
    "\n",
    "    return translations"
   ],
   "id": "6bf8a033aaf43756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preparar un conjunto de entrenamiento y otro de evaluación para la tarea de traducir de Inglés a Sindarin, para maximizar las posibilidades de obtener buenos resultados vamos a realizar un entrenamiento y evaluación con overfit. Para ello, prepare un",
   "id": "815e27d9c73fb8ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from libs.lotr_ds_builder import build_datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# TODO: Utilizar la función build_datasets() y generar un traing_dataset y test_dataset de Inglés a Sindarin\n",
    "\n",
    "# TODO: Cargar los datasets usando la clase Dataset\n",
    "\n",
    "# DONE: Mostrar la primera frase, la utilizaremos para probar los modelos\n",
    "print(\">\", train_dataset['translation'][0])"
   ],
   "id": "f2edad9214d04b3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenar un modelo MarianMT",
   "id": "6e7d3541bb8ff43a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, MarianConfig\n",
    "\n",
    "# Crear configuración para un modelo Marian en blanco\n",
    "config = MarianConfig(\n",
    "    vocab_size=32000,  # Tamaño del vocabulario (ajústalo según tu caso)\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    encoder_attention_heads=8,\n",
    "    decoder_attention_heads=8,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1,\n",
    "    pad_token_id=0,\n",
    "    eos_token_id=1,\n",
    "    bos_token_id=2,\n",
    ")\n",
    "\n",
    "# Crear el modelo MarianMT desde cero\n",
    "marian_model_trained = MarianMTModel(config)\n",
    "\n",
    "# Crear un tokenizador vacío (puedes cargar o definir tu propio vocabulario)\n",
    "marian_tokenizer_trained = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "marian_model_trained.resize_token_embeddings(len(marian_tokenizer_trained))\n",
    "\n",
    "\n",
    "marian_model_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "# Ajustar el tamaño del vocabulario del modelo Marian para que coincida con el tokenizador\n",
    "marian_tokenizer_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "\n",
    "def load_trained_marian():\n",
    "    marian_model = MarianMTModel.from_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "    marian_tokenizer = MarianTokenizer.from_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "    return marian_model, marian_tokenizer\n",
    "\n"
   ],
   "id": "32164aad639c5b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/training/trained-marian-en-sindarin\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "marian_model_trained, marian_tokenizer_trained = load_trained_marian()\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global marian_tokenizer_trained\n",
    "    inputs_lang = [example['en'] for example in examples['translation']]\n",
    "    targets_lang =  [example['fo'] for example in examples['translation']]\n",
    "\n",
    "    model_inputs = marian_tokenizer_trained(inputs_lang, text_target=targets_lang, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "encoded_training_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=marian_tokenizer_trained, model=marian_model_trained)\n",
    "trainer = Trainer(\n",
    "    model=marian_model_trained,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_training_dataset,\n",
    "    eval_dataset=encoded_eval_dataset,\n",
    "    data_collator= collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "marian_model_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "marian_tokenizer_trained.save_pretrained(\"./models/trained-marian-en-sindarin\")\n",
    "\n",
    "marian_trained_model, marian_trained_tokenizer = load_trained_marian()\n",
    "text = \"Who brings to us this token of darkness?\"\n",
    "translated_text = translate(text, marian_trained_model, marian_trained_tokenizer)\n",
    "print(\">Marian trained: \", translated_text)"
   ],
   "id": "6b50e19e80638d35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entrenar un modelo T5\n",
    "Utilizar un modelo T5 en blanco y entrenarlo enteramente con el dataset inglés-sindarin."
   ],
   "id": "267a91a90aa51f56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "\n",
    "# Crear configuración para un modelo T5 en blanco\n",
    "config = T5Config(\n",
    "    vocab_size=32000,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1,\n",
    "    pad_token_id=0,  # Token de padding\n",
    "    eos_token_id=1,  # Token de fin de secuencia\n",
    "    decoder_start_token_id=0,  # Token de inicio del decodificador\n",
    ")\n",
    "\n",
    "t5_model_trained = T5ForConditionalGeneration(config)\n",
    "\n",
    "t5_tokenizer_trained = T5Tokenizer.from_pretrained(\"vgaraujov/t5-base-translation-en-es\")\n",
    "\n",
    "t5_model_trained.save_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "t5_tokenizer_trained.save_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "\n",
    "def load_t5():\n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(\"./models/trained-t5-en-sindarin\")\n",
    "    return t5_model, t5_tokenizer\n"
   ],
   "id": "48fefd1f03c131fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilizando el primer modelo, generar una version refinada que esté entrenada con el dataset",
   "id": "eeb6b092f20d4300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/training/trained-t5-en-sindarin\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: Cargar y entrear el modelo `./models/trained-t5-en-sindarin`\n",
    "\n",
    "\n",
    "t5_trained_model, t5_trained_tokenizer = load_t5()\n",
    "text = \"Who brings to us this token of darkness?\"\n",
    "translated_text = translate(text, t5_trained_model, t5_trained_tokenizer)\n",
    "print(\">Marian trained: \", translated_text)"
   ],
   "id": "b47d9ab597deab9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparar todos los modelos usando las metricas BLEU, METEOR y ROUGE",
   "id": "d38362b7cede7913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "expected_results = [ [row['fo']] for row in eval_dataset['translation']]\n",
    "inputs = [row['en'] for row in eval_dataset['translation']]\n",
    "\n",
    "# TODO: calcular las metricas y guardarlas respectivamente en bleu_t5_trained, meteor_t5_trained, rouge_t5_trained y las equivalentes para marian\n",
    "\n"
   ],
   "id": "33323ab6d28dbca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sustituye estos valores por los resultados reales\n",
    "scores_t5 = {\n",
    "    \"BLEU\": bleu_t5_trained['bleu'],\n",
    "    \"METEOR\": meteor_t5_trained[\"meteor\"],\n",
    "    \"ROUGE-1\": rouge_t5_trained[\"rouge1\"],\n",
    "    \"ROUGE-2\": rouge_t5_trained[\"rouge2\"],\n",
    "    \"ROUGE-L\": rouge_t5_trained[\"rougeL\"]\n",
    "}\n",
    "\n",
    "scores_marian = {\n",
    "    \"BLEU\": bleu_marian_trained[\"bleu\"],\n",
    "    \"METEOR\": meteor_marian_trained[\"meteor\"],\n",
    "    \"ROUGE-1\": rouge_marian_trained[\"rouge1\"],\n",
    "    \"ROUGE-2\": rouge_marian_trained[\"rouge2\"],\n",
    "    \"ROUGE-L\": rouge_marian_trained[\"rougeL\"],\n",
    "}\n",
    "\n",
    "# Crear gráfico\n",
    "labels = list(scores_t5.keys())\n",
    "t5_values = list(scores_t5.values())\n",
    "marian_values = list(scores_marian.values())\n",
    "\n",
    "x = range(len(labels))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, t5_values, width=0.4, label=\"T5\", align=\"center\")\n",
    "plt.bar([i + 0.4 for i in x], marian_values, width=0.4, label=\"MarianMT\", align=\"center\")\n",
    "\n",
    "# Configurar etiquetas y leyenda\n",
    "plt.xticks([i + 0.2 for i in x], labels)\n",
    "plt.xlabel(\"Métricas\")\n",
    "plt.ylabel(\"Puntaje\")\n",
    "plt.title(\"Comparación de Métricas entre T5 y MarianMT\")\n",
    "plt.legend()"
   ],
   "id": "5fb81492ed6ea467",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
