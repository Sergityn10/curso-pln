{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste fino del modelo `tiny-llama`"
      ],
      "metadata": {
        "id": "fvCzDQnpb-68"
      },
      "id": "fvCzDQnpb-68"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESTE NOTEBOOK NO FUNCIONARÁ EN UN MAC OS POR LOS REQUISITOS TÉCNICOS DEL TRAINER**"
      ],
      "metadata": {
        "id": "9_iwJ5k5bvFp"
      },
      "id": "9_iwJ5k5bvFp"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-18T16:59:57.362396Z",
          "start_time": "2025-01-18T16:59:56.872785Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e8b16578cd7dc34",
        "outputId": "3efac86d-0a2b-4a44-9ebd-78d3d8ca81a1"
      },
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "token = \"\"\n",
        "print(\"Hugging Face logging\")\n",
        "login(token)"
      ],
      "id": "8e8b16578cd7dc34",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face logging\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-18T16:59:57.369883Z",
          "start_time": "2025-01-18T16:59:57.366935Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dcc2801542a58a",
        "outputId": "87cd5b5b-bc1b-4f6f-87c3-aea7690ed34c"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n"
      ],
      "id": "7dcc2801542a58a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets trl"
      ],
      "metadata": {
        "id": "iYpZQNCpcJ_0"
      },
      "id": "iYpZQNCpcJ_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ef73d09e98622764"
      },
      "cell_type": "markdown",
      "source": [
        "## Cargar el modelo + tokenizador"
      ],
      "id": "ef73d09e98622764"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-18T17:06:48.270390Z",
          "start_time": "2025-01-18T17:06:41.785935Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0e071d98173f19c",
        "outputId": "e04672da-6819-488e-ec9e-f9dae0b118e1"
      },
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "cache_dir = \"./models/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float32 if device == \"mps\" else (torch.float16 if torch.cuda.is_available() else torch.float32),\n",
        "            cache_dir=cache_dir,\n",
        "            local_files_only=False,\n",
        "        ).to(device)\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "id": "a0e071d98173f19c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "id": "a16522e60c88175c"
      },
      "cell_type": "markdown",
      "source": [
        "## Cargar el dataset y preprocesar los datos"
      ],
      "id": "a16522e60c88175c"
    },
    {
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-01-18T17:00:05.728395Z",
          "start_time": "2025-01-18T17:00:03.538664Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "82f323e0aeca46f3955a76515354de8f",
            "6f2fe803b68d4cc293df292f3ed07cde",
            "182b0ee0432446208c2e66838777f023",
            "661b295b83a54452a07ebe324942f1ad",
            "c66be6cb91ff41089f9f57f2b4bd334e",
            "fdee23af289247779d0041258fb54100",
            "d8e434e7562a4550aaed00ee5bf970e2",
            "e28a6850e09049f5979e63a83e5c752a",
            "af307f04a81a415a806c71181030bab9",
            "091b7ff1c0c0409f9793cc175d041f7b",
            "43a5cb03d28c425cbf282226b492a525"
          ]
        },
        "id": "initial_id",
        "outputId": "d5f350ec-b468-4118-e8f1-39e3271bf7fa"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "dataset = load_dataset(dataset_name, split=\"train\", cache_dir=\"./data/guanaco-llama2-1k\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    max_length = 512  # Longitud máxima que permite el modelo\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "    )\n",
        "    return tokenized\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "\n",
        "print(dataset)"
      ],
      "id": "initial_id",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f323e0aeca46f3955a76515354de8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 1000\n",
            "})\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "metadata": {
        "id": "d22f2fed92127161"
      },
      "cell_type": "markdown",
      "source": [
        "## Configurar y ejecutar el entrenamiento"
      ],
      "id": "d22f2fed92127161"
    },
    {
      "metadata": {
        "id": "24d947bc2bbd1d2b"
      },
      "cell_type": "markdown",
      "source": [
        "Configurar PEFT (ajuste fino eficiente de parámetros)"
      ],
      "id": "24d947bc2bbd1d2b"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-18T17:02:27.443803Z",
          "start_time": "2025-01-18T17:02:27.438646Z"
        },
        "id": "717125f5bdb1264"
      },
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "id": "717125f5bdb1264",
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-18T17:08:47.964312Z",
          "start_time": "2025-01-18T17:08:47.465980Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1b1e2613f659da4b",
        "outputId": "adf47c3c-7fa4-443d-fc94-58d44eef8219"
      },
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=100,\n",
        "    max_steps=1000,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=False, # Poner a true si hay cuda\n",
        "    logging_steps=10,\n",
        "    output_dir=\"./output\",\n",
        "    save_total_limit=3,\n",
        "    report_to=\"none\",  # Desactiva W&B\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Establece en False para modelos de lenguaje causal\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    #peft_config=lora_config,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        ")\n",
        "fine_tuned_model = \"./models/TinyLlama-FT\"\n",
        "trainer.train()\n",
        "trainer.save_model(fine_tuned_model)"
      ],
      "id": "1b1e2613f659da4b",
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='272' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 272/1000 13:13 < 35:38, 0.34 it/s, Epoch 4.30/17]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>146.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 50:47, Epoch 15/17]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>146.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uso de los modelos"
      ],
      "metadata": {
        "id": "tcYXCDGzcXS3"
      },
      "id": "tcYXCDGzcXS3"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "class DialogueController:\n",
        "\n",
        "    def __init__(self, system_prompt, assistant_token=\"<|assistant|>\", keep_cronology=True):\n",
        "        self.system_prompt = system_prompt\n",
        "        self.prompt = [ { \"role\": \"system\", \"content\": system_prompt} ]\n",
        "        self.assistant_token = assistant_token\n",
        "        self.keep_cronology = keep_cronology\n",
        "\n",
        "    def get_prompt(self):\n",
        "        return self.prompt\n",
        "\n",
        "    def add_user_prompt(self, user_prompt, role=\"user\"):\n",
        "        user_prompt_json = { \"role\": role, \"content\":  user_prompt}\n",
        "        if self.keep_cronology:\n",
        "          self.prompt.append(user_prompt_json)\n",
        "        else:\n",
        "          self.prompt = [self.prompt[0], user_prompt_json]\n",
        "        return self.prompt\n",
        "\n",
        "    def add_assistant_prompt(self, assistant_prompt):\n",
        "        if self.keep_cronology:\n",
        "          assistant_prompt_exclusive = assistant_prompt.split(self.assistant_token)\n",
        "          final_prompt = \"\"\n",
        "          if len(assistant_prompt_exclusive) == 2:\n",
        "              final_prompt = assistant_prompt_exclusive[1]\n",
        "          self.add_user_prompt(final_prompt, role=\"assistant\")\n",
        "\n",
        "\n",
        "class Chatbot2:\n",
        "\n",
        "    def __init__(self, controller, chatbot_model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", cache_dir=\"./models/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "        global device\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(chatbot_model)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            chatbot_model,\n",
        "            torch_dtype=torch.float32 if device == \"mps\" else (torch.float16 if torch.cuda.is_available() else torch.float32),\n",
        "            cache_dir=cache_dir,\n",
        "            local_files_only=False,\n",
        "        ).to(device)\n",
        "        self.model_device = device\n",
        "        self.dialogue_controller = controller\n",
        "\n",
        "    def __run_prompt(self, prompt, do_sample, temperature, top_p, max_length, show_prompt):\n",
        "        formatted_prompt = self.tokenizer.apply_chat_template(conversation=prompt, tokenize=False, return_dict=False, add_generation_prompt=True)\n",
        "\n",
        "        # Tokenizar\n",
        "        inputs = self.tokenizer(formatted_prompt, max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(self.model_device) for k, v in inputs.items()}\n",
        "\n",
        "        # Muestra infomacion de log\n",
        "        if show_prompt:\n",
        "          print(formatted_prompt)\n",
        "          print(\"--- Token size: ---\")\n",
        "          [print(\"\\t\", k, \": \", len(v[0])) for k, v in inputs.items()]\n",
        "          print(\"-------------------\")\n",
        "\n",
        "        # Generar respuesta\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            do_sample=do_sample,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # Decodificar y limpiar respuesta\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    def answer(self, user_prompt, do_sample=True, temperature=0.1, top_p=0.9, max_length=2047, show_prompt=False):\n",
        "        # Actualiza el prompt\n",
        "        prompt = self.dialogue_controller.add_user_prompt(user_prompt)\n",
        "        # Resolver prompt\n",
        "        answer = self.__run_prompt(prompt, do_sample, temperature, top_p, max_length, show_prompt)\n",
        "        # Actualiza el prompt con la respuesta del asistente\n",
        "        self.dialogue_controller.add_assistant_prompt(answer)\n",
        "        return answer\n",
        "\n"
      ],
      "metadata": {
        "id": "djNrlIyccizf"
      },
      "id": "djNrlIyccizf",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "477bd2d05715ce2b",
        "outputId": "36dc3240-1e49-4ba4-fff7-56e6a98e9e01"
      },
      "cell_type": "code",
      "source": [
        "# Modelos disponibles\n",
        "fine_tuned_model = \"./models/TinyLlama-FT\"\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "cache_dir = \"./models/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# Cargar los modelos a través del chatbot\n",
        "dialog_controller1 = DialogueController(system_prompt=\"Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'.\",keep_cronology=False)\n",
        "dialog_controller2 = DialogueController(system_prompt=\"Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'.\",keep_cronology=False)\n",
        "\n",
        "chatbot_finetuned = Chatbot2(controller=dialog_controller1, chatbot_model=model_name, cache_dir=fine_tuned_model)\n",
        "chatbot_standard = Chatbot2(controller=dialog_controller2)\n",
        "\n",
        "questions = [\n",
        "    (\"Cuál es la capital de francia?\", \"Paris\"),\n",
        "    (\"¿Qué juegos me recomendarías si me ha gustado Undertale?\",\"Deltarune, EarthBound, Hollow Knight, Hyper Light Drifter, Ori and the Blind Forest\"),\n",
        "    (\"¡Hola! ¿Me podrías ayudar con un problema? No me encuentro del todo bien y me duele bastante la cabeza, ¿Sabes que podría ser?\", \"Puede que estés sufriendo de un dolor de cabeza. El dolor de cabeza puede ser causado por muchas cosas, desde estrés hasta una lesión. Si el dolor de cabeza persiste o empeora, es importante consultar a un médico para descartar cualquier afección grave. Algunas cosas que puedes hacer para aliviar el dolor de cabeza incluyen tomar analgésicos, evitar el estrés, descansar, practicar técnicas de relajación y evitar los desencadenantes como la cafeína, el alcohol y los cambios repentinos de presión.\"),\n",
        "    (\"quien era Francisco Morazán?\", \"Francisco Morazán fue un líder político y militar hondureño que trabajó para unir a los países de Centroamérica en una sola nación durante la primera mitad del siglo XIX. Fue elegido presidente de Honduras y de la Confederación Centroamericana y promovió la educación, la justicia y la igualdad. A pesar de ser derrocado y exiliado varias veces, Morazán es recordado como un héroe nacional en Honduras y en otros países de Centroamérica.\")\n",
        "]\n",
        "for question, answer in questions:\n",
        "    print(\"regular: \",chatbot_standard.answer(user_prompt=question))\n",
        "    print(\"fine tuned: \",chatbot_finetuned.answer(user_prompt=question))\n",
        "    print(\"****expected answer: \", answer)\n",
        "    print(\"----------------------\")\n",
        "\n"
      ],
      "id": "477bd2d05715ce2b",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "regular:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "Cuál es la capital de francia? \n",
            "<|assistant|>\n",
            "La capital de Francia es París.\n",
            "fine tuned:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "Cuál es la capital de francia? \n",
            "<|assistant|>\n",
            "La capital de Francia es París.\n",
            "****expected answer:  Paris\n",
            "----------------------\n",
            "regular:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "¿Qué juegos me recomendarías si me ha gustado Undertale? \n",
            "<|assistant|>\n",
            "Sure, Undertale is a great game to play if you enjoyed the aesthetic and gameplay of Toby Fox's Undertale. Here are some games that you might enjoy:\n",
            "\n",
            "1. Celeste: This game is a platformer with a unique twist - the gameplay is based on the player's breathing. It's a challenging and rewarding game that's perfect for fans of Undertale.\n",
            "\n",
            "2. Celeste: Dark Moon: This is a sequel to Celeste that adds new levels and challenges to the game. It's a great way to continue the story and explore the game's world.\n",
            "\n",
            "3. Super Mario Odyssey: This game is a 3D platformer that features a unique and colorful world. It's a great game for fans of Undertale's art style and gameplay.\n",
            "\n",
            "4. Super Mario Odyssey: The Legend of Zelda: Breath of the Wild: This game is a spiritual successor to The Legend of Zelda: A Link to the Past and Breath of the Wild. It's a great game for fans of Undertale's art style and gameplay.\n",
            "\n",
            "5. Super Mario Odyssey: The Legend of Zelda: Breath of the Wild: This game is a spiritual successor to The Legend of Zelda: A Link to the Past and Breath of the Wild. It's a great game for fans of Undertale's art style and gameplay.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "fine tuned:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "¿Qué juegos me recomendarías si me ha gustado Undertale? \n",
            "<|assistant|>\n",
            "Sure, Undertale is a great game to play if you enjoyed the gameplay mechanics and storyline of Toby Fox's Undertale. Here are some games that you might enjoy:\n",
            "\n",
            "1. Celeste: This game is a challenging platformer that features a unique gameplay mechanic where the player controls a character as they climb a mountain.\n",
            "\n",
            "2. Super Mario Odyssey: This game is a 3D platformer where the player controls Mario and can explore different worlds and collect items.\n",
            "\n",
            "3. Super Mario Bros.: This classic game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "4. Super Mario Bros. 3: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "5. Super Mario Bros. 2: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "6. Super Mario Bros. 35: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "7. Super Mario Bros. 3: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "8. Super Mario Bros.: This classic game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "9. Super Mario Bros. 35: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "10. Super Mario Bros. 3: This game is a 2D platformer where the player controls Mario and can explore different levels and collect coins.\n",
            "\n",
            "I hope this helps! Let me know if you have any other questions.\n",
            "****expected answer:  Deltarune, EarthBound, Hollow Knight, Hyper Light Drifter, Ori and the Blind Forest\n",
            "----------------------\n",
            "regular:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "¡Hola! ¿Me podrías ayudar con un problema? No me encuentro del todo bien y me duele bastante la cabeza, ¿Sabes que podría ser? \n",
            "<|assistant|>\n",
            "Sure, I can help you with that.\n",
            "\n",
            "I understand that you may feel a bit overwhelmed and stressed out. It's normal to have doubts and questions at times.\n",
            "\n",
            "Here are some tips to help you cope with your headaches:\n",
            "\n",
            "1. Take a break: Sometimes, taking a break from studying or work can help you clear your mind and reduce stress.\n",
            "\n",
            "2. Practice relaxation techniques: There are many relaxation techniques you can try, such as deep breathing, meditation, or yoga. These techniques can help you calm your mind and reduce stress.\n",
            "\n",
            "3. Seek support: If you're feeling overwhelmed, it's okay to seek support from friends, family, or a mental health professional. They can help you identify your concerns and provide you with the support you need.\n",
            "\n",
            "4. Practice self-care: Make sure to take care of yourself physically and emotionally. This could mean getting enough sleep, eating a healthy diet, and exercising regularly.\n",
            "\n",
            "5. Stay positive: Try to stay positive and focus on the positive aspects of your life. This can help you feel more confident and motivated.\n",
            "\n",
            "Remember, it's okay to have doubts and questions. Don't be afraid to ask for help or seek support. You're not alone in this.\n",
            "fine tuned:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "¡Hola! ¿Me podrías ayudar con un problema? No me encuentro del todo bien y me duele bastante la cabeza, ¿Sabes que podría ser? \n",
            "<|assistant|>\n",
            "Sure, I can help you with that. Here's a possible solution:\n",
            "\n",
            "1. \"¿No te duerme?\" (Do you sleep well?)\n",
            "2. \"¿No te duerme?\" (Do you sleep well?)\n",
            "3. \"¿No te duerme?\" (Do you sleep well?)\n",
            "\n",
            "In this example, the question is asked in Spanish, and the response is \"No\" in the same way that it would be in English.\n",
            "\n",
            "Remember that the tone and style of the question and response should be the same in both languages. If you're unsure about the tone or style, it's always best to ask a native speaker for guidance.\n",
            "****expected answer:  Puede que estés sufriendo de un dolor de cabeza. El dolor de cabeza puede ser causado por muchas cosas, desde estrés hasta una lesión. Si el dolor de cabeza persiste o empeora, es importante consultar a un médico para descartar cualquier afección grave. Algunas cosas que puedes hacer para aliviar el dolor de cabeza incluyen tomar analgésicos, evitar el estrés, descansar, practicar técnicas de relajación y evitar los desencadenantes como la cafeína, el alcohol y los cambios repentinos de presión.\n",
            "----------------------\n",
            "regular:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "quien era Francisco Morazán? \n",
            "<|assistant|>\n",
            "Francisco Morazán (1802-1853) was a Mexican statesman, diplomat, and revolutionary leader who played a significant role in the Mexican War of Independence (1810-1821) and the Mexican Revolution (1910-1920). He was the first president of the Republic of Mexico and served as the first president of the Mexican Empire (1821-1823). Morazán was a member of the Liberal Party and was known for his advocacy for democracy, human rights, and national unity. He was also a proponent of the idea of a federal system for Mexico, which was eventually implemented in the country's constitution of 1917.\n",
            "fine tuned:  <|system|>\n",
            "Responde mis dudas de manera coincisa, breve, y siempre en español. En caso de no conocer la respuesta dime 'no lo se'. \n",
            "<|user|>\n",
            "quien era Francisco Morazán? \n",
            "<|assistant|>\n",
            "Francisco Morazán (1802-1850) was a Mexican general, politician, and revolutionary leader who played a significant role in the Mexican War of Independence and the Mexican Revolution. He was born in the town of Morazán, in the state of Chiapas, and was the son of a wealthy landowner. Morazán joined the army at a young age and rose through the ranks to become a general in the Mexican army. He played a key role in the Mexican War of Independence, where he led the army in several battles against the Spanish Empire. After the war, Morazán became a prominent figure in Mexican politics, serving as the president of the Mexican Republic from 1857 to 1861. He was also a prominent figure in the Mexican Revolution, where he played a key role in the Battle of Puebla and the subsequent fall of the Spanish Empire.\n",
            "****expected answer:  Francisco Morazán fue un líder político y militar hondureño que trabajó para unir a los países de Centroamérica en una sola nación durante la primera mitad del siglo XIX. Fue elegido presidente de Honduras y de la Confederación Centroamericana y promovió la educación, la justicia y la igualdad. A pesar de ser derrocado y exiliado varias veces, Morazán es recordado como un héroe nacional en Honduras y en otros países de Centroamérica.\n",
            "----------------------\n"
          ]
        }
      ],
      "execution_count": 14
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82f323e0aeca46f3955a76515354de8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f2fe803b68d4cc293df292f3ed07cde",
              "IPY_MODEL_182b0ee0432446208c2e66838777f023",
              "IPY_MODEL_661b295b83a54452a07ebe324942f1ad"
            ],
            "layout": "IPY_MODEL_c66be6cb91ff41089f9f57f2b4bd334e"
          }
        },
        "6f2fe803b68d4cc293df292f3ed07cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdee23af289247779d0041258fb54100",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e434e7562a4550aaed00ee5bf970e2",
            "value": "Map: 100%"
          }
        },
        "182b0ee0432446208c2e66838777f023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28a6850e09049f5979e63a83e5c752a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af307f04a81a415a806c71181030bab9",
            "value": 1000
          }
        },
        "661b295b83a54452a07ebe324942f1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091b7ff1c0c0409f9793cc175d041f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_43a5cb03d28c425cbf282226b492a525",
            "value": " 1000/1000 [00:01&lt;00:00, 657.37 examples/s]"
          }
        },
        "c66be6cb91ff41089f9f57f2b4bd334e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdee23af289247779d0041258fb54100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e434e7562a4550aaed00ee5bf970e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28a6850e09049f5979e63a83e5c752a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af307f04a81a415a806c71181030bab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "091b7ff1c0c0409f9793cc175d041f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a5cb03d28c425cbf282226b492a525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}