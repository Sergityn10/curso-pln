# Curso de Introducci√≥n al Procesamiento del Lenguaje Natural (PLN)

Este repositorio contiene una colecci√≥n de notebooks y recursos para el curso de Procesamiento de Lenguaje Natural. El curso est√° dise√±ado para estudiantes y profesionales que desean adentrarse en el mundo del PLN, comenzando desde
conceptos b√°sicos hasta t√©cnicas m√°s avanzadas.

## üéØ Objetivos del Curso

- Comprender los fundamentos de Procesamiento de Lenguaje Natural
- Aprender a trabajar con diferentes tipos de corpus ling√º√≠sticos
- Desarrollar habilidades pr√°cticas en el preprocesamiento de texto
- Implementar modelos b√°sicos de PLN
- Familiarizarse con las principales bibliotecas y herramientas del ecosistema PLN

## üìö Contenido

### M√≥dulo 1: Preparaci√≥n de Datos
- [Expresiones Regulares](notebooks/01_expresiones_regulares.ipynb)
- [Preprocesamiento de Datos](notebooks/01_Preprocesamiento_Datos.ipynb)
- [An√°lisis de Valoraciones](notebooks/01_analisis_de_valoraciones.ipynb)

### M√≥dulo 2: Modelos n-gramas
- [Modelos N-gramas](notebooks/02_modelos_ngramas.ipynb)
- [Naive Bayes](notebooks/02_naive_bayes.ipynb)
- [Regresion Log√≠stica](notebooks/02_regresion_logistica.ipynb)

### M√≥dulo 3: Modelos Vectoriales
- [Word2Vec](notebooks/03_word2vec.ipynb)
- [Sherlock Holmes](notebooks/03_embeddings_sherlock_holmes.ipynb)
- [Wikipedia](notebooks/03_exercise_embeddings_wikipedia.ipynb)

### M√≥dulo 4: Modelos Probabil√≠sticos de T√≥picos
- [LDA](notebooks/04_LDA_Cordis.ipynb)
- [Extensiones LDA](notebooks/04_Extensiones_LDA.ipynb)

### M√≥dulo 5: Modelos Transformers
- [MLP](notebooks/05_MLP.ipynb)
- [Redes de Neuronas](notebooks/05_Red_Neuronas_Keras.ipynb)
- [Transformers](notebooks/05_Transformers_con_Keras.ipynb)
- [GPT](notebooks/05_Transformers_GPT.ipynb)
- [HuggingFace](notebooks/05_Transformers_HuggingFace.ipynb)

### M√≥dulo 6: Ajuste Fino (fine-tuning)
- [Clasificacion](notebooks/06_Ajuste_Fino_Clasificacion_IMDB.ipynb)
- [Named Entity Recognition (NER)](notebooks/06_Ajuste_Fino_NER.ipynb)

### M√≥dulo 7: Prompting
- [Aprendizaje por Contexto](notebooks/07_Ajuste_por_Instrucciones.ipynb)
- [Evaluaci√≥n](notebooks/07_Evaluacion_Modelos_Prompts.ipynb)

### M√≥dulo 8: Retrieval Augmented Generation (RAG)
- [B√∫squeda Dispersa y Densa](notebooks/08_Busqueda_Dispersa_y_Densa.ipynb)
- [RAG Avanzado](notebooks/08_RAG_Avanzado.ipynb)


## üìä Datasets Incluidos

- [Valoraciones de Restaurantes](datasets/valoraciones_restaurante.json) - Este dataset contiene rese√±as de restaurantes en espa√±ol, ideal para practicar an√°lisis de texto y expresiones regulares.

## üõ†Ô∏è Requisitos T√©cnicos

- Python 3.7+
- Jupyter Notebook o JupyterLab
- Bibliotecas principales:
    - nltk
    - pandas
    - numpy
    - matplotlib
    - scikit-learn

## üöÄ Comenzando

1. Clona este repositorio:
```bash
git clone https://github.com/cbadenes/curso-pln.git
```
2. Instala las dependencias necesarias:
```bash
pip install -r requirements.txt
```
3. Descarga los recursos necesarios de NLTK:
```bash
import nltk
nltk.download('reuters')
nltk.download('punkt')
nltk.download('punkt_tab')
```
4. Abre los notebooks en Jupyter:
```bash
jupyter notebook
```

## üìñ Estructura de los Notebooks
Cada notebook sigue una estructura similar:

1. Introducci√≥n te√≥rica al concepto
2. Implementaci√≥n pr√°ctica
3. Ejercicios y ejemplos
4. Referencias adicionales

## üë• Contribuciones
Las contribuciones son bienvenidas. Si deseas contribuir:

1. Haz fork del repositorio
2. Crea una nueva rama para tu funcionalidad
3. Env√≠a un pull request

## üìÑ Licencia
Este proyecto est√° bajo la Licencia MIT - ver el archivo LICENSE para m√°s detalles.

## üì¨ Contacto
Para dudas, sugerencias o colaboraciones, no dudes en:

- Abrir un issue en este repositorio
- Contactar a trav√©s de [carlos.badenes](mailto:carlos.badenes@upm.es)

## üôè Agradecimientos

- A la comunidad NLTK por sus excelentes recursos y documentaci√≥n
- A todos los contribuidores y estudiantes que ayudan a mejorar este material

‚≠êÔ∏è Si este curso te resulta √∫til, no dudes en darle una estrella al repositorio.
